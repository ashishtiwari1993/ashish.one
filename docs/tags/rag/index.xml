<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>RAG on ashish.one</title>
    <link>https://ashish.one/tags/rag/</link>
    <description>Recent content in RAG on ashish.one</description>
    <image>
      <title>ashish.one</title>
      <url>https://ashish.one/img/speaker-pic/ashish.png</url>
      <link>https://ashish.one/img/speaker-pic/ashish.png</link>
    </image>
    <generator>Hugo -- 0.136.4</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 25 Aug 2025 11:29:16 +0530</lastBuildDate>
    <atom:link href="https://ashish.one/tags/rag/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Laracon 2024</title>
      <link>https://ashish.one/talks/laracon-2024/</link>
      <pubDate>Mon, 25 Aug 2025 11:29:16 +0530</pubDate>
      <guid>https://ashish.one/talks/laracon-2024/</guid>
      <description>&lt;h1 id=&#34;-talk-summary-no-code-rag-chatbot-with-php-llms--elasticsearch&#34;&gt;🎤 Talk Summary: No-Code RAG Chatbot with PHP, LLMs &amp;amp; Elasticsearch&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Speaker:&lt;/strong&gt; Ashish Diwali (Senior Developer Advocate, Elastic)&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-introduction&#34;&gt;🔑 Introduction&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Topic: Integrating &lt;strong&gt;Generative AI (LLMs)&lt;/strong&gt; with &lt;strong&gt;PHP&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Goal: Show how to build &lt;strong&gt;chat assistants, semantic search, and vector search&lt;/strong&gt; without heavy ML expertise.&lt;/li&gt;
&lt;li&gt;Demo focus: Using &lt;strong&gt;Elasticsearch + PHP + LLM (LLaMA 3.1)&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-core-concepts&#34;&gt;🧩 Core Concepts&lt;/h2&gt;
&lt;h3 id=&#34;1-prompt-engineering&#34;&gt;1. Prompt Engineering&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;LLMs generate responses based on prompts → predicting next words.&lt;/li&gt;
&lt;li&gt;Techniques:
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Zero-shot inference&lt;/strong&gt; → direct classification or tagging.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;One-shot inference&lt;/strong&gt; → provide one example in the prompt.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Few-shot inference&lt;/strong&gt; → multiple examples → useful for structured outputs (SQL, JSON, XML).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Iteration + context = &lt;strong&gt;In-context learning (ICL)&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2-llm-limitations&#34;&gt;2. LLM Limitations&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;❌ Hallucinations (wrong answers).&lt;/li&gt;
&lt;li&gt;❌ Complex to build/train from scratch.&lt;/li&gt;
&lt;li&gt;❌ No real-time / private data access.&lt;/li&gt;
&lt;li&gt;❌ Privacy &amp;amp; security concerns (especially in banking, public sector).&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;3-rag-retrieval-augmented-generation&#34;&gt;3. RAG (Retrieval-Augmented Generation)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Solution to limitations.&lt;/li&gt;
&lt;li&gt;Workflow:
&lt;ol&gt;
&lt;li&gt;User query → hits database/vector DB (e.g., Elasticsearch).&lt;/li&gt;
&lt;li&gt;Retrieve &lt;strong&gt;top 5–10 relevant docs&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Pass as context window → LLM generates accurate answer.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Benefits:
&lt;ul&gt;
&lt;li&gt;Grounded responses.&lt;/li&gt;
&lt;li&gt;Works with private data.&lt;/li&gt;
&lt;li&gt;Avoids retraining large models.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-semantic--vector-search&#34;&gt;🔍 Semantic &amp;amp; Vector Search&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Semantic Search:&lt;/strong&gt; Understands meaning, not just keywords.
&lt;ul&gt;
&lt;li&gt;Example: “best city” ↔ “beautiful city.”&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Vector Search:&lt;/strong&gt; Text, images, and audio converted into embeddings (arrays of floats).
&lt;ul&gt;
&lt;li&gt;Enables image search, recommendation systems, music search (via humming).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Similarity algorithms:&lt;/strong&gt; cosine similarity, dot product, nearest neighbors.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-tools--demo&#34;&gt;🛠️ Tools &amp;amp; Demo&lt;/h2&gt;
&lt;h3 id=&#34;elephant-library-php&#34;&gt;Elephant Library (PHP)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Open-source PHP library for GenAI apps.&lt;/li&gt;
&lt;li&gt;Supports:
&lt;ul&gt;
&lt;li&gt;LLMs: OpenAI, Mistral, Anthropic, LLaMA.&lt;/li&gt;
&lt;li&gt;Vector DBs: Elasticsearch, Pinecone, Chroma, etc.&lt;/li&gt;
&lt;li&gt;Features: document chunking, embedding generation, semantic retrieval, Q&amp;amp;A (RAG).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;demo-flow&#34;&gt;Demo Flow&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Ingestion&lt;/strong&gt;:&lt;/p&gt;</description>
      <content:encoded><![CDATA[<h1 id="-talk-summary-no-code-rag-chatbot-with-php-llms--elasticsearch">🎤 Talk Summary: No-Code RAG Chatbot with PHP, LLMs &amp; Elasticsearch</h1>
<p><strong>Speaker:</strong> Ashish Diwali (Senior Developer Advocate, Elastic)</p>
<hr>
<h2 id="-introduction">🔑 Introduction</h2>
<ul>
<li>Topic: Integrating <strong>Generative AI (LLMs)</strong> with <strong>PHP</strong>.</li>
<li>Goal: Show how to build <strong>chat assistants, semantic search, and vector search</strong> without heavy ML expertise.</li>
<li>Demo focus: Using <strong>Elasticsearch + PHP + LLM (LLaMA 3.1)</strong>.</li>
</ul>
<hr>
<h2 id="-core-concepts">🧩 Core Concepts</h2>
<h3 id="1-prompt-engineering">1. Prompt Engineering</h3>
<ul>
<li>LLMs generate responses based on prompts → predicting next words.</li>
<li>Techniques:
<ul>
<li><strong>Zero-shot inference</strong> → direct classification or tagging.</li>
<li><strong>One-shot inference</strong> → provide one example in the prompt.</li>
<li><strong>Few-shot inference</strong> → multiple examples → useful for structured outputs (SQL, JSON, XML).</li>
</ul>
</li>
<li>Iteration + context = <strong>In-context learning (ICL)</strong>.</li>
</ul>
<h3 id="2-llm-limitations">2. LLM Limitations</h3>
<ul>
<li>❌ Hallucinations (wrong answers).</li>
<li>❌ Complex to build/train from scratch.</li>
<li>❌ No real-time / private data access.</li>
<li>❌ Privacy &amp; security concerns (especially in banking, public sector).</li>
</ul>
<h3 id="3-rag-retrieval-augmented-generation">3. RAG (Retrieval-Augmented Generation)</h3>
<ul>
<li>Solution to limitations.</li>
<li>Workflow:
<ol>
<li>User query → hits database/vector DB (e.g., Elasticsearch).</li>
<li>Retrieve <strong>top 5–10 relevant docs</strong>.</li>
<li>Pass as context window → LLM generates accurate answer.</li>
</ol>
</li>
<li>Benefits:
<ul>
<li>Grounded responses.</li>
<li>Works with private data.</li>
<li>Avoids retraining large models.</li>
</ul>
</li>
</ul>
<hr>
<h2 id="-semantic--vector-search">🔍 Semantic &amp; Vector Search</h2>
<ul>
<li><strong>Semantic Search:</strong> Understands meaning, not just keywords.
<ul>
<li>Example: “best city” ↔ “beautiful city.”</li>
</ul>
</li>
<li><strong>Vector Search:</strong> Text, images, and audio converted into embeddings (arrays of floats).
<ul>
<li>Enables image search, recommendation systems, music search (via humming).</li>
</ul>
</li>
<li><strong>Similarity algorithms:</strong> cosine similarity, dot product, nearest neighbors.</li>
</ul>
<hr>
<h2 id="-tools--demo">🛠️ Tools &amp; Demo</h2>
<h3 id="elephant-library-php">Elephant Library (PHP)</h3>
<ul>
<li>Open-source PHP library for GenAI apps.</li>
<li>Supports:
<ul>
<li>LLMs: OpenAI, Mistral, Anthropic, LLaMA.</li>
<li>Vector DBs: Elasticsearch, Pinecone, Chroma, etc.</li>
<li>Features: document chunking, embedding generation, semantic retrieval, Q&amp;A (RAG).</li>
</ul>
</li>
</ul>
<h3 id="demo-flow">Demo Flow</h3>
<ol>
<li>
<p><strong>Ingestion</strong>:</p>
<ul>
<li>Chunk PDF into smaller pieces (800 chars).</li>
<li>Generate embeddings with LLaMA.</li>
<li>Store text + vectors in Elasticsearch.</li>
</ul>
</li>
<li>
<p><strong>Querying</strong>:</p>
<ul>
<li>User question → hits Elasticsearch.</li>
<li>Retrieve top 10 docs.</li>
<li>Send docs + query → LLaMA → response.</li>
</ul>
</li>
<li>
<p><strong>Examples</strong>:</p>
<ul>
<li><em>“Who won the Nobel Prize in Physics 2024?”</em> → Retrieved correct answer from PDF context.</li>
<li><em>“How do brain neural networks work?”</em> → Summarized based on provided docs.</li>
<li><em>“Who won ICC Championship 2025?”</em> → No irrelevant hallucination (kept within context).</li>
</ul>
</li>
</ol>
<hr>
<h2 id="-key-takeaways">🎯 Key Takeaways</h2>
<ul>
<li><strong>Don’t train your own LLM</strong> → use <strong>RAG + search</strong> to build assistants on private data.</li>
<li><strong>Elasticsearch</strong> is a powerful vector DB for semantic + hybrid search.</li>
<li><strong>PHP + Elephant</strong> makes building RAG chatbots accessible for web developers.</li>
<li>RAG powers most modern chat assistants today.</li>
</ul>
<hr>


    
    <div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
      <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/qDFct7oeRss?autoplay=0&controls=1&end=0&loop=0&mute=0&start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video"
      ></iframe>
    </div>

]]></content:encoded>
    </item>
    <item>
      <title>AWS Community Day Mumbai 2024</title>
      <link>https://ashish.one/talks/aws-communtiy-day-mumbai-2024/</link>
      <pubDate>Mon, 25 Aug 2025 10:18:25 +0530</pubDate>
      <guid>https://ashish.one/talks/aws-communtiy-day-mumbai-2024/</guid>
      <description>&lt;h1 id=&#34;-no-code-chatbot-with-elasticsearch--aws-bedrock-talk-summary&#34;&gt;🚀 No-Code Chatbot with Elasticsearch + AWS Bedrock (Talk Summary)&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Speaker:&lt;/strong&gt; Ashish (Senior Developer Advocate, Elastic)&lt;br&gt;
&lt;strong&gt;Event:&lt;/strong&gt; AWS Community Day Mumbai 2024&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-why-search-still-matters-with-llms&#34;&gt;🔑 Why Search Still Matters with LLMs&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;LLMs (like ChatGPT) are powerful but face:
&lt;ul&gt;
&lt;li&gt;❌ Hallucinations&lt;/li&gt;
&lt;li&gt;💰 High cost per query&lt;/li&gt;
&lt;li&gt;🔒 No access to private / real-time data&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;✅ Search grounds LLMs in &lt;strong&gt;reliable, domain-specific info&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-elasticsearch-capabilities&#34;&gt;⚡ Elasticsearch Capabilities&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Traditional &lt;strong&gt;keyword search&lt;/strong&gt; + modern &lt;strong&gt;vector search&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Real-world use cases:
&lt;ul&gt;
&lt;li&gt;📍 Geospatial queries (ride-sharing, food delivery)&lt;/li&gt;
&lt;li&gt;❤️ Matchmaking&lt;/li&gt;
&lt;li&gt;📊 Observability dashboards&lt;/li&gt;
&lt;li&gt;📝 Centralized logging (Elastic Stack: Elasticsearch, Kibana, Beats, Logstash)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-retrieval-augmented-generation-rag&#34;&gt;🤖 Retrieval-Augmented Generation (RAG)&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Workflow:&lt;/strong&gt;&lt;/p&gt;</description>
      <content:encoded><![CDATA[<h1 id="-no-code-chatbot-with-elasticsearch--aws-bedrock-talk-summary">🚀 No-Code Chatbot with Elasticsearch + AWS Bedrock (Talk Summary)</h1>
<p><strong>Speaker:</strong> Ashish (Senior Developer Advocate, Elastic)<br>
<strong>Event:</strong> AWS Community Day Mumbai 2024</p>
<hr>
<h2 id="-why-search-still-matters-with-llms">🔑 Why Search Still Matters with LLMs</h2>
<ul>
<li>LLMs (like ChatGPT) are powerful but face:
<ul>
<li>❌ Hallucinations</li>
<li>💰 High cost per query</li>
<li>🔒 No access to private / real-time data</li>
</ul>
</li>
<li>✅ Search grounds LLMs in <strong>reliable, domain-specific info</strong>.</li>
</ul>
<hr>
<h2 id="-elasticsearch-capabilities">⚡ Elasticsearch Capabilities</h2>
<ul>
<li>Traditional <strong>keyword search</strong> + modern <strong>vector search</strong>.</li>
<li>Real-world use cases:
<ul>
<li>📍 Geospatial queries (ride-sharing, food delivery)</li>
<li>❤️ Matchmaking</li>
<li>📊 Observability dashboards</li>
<li>📝 Centralized logging (Elastic Stack: Elasticsearch, Kibana, Beats, Logstash)</li>
</ul>
</li>
</ul>
<hr>
<h2 id="-retrieval-augmented-generation-rag">🤖 Retrieval-Augmented Generation (RAG)</h2>
<p><strong>Workflow:</strong></p>
<ol>
<li>User query →</li>
<li>Elasticsearch retrieves relevant documents →</li>
<li>Context passed to AWS Bedrock LLM →</li>
<li>LLM generates grounded answers</li>
</ol>
<p>👉 Reduces hallucination, enables <strong>chatbots on private data</strong>.</p>
<hr>
<h2 id="-demo-stack">🛠️ Demo Stack</h2>
<ul>
<li><strong>Flowise AI</strong> → No-code, drag &amp; drop RAG builder</li>
<li><strong>Steps:</strong>
<ol>
<li>Ingest data (JSON, PDFs, web crawl)</li>
<li>Chunk text</li>
<li>Generate embeddings (Amazon Titan)</li>
<li>Store embeddings + text in Elasticsearch</li>
<li>Connect Bedrock LLM for Q&amp;A</li>
</ol>
</li>
</ul>
<hr>
<h2 id="-extensions">🌐 Extensions</h2>
<ul>
<li>Text search ✅</li>
<li>Image search 🖼️</li>
<li>Audio search (e.g., humming a tune) 🎵</li>
<li>Multimodal experiences 🤝</li>
</ul>
<hr>
<h2 id="-key-takeaway">🎯 Key Takeaway</h2>
<p>With <strong>Elasticsearch + AWS Bedrock + Flowise AI</strong>, developers can build <strong>domain-specific, no-code RAG chatbots</strong> that combine:</p>
<ul>
<li>The <strong>precision of search</strong> 🔍</li>
<li>The <strong>fluency of LLMs</strong> 💬</li>
</ul>
<hr>
<h1 id="talk-video">Talk video</h1>


    
    <div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
      <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/ODy_xZIKU-s?autoplay=0&controls=1&end=0&loop=0&mute=0&start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video"
      ></iframe>
    </div>

]]></content:encoded>
    </item>
    <item>
      <title>GIDS 2024 - Smart Search with RAG: Elasticsearch Meets Language Models</title>
      <link>https://ashish.one/talks/gids-2024-rag/</link>
      <pubDate>Mon, 03 Jun 2024 12:12:06 +0530</pubDate>
      <guid>https://ashish.one/talks/gids-2024-rag/</guid>
      <description>&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;In today&amp;rsquo;s data-driven world, just having a search engine is not enough; the key is making it smart. Enter Elasticsearch Relevance Engine (ESRE) augmented with Retrieval Augmented Generation (RAG), a powerful solution
that marries Elasticsearch’s superior search capabilities with Large Language Models (LLMs) like ChatGPT for precise, contextual querying over proprietary datasets. This session is a hands-on guide that will show you how to amplify the power of Elasticsearch with advanced LLMs.&lt;/p&gt;</description>
      <content:encoded><![CDATA[<h1 id="introduction">Introduction</h1>
<p>In today&rsquo;s data-driven world, just having a search engine is not enough; the key is making it smart. Enter Elasticsearch Relevance Engine (ESRE) augmented with Retrieval Augmented Generation (RAG), a powerful solution
that marries Elasticsearch’s superior search capabilities with Large Language Models (LLMs) like ChatGPT for precise, contextual querying over proprietary datasets. This session is a hands-on guide that will show you how to amplify the power of Elasticsearch with advanced LLMs.</p>
<p>Key Takeaways:</p>
<ul>
<li>Learn how to supercharge Elasticsearch&rsquo;s BM25 algorithm with semantic search for results that are not just relevant but contextually accurate.</li>
<li>Discover how to plug in Large Language Models like OpenAI&rsquo;s ChatGPT to enable context-aware question-answering over your proprietary data.</li>
<li>Gain insights into the latest advancements in vector search within Lucene and Elasticsearch.</li>
<li>A quick live demo: Experience first-hand how ESRE, empowered by RAG, transforms a basic search query into a context-rich, highly relevant result..</li>
</ul>
<p>This talk is for you if you&rsquo;re grappling with search relevance issues and are looking for innovative ways to make your search smarter and more efficient. Whether you&rsquo;re a software developer, data engineer, or ML enthusiast, this session will equip you with the skills you need to build next-generation search capabilities.</p>
<h2 id="talk-video">Talk video</h2>


    
    <div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
      <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/r1jO4TglsEg?autoplay=0&controls=1&end=0&loop=0&mute=0&start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video"
      ></iframe>
    </div>

]]></content:encoded>
    </item>
  </channel>
</rss>

<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Laravel on ashish.one</title>
    <link>https://ashish.one/tags/laravel/</link>
    <description>Recent content in Laravel on ashish.one</description>
    <image>
      <title>ashish.one</title>
      <url>https://ashish.one/img/speaker-pic/ashish.png</url>
      <link>https://ashish.one/img/speaker-pic/ashish.png</link>
    </image>
    <generator>Hugo -- 0.136.4</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 25 Aug 2025 12:47:35 +0530</lastBuildDate>
    <atom:link href="https://ashish.one/tags/laravel/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Laracon 2024</title>
      <link>https://ashish.one/talks/laracon-2024/</link>
      <pubDate>Mon, 25 Aug 2025 11:29:16 +0530</pubDate>
      <guid>https://ashish.one/talks/laracon-2024/</guid>
      <description>&lt;h1 id=&#34;-talk-summary-no-code-rag-chatbot-with-php-llms--elasticsearch&#34;&gt;ğŸ¤ Talk Summary: No-Code RAG Chatbot with PHP, LLMs &amp;amp; Elasticsearch&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Speaker:&lt;/strong&gt; Ashish Diwali (Senior Developer Advocate, Elastic)&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-introduction&#34;&gt;ğŸ”‘ Introduction&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Topic: Integrating &lt;strong&gt;Generative AI (LLMs)&lt;/strong&gt; with &lt;strong&gt;PHP&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Goal: Show how to build &lt;strong&gt;chat assistants, semantic search, and vector search&lt;/strong&gt; without heavy ML expertise.&lt;/li&gt;
&lt;li&gt;Demo focus: Using &lt;strong&gt;Elasticsearch + PHP + LLM (LLaMA 3.1)&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-core-concepts&#34;&gt;ğŸ§© Core Concepts&lt;/h2&gt;
&lt;h3 id=&#34;1-prompt-engineering&#34;&gt;1. Prompt Engineering&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;LLMs generate responses based on prompts â†’ predicting next words.&lt;/li&gt;
&lt;li&gt;Techniques:
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Zero-shot inference&lt;/strong&gt; â†’ direct classification or tagging.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;One-shot inference&lt;/strong&gt; â†’ provide one example in the prompt.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Few-shot inference&lt;/strong&gt; â†’ multiple examples â†’ useful for structured outputs (SQL, JSON, XML).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Iteration + context = &lt;strong&gt;In-context learning (ICL)&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2-llm-limitations&#34;&gt;2. LLM Limitations&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;âŒ Hallucinations (wrong answers).&lt;/li&gt;
&lt;li&gt;âŒ Complex to build/train from scratch.&lt;/li&gt;
&lt;li&gt;âŒ No real-time / private data access.&lt;/li&gt;
&lt;li&gt;âŒ Privacy &amp;amp; security concerns (especially in banking, public sector).&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;3-rag-retrieval-augmented-generation&#34;&gt;3. RAG (Retrieval-Augmented Generation)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Solution to limitations.&lt;/li&gt;
&lt;li&gt;Workflow:
&lt;ol&gt;
&lt;li&gt;User query â†’ hits database/vector DB (e.g., Elasticsearch).&lt;/li&gt;
&lt;li&gt;Retrieve &lt;strong&gt;top 5â€“10 relevant docs&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Pass as context window â†’ LLM generates accurate answer.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Benefits:
&lt;ul&gt;
&lt;li&gt;Grounded responses.&lt;/li&gt;
&lt;li&gt;Works with private data.&lt;/li&gt;
&lt;li&gt;Avoids retraining large models.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-semantic--vector-search&#34;&gt;ğŸ” Semantic &amp;amp; Vector Search&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Semantic Search:&lt;/strong&gt; Understands meaning, not just keywords.
&lt;ul&gt;
&lt;li&gt;Example: â€œbest cityâ€ â†” â€œbeautiful city.â€&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Vector Search:&lt;/strong&gt; Text, images, and audio converted into embeddings (arrays of floats).
&lt;ul&gt;
&lt;li&gt;Enables image search, recommendation systems, music search (via humming).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Similarity algorithms:&lt;/strong&gt; cosine similarity, dot product, nearest neighbors.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-tools--demo&#34;&gt;ğŸ› ï¸ Tools &amp;amp; Demo&lt;/h2&gt;
&lt;h3 id=&#34;elephant-library-php&#34;&gt;Elephant Library (PHP)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Open-source PHP library for GenAI apps.&lt;/li&gt;
&lt;li&gt;Supports:
&lt;ul&gt;
&lt;li&gt;LLMs: OpenAI, Mistral, Anthropic, LLaMA.&lt;/li&gt;
&lt;li&gt;Vector DBs: Elasticsearch, Pinecone, Chroma, etc.&lt;/li&gt;
&lt;li&gt;Features: document chunking, embedding generation, semantic retrieval, Q&amp;amp;A (RAG).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;demo-flow&#34;&gt;Demo Flow&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Ingestion&lt;/strong&gt;:&lt;/p&gt;</description>
      <content:encoded><![CDATA[<h1 id="-talk-summary-no-code-rag-chatbot-with-php-llms--elasticsearch">ğŸ¤ Talk Summary: No-Code RAG Chatbot with PHP, LLMs &amp; Elasticsearch</h1>
<p><strong>Speaker:</strong> Ashish Diwali (Senior Developer Advocate, Elastic)</p>
<hr>
<h2 id="-introduction">ğŸ”‘ Introduction</h2>
<ul>
<li>Topic: Integrating <strong>Generative AI (LLMs)</strong> with <strong>PHP</strong>.</li>
<li>Goal: Show how to build <strong>chat assistants, semantic search, and vector search</strong> without heavy ML expertise.</li>
<li>Demo focus: Using <strong>Elasticsearch + PHP + LLM (LLaMA 3.1)</strong>.</li>
</ul>
<hr>
<h2 id="-core-concepts">ğŸ§© Core Concepts</h2>
<h3 id="1-prompt-engineering">1. Prompt Engineering</h3>
<ul>
<li>LLMs generate responses based on prompts â†’ predicting next words.</li>
<li>Techniques:
<ul>
<li><strong>Zero-shot inference</strong> â†’ direct classification or tagging.</li>
<li><strong>One-shot inference</strong> â†’ provide one example in the prompt.</li>
<li><strong>Few-shot inference</strong> â†’ multiple examples â†’ useful for structured outputs (SQL, JSON, XML).</li>
</ul>
</li>
<li>Iteration + context = <strong>In-context learning (ICL)</strong>.</li>
</ul>
<h3 id="2-llm-limitations">2. LLM Limitations</h3>
<ul>
<li>âŒ Hallucinations (wrong answers).</li>
<li>âŒ Complex to build/train from scratch.</li>
<li>âŒ No real-time / private data access.</li>
<li>âŒ Privacy &amp; security concerns (especially in banking, public sector).</li>
</ul>
<h3 id="3-rag-retrieval-augmented-generation">3. RAG (Retrieval-Augmented Generation)</h3>
<ul>
<li>Solution to limitations.</li>
<li>Workflow:
<ol>
<li>User query â†’ hits database/vector DB (e.g., Elasticsearch).</li>
<li>Retrieve <strong>top 5â€“10 relevant docs</strong>.</li>
<li>Pass as context window â†’ LLM generates accurate answer.</li>
</ol>
</li>
<li>Benefits:
<ul>
<li>Grounded responses.</li>
<li>Works with private data.</li>
<li>Avoids retraining large models.</li>
</ul>
</li>
</ul>
<hr>
<h2 id="-semantic--vector-search">ğŸ” Semantic &amp; Vector Search</h2>
<ul>
<li><strong>Semantic Search:</strong> Understands meaning, not just keywords.
<ul>
<li>Example: â€œbest cityâ€ â†” â€œbeautiful city.â€</li>
</ul>
</li>
<li><strong>Vector Search:</strong> Text, images, and audio converted into embeddings (arrays of floats).
<ul>
<li>Enables image search, recommendation systems, music search (via humming).</li>
</ul>
</li>
<li><strong>Similarity algorithms:</strong> cosine similarity, dot product, nearest neighbors.</li>
</ul>
<hr>
<h2 id="-tools--demo">ğŸ› ï¸ Tools &amp; Demo</h2>
<h3 id="elephant-library-php">Elephant Library (PHP)</h3>
<ul>
<li>Open-source PHP library for GenAI apps.</li>
<li>Supports:
<ul>
<li>LLMs: OpenAI, Mistral, Anthropic, LLaMA.</li>
<li>Vector DBs: Elasticsearch, Pinecone, Chroma, etc.</li>
<li>Features: document chunking, embedding generation, semantic retrieval, Q&amp;A (RAG).</li>
</ul>
</li>
</ul>
<h3 id="demo-flow">Demo Flow</h3>
<ol>
<li>
<p><strong>Ingestion</strong>:</p>
<ul>
<li>Chunk PDF into smaller pieces (800 chars).</li>
<li>Generate embeddings with LLaMA.</li>
<li>Store text + vectors in Elasticsearch.</li>
</ul>
</li>
<li>
<p><strong>Querying</strong>:</p>
<ul>
<li>User question â†’ hits Elasticsearch.</li>
<li>Retrieve top 10 docs.</li>
<li>Send docs + query â†’ LLaMA â†’ response.</li>
</ul>
</li>
<li>
<p><strong>Examples</strong>:</p>
<ul>
<li><em>â€œWho won the Nobel Prize in Physics 2024?â€</em> â†’ Retrieved correct answer from PDF context.</li>
<li><em>â€œHow do brain neural networks work?â€</em> â†’ Summarized based on provided docs.</li>
<li><em>â€œWho won ICC Championship 2025?â€</em> â†’ No irrelevant hallucination (kept within context).</li>
</ul>
</li>
</ol>
<hr>
<h2 id="-key-takeaways">ğŸ¯ Key Takeaways</h2>
<ul>
<li><strong>Donâ€™t train your own LLM</strong> â†’ use <strong>RAG + search</strong> to build assistants on private data.</li>
<li><strong>Elasticsearch</strong> is a powerful vector DB for semantic + hybrid search.</li>
<li><strong>PHP + Elephant</strong> makes building RAG chatbots accessible for web developers.</li>
<li>RAG powers most modern chat assistants today.</li>
</ul>
<hr>


    
    <div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
      <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/qDFct7oeRss?autoplay=0&controls=1&end=0&loop=0&mute=0&start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video"
      ></iframe>
    </div>

]]></content:encoded>
    </item>
  </channel>
</rss>

<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Elastic on ashish.one</title>
    <link>https://ashish.one/tags/elastic/</link>
    <description>Recent content in Elastic on ashish.one</description>
    <image>
      <url>https://www.gravatar.com/avatar/dcb52889deff3e5017a18de40c57add8?s=200</url>
      <link>https://www.gravatar.com/avatar/dcb52889deff3e5017a18de40c57add8?s=200</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 29 Apr 2022 01:24:55 +0530</lastBuildDate><atom:link href="https://ashish.one/tags/elastic/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Parsing Custom log format to the Elasticsearch</title>
      <link>https://ashish.one/blogs/parsing-custom-log-format-to-the-elasticsearch/</link>
      <pubDate>Fri, 29 Apr 2022 01:24:55 +0530</pubDate>
      
      <guid>https://ashish.one/blogs/parsing-custom-log-format-to-the-elasticsearch/</guid>
      <description>Introduction As a developer, you need to log everything it may be info, error or debug logs, etc. There are multiple types of log formats like Common log, JSON log, etc. and there are already solutions available in an elastic stack like filebeat to read JSON logs and push them to elasticsearch.
There can be cases where you need to log the data according to your convenience which will not be any standard log format.</description>
    </item>
    
    <item>
      <title>[Part -1] Search as you type</title>
      <link>https://ashish.one/blogs/search-as-you-type/</link>
      <pubDate>Fri, 18 Mar 2022 01:24:55 +0530</pubDate>
      
      <guid>https://ashish.one/blogs/search-as-you-type/</guid>
      <description>Introduction In this blog, we will try to understand how “Search as you type” works and Quickly setup one demo using some sample data. You must have seen various websites like eCommerce, food apps, etc. where you just start typing &amp;amp; simultaneously relevant options start displaying as suggestions and autocomplete. We will try to achieve somewhat the same feature. Search as you type Elasticsearch gives this specific mapping type which you can simply set to a specific field where you want to perform this kind of search.</description>
    </item>
    
    <item>
      <title>Deploy Elasicsearch on Azure cloud</title>
      <link>https://ashish.one/talks/deploy_elastic_on_azure/</link>
      <pubDate>Sat, 29 Jan 2022 19:24:45 +0000</pubDate>
      
      <guid>https://ashish.one/talks/deploy_elastic_on_azure/</guid>
      <description>Introduction What this talk is all about ? The purpose of the talk is to give a short overview of Elastic solutions &amp;amp; Elastic stacks. In the demo shown, how you can deploy elasticsearch instance on Microsoft Azure.
Also, it gives an idea to use the elastic cloud to manage the elasticsearch instance which deployed on the Azure cloud. You can also create deployment on elastic cloud (cloud.elastic.co).
In the demo, Successfully shipped the metric data of the local system (my MacBook) to the newly deployed elasticsearch instance and explored the dashboard on kibana.</description>
    </item>
    
    <item>
      <title>Shipping Golang logs with ELKB stack</title>
      <link>https://ashish.one/blogs/shipping-golang-logs-with-elkb-stack/</link>
      <pubDate>Sat, 06 Jun 2020 23:31:33 +0530</pubDate>
      
      <guid>https://ashish.one/blogs/shipping-golang-logs-with-elkb-stack/</guid>
      <description>Goal of this blog In this blog, I am going to show you how easily we can write logs to the files in Golang. As well as we are going to store all logs on elasticsearch with EKB (Elasticsearch, Kibana, Beats).
Why ELKB stack ? Logs are very important for debugging, reporting, insights etc. In today&amp;rsquo;s tech world, We uses multiple cloud servers, private servers etc. Which consist of lots of different applications, scripts, programs, daemons, services and they generate their logs too.</description>
    </item>
    
    <item>
      <title>How to scale with massive update queries in Elasticsearch?</title>
      <link>https://ashish.one/talks/scale-with-massive-updates-queries-in-elasticsearch/</link>
      <pubDate>Sun, 08 Dec 2019 20:26:06 +0530</pubDate>
      
      <guid>https://ashish.one/talks/scale-with-massive-updates-queries-in-elasticsearch/</guid>
      <description>Introduction What this talk is all about? We recently moved from MySQL to Elasticsearch where we got a direct 10x - 15x boost in our performance.
We came up with unique use cases of heavy updates in Elasticsearch. That been challenging but yes currently Our Elaticsearch handling 200 million requests per day very efficiently. Our WRITE consist of the partial update, update with script conditions and of course simple indexing.</description>
    </item>
    
    <item>
      <title>Elasticsearch Exceptions &amp; Challenges</title>
      <link>https://ashish.one/gist/elasticsearch-exceptions-and-challenges/</link>
      <pubDate>Tue, 03 Dec 2019 02:47:28 +0530</pubDate>
      
      <guid>https://ashish.one/gist/elasticsearch-exceptions-and-challenges/</guid>
      <description>Below are some challenges &amp;amp; exceptions faced while setting up Elasticsearch. I just shared my experience and learning. Please correct me, If you guys feel somewhere i got wrong OR You can contribute if you have any experiences . Will keep update this gist.
 Every use case having different solutions. You can try accordingly.</description>
    </item>
    
    <item>
      <title>What should be the value of max_gram and min_gram in Elasticsearch?</title>
      <link>https://ashish.one/blogs/min-gram-and-max-gram-elasticsearch/</link>
      <pubDate>Sun, 22 Sep 2019 15:20:39 +0530</pubDate>
      
      <guid>https://ashish.one/blogs/min-gram-and-max-gram-elasticsearch/</guid>
      <description>I was working on elasticsearch and the requirement was to implement like query “%text%” ( like mysql %like% ). We could use wildcard, regex or query string but those are slow. Hence i took decision to use ngram token filter for like query. It was quickly implemented on local and works exactly i want.
The problem To know the actual behavior, I implemented the same on staging server. I found some problem while we start indexing on staging.</description>
    </item>
    
  </channel>
</rss>

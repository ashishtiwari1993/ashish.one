<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Llm on ashish.one</title>
    <link>https://ashish.one/tags/llm/</link>
    <description>Recent content in Llm on ashish.one</description>
    <image>
      <title>ashish.one</title>
      <url>https://ashish.one/img/speaker-pic/ashish.png</url>
      <link>https://ashish.one/img/speaker-pic/ashish.png</link>
    </image>
    <generator>Hugo -- 0.136.4</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 25 Aug 2025 12:09:27 +0530</lastBuildDate>
    <atom:link href="https://ashish.one/tags/llm/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Hybrid Search Done Right: Stop Calling Metadata Filters &#34;Hybrid&#34;</title>
      <link>https://ashish.one/blogs/elastic/true-hybrid-search/</link>
      <pubDate>Mon, 25 Aug 2025 12:09:27 +0530</pubDate>
      <guid>https://ashish.one/blogs/elastic/true-hybrid-search/</guid>
      <description>&lt;h1 id=&#34;hybrid-search-done-right-stop-calling-metadata-filters-hybrid&#34;&gt;Hybrid Search Done Right: Stop Calling Metadata Filters &amp;ldquo;Hybrid&amp;rdquo;&lt;/h1&gt;
&lt;p&gt;Everyone’s talking about &lt;strong&gt;hybrid search&lt;/strong&gt; right now.
But here’s the uncomfortable truth:&lt;/p&gt;
&lt;p&gt;👉 Just because you glued vector search onto your database and added metadata filters doesn’t mean you’ve built &lt;em&gt;true&lt;/em&gt; hybrid search.&lt;/p&gt;
&lt;p&gt;That’s like duct-taping a spoiler on a hatchback and calling it a race car. 🚗💨&lt;/p&gt;
&lt;p&gt;Hybrid search is more than just “keyword + vector + filter.”
It’s about &lt;strong&gt;field-level design, reranking, scoring, and scale&lt;/strong&gt;.&lt;/p&gt;</description>
      <content:encoded><![CDATA[<h1 id="hybrid-search-done-right-stop-calling-metadata-filters-hybrid">Hybrid Search Done Right: Stop Calling Metadata Filters &ldquo;Hybrid&rdquo;</h1>
<p>Everyone’s talking about <strong>hybrid search</strong> right now.
But here’s the uncomfortable truth:</p>
<p>👉 Just because you glued vector search onto your database and added metadata filters doesn’t mean you’ve built <em>true</em> hybrid search.</p>
<p>That’s like duct-taping a spoiler on a hatchback and calling it a race car. 🚗💨</p>
<p>Hybrid search is more than just “keyword + vector + filter.”
It’s about <strong>field-level design, reranking, scoring, and scale</strong>.</p>
<p>Let’s break this down.</p>
<hr>
<h2 id="field-level-truth-not-every-field-deserves-semantic-search">Field-Level Truth: Not Every Field Deserves Semantic Search</h2>
<p>The biggest mistake I see:
Teams running semantic + lexical search on <em>every</em> field in their JSON docs.</p>
<p>That’s how you kill relevance.</p>
<h3 id="lexical-only-fields">Lexical-Only Fields</h3>
<p>These work best with exact match:</p>
<ul>
<li><code>title</code></li>
<li><code>name</code></li>
<li><code>issue_id</code></li>
<li><code>category</code></li>
<li><code>tags</code></li>
</ul>
<p>If I search for <code>issue_id: 1245</code>, I want <strong>1245</strong> — not “similar looking IDs.”</p>
<h3 id="semantic-only-fields">Semantic-Only Fields</h3>
<p>These benefit from embeddings:</p>
<ul>
<li><code>product_description</code></li>
<li><code>movie_storyline</code></li>
<li><code>customer_feedback</code></li>
<li><code>reviews</code></li>
</ul>
<p>This is where meaning &gt; keywords.
“Battery dies too quickly” should match with “poor battery life.”</p>
<h3 id="the-formula-that-works">The Formula That Works</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>Final Score = RRF(
</span></span><span style="display:flex;"><span>   Lexical(title, name, category) +
</span></span><span style="display:flex;"><span>   Semantic(description, feedback, reviews)
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><p>Hybrid works when <strong>each field is treated for what it is</strong>.</p>
<h3 id="quick-reference-table">Quick Reference Table</h3>
<table>
  <thead>
      <tr>
          <th>Field Type</th>
          <th>Example Fields</th>
          <th>Best Search Method</th>
          <th>Why?</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Metadata / Identifiers</td>
          <td><code>id</code>, <code>issue_id</code>, <code>category</code></td>
          <td>Lexical</td>
          <td>Needs exact matching, filtering</td>
      </tr>
      <tr>
          <td>Structured Short Text</td>
          <td><code>title</code>, <code>name</code>, <code>tags</code></td>
          <td>Lexical</td>
          <td>Precision &gt; meaning</td>
      </tr>
      <tr>
          <td>Unstructured Text</td>
          <td><code>description</code>, <code>reviews</code></td>
          <td>Semantic</td>
          <td>Context + meaning matter</td>
      </tr>
  </tbody>
</table>
<hr>
<h2 id="metadata-filters-keep-them-lexical">Metadata Filters: Keep Them Lexical</h2>
<p>One of the biggest anti-patterns: vectorizing filters.</p>
<p>Filters are not semantic. They should remain <strong>exact</strong>.</p>
<ul>
<li>Price → numeric filters</li>
<li>Stock availability → boolean</li>
<li>Categories, IDs → keyword</li>
<li>Timestamps, geo → structured fields</li>
</ul>
<p>Search is about <em>precision here</em>. If you fuzzy up filters with embeddings, you’ll tank user trust.</p>
<hr>
<h2 id="hybrid--metadata-filters--vectors">Hybrid ≠ Metadata Filters + Vectors</h2>
<p>Here’s the thing. Some vector DBs shout <em>“we support keyword search now!”</em>
But if you look closer, it’s often:</p>
<ul>
<li>A bolted-on library</li>
<li>Or patched-in metadata filters</li>
</ul>
<p>Yeah, technically it works.
But <strong>that’s not hybrid</strong>.</p>
<p>Search is not just filters.</p>
<hr>
<h2 id="what-real-hybrid-search-looks-like">What Real Hybrid Search Looks Like</h2>
<p>Let’s talk the real stuff beyond filters + vectors:</p>
<ul>
<li><strong>Autocomplete</strong> — search-as-you-type, phrase suggesters, boosting, user-friendly completion.</li>
<li><strong>Facets</strong> — powerful aggregations: geo boundaries, date histograms, bucketing. Not just string counts.</li>
<li><strong>Native rescoring</strong> — query rescorer, rank features, boosting for freshness, popularity, personalization.</li>
<li><strong>Rich documents</strong> — nested JSON, arrays, geo points, IPs. Search isn’t flat.</li>
<li><strong>Geo Search</strong> — aggregations, polygons, proximity scoring. Beyond just “in radius.”</li>
<li><strong>Access control</strong> — index → document → field level security. For lexical <strong>and</strong> vector fields.</li>
<li><strong>Data enrichment pipelines</strong> — entity extraction, tagging, embeddings, LLM-based enrichment.</li>
<li><strong>Scalability</strong> — petabytes of data, tiered storage, lifecycle management. Search doesn’t stop at 10M docs.</li>
</ul>
<p>This is hybrid.</p>
<hr>
<h2 id="vectors-ask-the-hard-questions">Vectors: Ask the Hard Questions</h2>
<p>Not all vector support is equal. Check:</p>
<ul>
<li>Is vector search <strong>native to the engine</strong> or bolted on?</li>
<li>Query types: KNN, ANN, hybrid filtering?</li>
<li>Can it run at scale with good recall + low latency?</li>
<li>Quantization: int4, int8, binary, advanced methods like <strong>BBQ (Better Binary Quantization)</strong>?</li>
<li>Filters on HNSW: is it pre-filtering or filter-aware indexing (like ACORN)?</li>
<li>Can it blend semantic + lexical scoring at query time?
<ul>
<li>RRF (Reciprocal Rank Fusion)</li>
<li>Linear retrievers</li>
<li>Semantic reranking with LLMs</li>
</ul>
</li>
</ul>
<p>If your engine can’t do these, it’s not serious about hybrid.</p>
<hr>
<h2 id="implementation-note-one-query-should-do-it">Implementation Note: One Query Should Do It</h2>
<p>If you need to stitch 3–4 services together just to get:</p>
<ul>
<li>Facets</li>
<li>Filters</li>
<li>Semantic results</li>
<li>Lexical results</li>
<li>Reranking</li>
</ul>
<p>…you’re adding <strong>latency + complexity</strong>.</p>
<p>A true hybrid engine should give you everything in <strong>one structured query</strong>.</p>
<hr>
<h2 id="practical-takeaways">Practical Takeaways</h2>
<ol>
<li><strong>Not all fields deserve semantic.</strong> Treat fields differently.</li>
<li><strong>Filters are lexical.</strong> Stop semantic-izing metadata.</li>
<li><strong>Hybrid = lexical + semantic + rescoring + scale.</strong> Not just bolted-on keyword support.</li>
<li><strong>Evaluate vectors deeply.</strong> Native support, quantization, filtering, reranking.</li>
<li><strong>One query &gt; stitched services.</strong> Hybrid done right = clean pipeline, low latency.</li>
</ol>
<hr>
<h2 id="closing-thoughts">Closing Thoughts</h2>
<p>Hybrid search is not a checkbox.
It’s about designing for <strong>relevance + scale + control</strong>.</p>
<p>If your “hybrid” is just vectors + filters, you’ve built a demo — not a real search engine.</p>
<p>True hybrid is <strong>Lexical + Semantic + Scoring + Access + Scale + Control</strong>.
That’s when search feels natural, accurate, and production-ready.</p>
<hr>
]]></content:encoded>
    </item>
    <item>
      <title>Elasticsearch: Vector and Hybrid Search</title>
      <link>https://ashish.one/talks/vector-hybrid-search/</link>
      <pubDate>Tue, 29 Aug 2023 21:41:03 +0530</pubDate>
      <guid>https://ashish.one/talks/vector-hybrid-search/</guid>
      <description>&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Search is not just traditional TF/IDF any more but the current trend of machine learning and models has opened another dimension for search.&lt;/p&gt;
&lt;p&gt;This talk gives an overview of:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Classic&lt;/strong&gt; search and its limitations.&lt;/li&gt;
&lt;li&gt;What is a model and how can you use it.&lt;/li&gt;
&lt;li&gt;How to use vector search or hybrid search in Elasticsearch.&lt;/li&gt;
&lt;li&gt;Where OpenAI&amp;rsquo;s ChatGPT or similar LLMs come into play to with Elastic.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Check how to leverage &lt;a href=&#34;https://ashish.one/talks/chatgpt-elasticsearch/&#34;&gt;Leverage ChatGPT with Elasticsearch&lt;/a&gt;.&lt;/p&gt;</description>
      <content:encoded><![CDATA[<h1 id="introduction">Introduction</h1>
<p>Search is not just traditional TF/IDF any more but the current trend of machine learning and models has opened another dimension for search.</p>
<p>This talk gives an overview of:</p>
<ul>
<li><strong>Classic</strong> search and its limitations.</li>
<li>What is a model and how can you use it.</li>
<li>How to use vector search or hybrid search in Elasticsearch.</li>
<li>Where OpenAI&rsquo;s ChatGPT or similar LLMs come into play to with Elastic.</li>
</ul>
<p>Check how to leverage <a href="https://ashish.one/talks/chatgpt-elasticsearch/">Leverage ChatGPT with Elasticsearch</a>.</p>
<h2 id="talk-video">Talk Video</h2>


    
    <div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
      <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/AljarsLZRW0?autoplay=0&controls=1&end=0&loop=0&mute=0&start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video"
      ></iframe>
    </div>

]]></content:encoded>
    </item>
    <item>
      <title>Workshop - Leverage ChatGPT with Elasticsearch</title>
      <link>https://ashish.one/talks/chatgpt-elasticsearch/</link>
      <pubDate>Fri, 21 Jul 2023 15:52:06 +0530</pubDate>
      <guid>https://ashish.one/talks/chatgpt-elasticsearch/</guid>
      <description>Connect ChatGPT to proprietary data stores using Elasticsearch</description>
      <content:encoded><![CDATA[<h1 id="objective">Objective</h1>
<p>In this hands-on workshop, We will learn how to connect ChatGPT to proprietary data stores using Elasticsearch and build question/answer capabilities for your data. In a demo, We will quickly convert your website, FAQ, or any documentation into prompt chat where your user can directly ask a question on your data.</p>
<h1 id="flow">Flow</h1>
<p><img loading="lazy" src="/img/talks/elasticsearch-chatgpt/flow.png" alt="ChatGPT with Elasticsearch"  />
</p>
<h1 id="prerequisites">Prerequisites</h1>
<ol>
<li>
<p>You have used ChatGPT :)</p>
</li>
<li>
<p>Good to have understanding around Elasticsearch (Not mandatory, Introduction will be cover)</p>
</li>
<li>
<p>System + Internet connection</p>
</li>
<li>
<p>OpenAI account with API key - Create new one from <a href="https://platform.openai.com/account/api-keys">https://platform.openai.com/account/api-keys</a>. Make sure it having <a href="https://platform.openai.com/account/usage">free credits</a>.</p>
</li>
</ol>
<h2 id="without-local-setup">Without local setup</h2>
<ol>
<li>
<p>Google account to use <a href="https://colab.research.google.com/">google Colab</a>.</p>
</li>
<li>
<p><a href="https://render.com/">Render</a> account.</p>
</li>
</ol>
<h2 id="local-setup">Local setup</h2>
<ol>
<li>
<p>Git - Install it from <a href="https://git-scm.com/downloads">https://git-scm.com/downloads</a></p>
</li>
<li>
<p>Docker - Good to have. Install it from <a href="https://docs.docker.com/engine/install/">https://docs.docker.com/engine/install/</a>.</p>
</li>
<li>
<p>Having basic python knowledge will be good.</p>
</li>
</ol>
<p>For a workshop we going to follow without local setup.</p>
<h1 id="1-setup-cluster">1. Setup cluster</h1>
<ol>
<li>
<p>Visit <a href="https://cloud.elastic.co">cloud.elastic.co</a> and signup.</p>
</li>
<li>
<p>Click on <em><strong>Create deployment</strong></em>. In the pop-up, you can change the settings or leave it default.</p>
</li>
<li>
<p>We need to add machine learning instance. For that, simply click on &ldquo;<em><strong>advance settings</strong></em>&rdquo; .</p>
</li>
<li>
<p>Go to <em><strong>&ldquo;Machine Learning instances&rdquo; -&gt; click on &ldquo;Add Capacity&rdquo;</strong></em> and select at least <strong>4GB</strong> ram capacity.</p>
</li>
<li>
<p>Finally click on &ldquo;<em><strong>Create deployment</strong></em>&rdquo;.</p>
</li>
<li>
<p>Download / Copy the deployment credentials.</p>
</li>
<li>
<p>Once deployment ready, click on &ldquo;Continue&rdquo; (or click on <em><strong>Open Kibana</strong></em>). It will redirect you on kibana dashboard.</p>
</li>
</ol>
<h1 id="2-deploy-model">2. Deploy Model</h1>
<h2 id="elser-model-by-elastic-recommended">ELSER Model by Elastic (Recommended)</h2>
<p>Go to the kibana panel. Navigate to <em><strong>Menu -&gt; Machine Learning</strong></em> (In <em>Analytics</em> section). In left menu, Click on <em><strong>Trained Models</strong></em> (In <em>Model Management</em> Section).</p>
<ol>
<li>ELSER can be found in the list of trained models.</li>
<li>Click the <em><strong>Download model</strong></em> button under <em><strong>Actions</strong></em>.</li>
<li>After the download is finished, start the deployment by clicking the <em><strong>Start deployment</strong></em> button.</li>
<li>Provide a deployment ID, select the priority, and set the number of allocations and threads per allocation values.</li>
<li>Click <em><strong>Start</strong></em>.</li>
</ol>
<h2 id="third-party-model">Third party model</h2>
<p>We are going to use <a href="https://huggingface.co/sentence-transformers/all-distilroberta-v1">all-distilroberta-v1</a> model hosted on a hugging face. Lets import on an elastic cluster using eland.</p>
<p><strong>Get your credentials ready</strong></p>
<ul>
<li><code>cloud_id</code> : Visit “<em><strong><a href="https://cloud.elastic.co">cloud.elastic.co</a></strong></em>” -&gt; Navigate to your deployment and click on “<em><strong>manage</strong></em>”. Simply copy Cloud ID and save it.</li>
<li><code>cloud_user</code>: <code>elastic</code></li>
<li><code>cloud_password</code>: You will get it from step 1.6. If you forget to save, Simply click on <em><strong>“Action” -&gt; “Reset password”</strong></em>. (Username will be <code>elastic</code> only)</li>
<li><code>hf_model_id</code>: <code>sentence-transformers/all-distilroberta-v1</code> (Go to model <a href="https://huggingface.co/sentence-transformers/all-distilroberta-v1">page</a> on huggingface &amp; copy the ID <code>sentence-transformers/all-distilroberta-v1</code>)</li>
</ul>
<p>Now there is two way, You can upload the model using <code>docker</code> as well as <code>Google colab</code>.</p>
<h3 id="using-google-colab-recommended">Using Google Colab (Recommended)</h3>
<p>Simply click on below link. It will open ready made notebook. You just need to click on <code>play</code> button to run notebood.</p>
<p><a href="https://colab.research.google.com/github/ashishtiwari1993/elasticsearch-chatgpt/blob/main/load_model_eland.ipynb"><img loading="lazy" src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"  />
</a></p>
<h3 id="using-docker">Using Docker</h3>
<ol start="2">
<li>
<p>We’re going to use docker for import model to the elastic cluster</p>
<ol>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span> git clone https://github.com/elastic/eland.git 
</span></span><span style="display:flex;"><span> cd eland
</span></span></code></pre></div></li>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span> docker build -t elastic/eland .
</span></span></code></pre></div></li>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span> docker run -it --rm elastic/eland eland_import_hub_model <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>     --cloud-id &lt;cloud_id&gt; <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>     -u elastic -p &lt;elastic_cloud_password&gt; <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>     --hub-model-id sentence-transformers/all-distilroberta-v1 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>     --task-type text_embedding <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>     --start
</span></span></code></pre></div></li>
<li>
<p>Let&rsquo;s wait till the model gets uploaded without any error.</p>
</li>
<li>
<p>Exit from <code>eland</code> folder.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>cd ..
</span></span></code></pre></div></li>
</ol>
</li>
</ol>
<h3 id="verify-uploaded-model">Verify uploaded model</h3>
<p>Go to the kibana panel. Navigate to <em><strong>Menu -&gt; Machine Learning (In <code>Analytics</code> section)</strong></em>. In left menu, Click on <em><strong>Trained Models</strong></em>(<code>Model Management</code> Section). You must see your model here in the “<em><strong>Started</strong></em>” state.</p>
<p>In case if a warning message is displayed at the top of the page that says <em><strong>ML job and trained model synchronization required</strong></em>. Follow the link to <em><strong>Synchronize your jobs and trained models.</strong></em> Then click <em><strong>Synchronize</strong></em>.</p>
<h1 id="3-crawling-private-data">3. Crawling private data</h1>
<ol>
<li>Click on <em><strong>Menu -&gt; Enterprise Search -&gt; “Create an Elasticsearch index”</strong></em> button</li>
<li>Click on <em><strong>Web crawler</strong></em>.</li>
<li>Add index name (It will add prefix <em><strong>search</strong></em>) and  hit “<em><strong>Create index</strong></em>”. In my case index name is (search-ashish.one)</li>
<li>Go to “<em><strong>Pipelines</strong></em>” to create a pipeline.</li>
<li>Click “<em><strong>Copy and customize</strong></em>” in the Ingest Pipeline Box.</li>
<li>Click “<em><strong>Add Inference Pipeline</strong></em>” in the Machine Learning Inference Pipelines box.</li>
<li>Give the unique pipeline name e.g. “<em><strong>ml-inference-ashish-one</strong></em>”</li>
<li>Select a trained ML Model from the dropdown “<em><strong>sentence-transformers__all-distilroberta-v1</strong></em>” (For ELSER choose &ldquo;<em><strong>.elser_model_1</strong></em>&rdquo;)</li>
<li>Select “<em><strong>title</strong></em>” as the Source field and set “<em><strong>title-vector</strong></em>” as a destination. You can specify your own destination field name. (In case of ELSER, just select the &ldquo;<em><strong>Source</strong></em>&rdquo; field e.g <em>title, body_content</em>)</li>
<li>Let&rsquo;s click on “<em><strong>Continue</strong></em>” and move to the Test(Optional) tab.  Click on “<em><strong>Continue</strong></em>” again.</li>
<li>At the Review stage let&rsquo;s click on “<em><strong>Create pipeline</strong></em>”.</li>
<li>(Skip this for <em><strong>ELSER</strong></em>) Go to <em><strong>Menu -&gt; Management -&gt; Dev Tools</strong></em>. Let&rsquo;s create a mapping</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>POST &lt;index_name&gt;/_mapping
</span></span><span style="display:flex;"><span><span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;properties&#34;</span>: <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&lt;vector_field_name&gt;&#34;</span>: <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;dense_vector&#34;</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;dims&#34;</span>: 768,
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;index&#34;</span>: true,
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;similarity&#34;</span>: <span style="color:#e6db74">&#34;dot_product&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">}</span>
</span></span></code></pre></div><p>In my case mapping will be:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>POST search-ashish.one/_mapping
</span></span><span style="display:flex;"><span><span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;properties&#34;</span>: <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;title-vector&#34;</span>: <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;dense_vector&#34;</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;dims&#34;</span>: 768,
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;index&#34;</span>: true,
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;similarity&#34;</span>: <span style="color:#e6db74">&#34;dot_product&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">}</span>
</span></span></code></pre></div><p>Paste above query in <code>cosole</code> and hit on play button.</p>
<ol start="13">
<li>Go to <em><strong>Enterprise search -&gt; indices -&gt; your_index_name -&gt; Manage Domains</strong></em>. Enter the domain (e.g. <a href="https://ashish.one">https://ashish.one</a>. You can add your own domain) to crawl and hit “<em><strong>Validate Domain</strong></em>”.</li>
<li>If everything is fine, simply click on “<em><strong>Add domain</strong></em>” and start crawling by click on <em><strong>Crawl -&gt; Crawl all domains on this index</strong></em>.</li>
<li>Go to <em><strong>Enterprise Search -&gt; Indices</strong></em>. You should see your index name.</li>
</ol>
<h1 id="4-setup-interface">4. Setup Interface</h1>
<p>** Get your credentials ready **</p>
<ol>
<li><code>cloud_id</code> : Visit “<em><strong><a href="https://cloud.elastic.co">cloud.elastic.co</a></strong></em>” -&gt; Navigate to your deployment and click on “<em><strong>manage</strong></em>”. Simply copy Cloud ID and save it.</li>
<li><code>cloud_user</code>: elastic</li>
<li><code>cloud_password</code>: You will get it from step 1.6. If you forget to save, Simply click on <em><strong>“Action” -&gt; “Reset password”</strong></em>. (Username will be elastic)</li>
<li><code>openai_api</code>: Create open ai api key from <a href="https://platform.openai.com/account/api-keys">https://platform.openai.com/account/api-keys</a>.</li>
<li><code>es_index</code>: Index name which we created in step 3.3. (search-ashish.one)</li>
<li><code>vector_field</code>: The field which we&rsquo;ve set for destination at step 3.9. i.e. <strong>title-vector</strong></li>
</ol>
<h2 id="setup-on-local-with-docker">Setup on local with Docker</h2>
<ol>
<li>Clone</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>git clone https://github.com/ashishtiwari1993/elasticsearch-chatgpt.git
</span></span><span style="display:flex;"><span>cd elasticsearch-chatgpt
</span></span></code></pre></div><ol start="2">
<li>Replace credentials in <code>Dockerfile</code></li>
</ol>
<p>Open <code>Dockerfile</code> and change below creds</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>ENV openai_api<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&lt;open_api_key&gt;&#34;</span>
</span></span><span style="display:flex;"><span>ENV cloud_id<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&lt;elastic cloud id&gt;&#34;</span>
</span></span><span style="display:flex;"><span>ENV cloud_user<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;elastic&#34;</span>
</span></span><span style="display:flex;"><span>ENV cloud_pass<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&lt;elastic_cloud_password&gt;&#34;</span>
</span></span><span style="display:flex;"><span>ENV es_index<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&lt;elasticsearch_index_name&gt;&#34;</span>
</span></span><span style="display:flex;"><span>ENV chat_title<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&lt;Any title for your page e.g. ashish.one GPT&gt;&#34;</span>
</span></span><span style="display:flex;"><span>ENV vector_field<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&lt; specify vector field where embedding will be save. e.g. title-vector&gt;&#34;</span>
</span></span></code></pre></div><ol start="3">
<li>Build</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>docker build -t es-gpt .
</span></span></code></pre></div><ol start="4">
<li>Run</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>docker run -p 8501:8501 es-gpt
</span></span></code></pre></div><p>Simply visit on <a href="!http://localhost:8501">localhost:8501</a></p>
<h2 id="setup-on-renderhttpsrendercom-with-docker">Setup on <a href="https://render.com/">Render</a> with Docker</h2>
<ol>
<li>
<p>Signup on <a href="https://render.com">https://render.com</a>.</p>
</li>
<li>
<p>Create <strong>Web Service</strong>.</p>
</li>
<li>
<p>Go to <strong>Public Git repository</strong> section and add below repo url</p>
</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>https://github.com/ashishtiwari1993/elasticsearch-chatgpt
</span></span></code></pre></div><p>Hit on <strong>Continue</strong>.</p>
<ol start="4">
<li>
<p>Add <strong>Name</strong> and select <strong>Free</strong> Instance Type.</p>
</li>
<li>
<p>Click on <strong>Advanced</strong> and <strong>Add Environment Variable</strong></p>
</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>openai_api<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&lt;open_api_key&gt;&#34;</span>
</span></span><span style="display:flex;"><span>cloud_id<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&lt;elastic cloud id&gt;&#34;</span>
</span></span><span style="display:flex;"><span>cloud_user<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;elastic&#34;</span>
</span></span><span style="display:flex;"><span>cloud_pass<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&lt;elastic_cloud_password&gt;&#34;</span>
</span></span><span style="display:flex;"><span>es_index<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&lt;elasticsearch_index_name&gt;&#34;</span>                                                 
</span></span><span style="display:flex;"><span>chat_title<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&lt;Any title for your page e.g. ashish.one GPT&gt;&#34;</span>
</span></span><span style="display:flex;"><span>vector_field<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&lt; specify vector field where embedding will be save. e.g. title-vector&gt;&#34;</span>
</span></span></code></pre></div><ol start="6">
<li>Finally click on <strong>Create Web Service</strong></li>
</ol>
<h2 id="output">Output</h2>
<p><img loading="lazy" src="/img/talks/elasticsearch-chatgpt/ashish_one_gpt.gif" alt="ashish.one ChatGPT"  />
</p>
<h1 id="reference">Reference</h1>
<p><a href="https://www.elastic.co/blog/chatgpt-elasticsearch-openai-meets-private-data">Blog - ChatGPT and Elasticsearch: OpenAI meets private data</a></p>
]]></content:encoded>
    </item>
  </channel>
</rss>

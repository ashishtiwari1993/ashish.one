<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blogs on ashish.one</title>
    <link>https://ashish.one/blogs/</link>
    <description>Recent content in Blogs on ashish.one</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 07 Jan 2022 07:20:29 +0530</lastBuildDate><atom:link href="https://ashish.one/blogs/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Arch Linux Installation Challenges</title>
      <link>https://ashish.one/blogs/arch-linux-installation-challenges/</link>
      <pubDate>Fri, 07 Jan 2022 07:20:29 +0530</pubDate>
      
      <guid>https://ashish.one/blogs/arch-linux-installation-challenges/</guid>
      <description>Introduction This article is not containing the detailed procedure for installation but listed some challenges which you can face while installing the arch Linux. Arch Linux is one of the Linux distributions, Which gives you full control over your application and OS. You have complete freedom to install or what to keep. Unlike the other distribution like Ubuntu, Centos, etc. It doesn&amp;rsquo;t come with pre-loaded applications or software.
Though Arch wiki has a detailed explanation of the installation process I faced some challenges whose solution was not easily available.</description>
    </item>
    
    <item>
      <title>Get start with BugBounty, Pentest and Security Researcher</title>
      <link>https://ashish.one/blogs/get-start-with-bugbounty-pentest-security-researcher/</link>
      <pubDate>Sun, 20 Jun 2021 13:53:50 +0530</pubDate>
      
      <guid>https://ashish.one/blogs/get-start-with-bugbounty-pentest-security-researcher/</guid>
      <description>I have always been in confusion about how to get started with security or pentest or somehow with a bug bounty. There are tons of resources available on the internet.
The Fact The fact is there is no hard and fast rule or there is no standard course by following which you will get the tag of a security expert.
 There is no defined way to become a security researcher.</description>
    </item>
    
    <item>
      <title>Shipping Golang logs with ELKB stack</title>
      <link>https://ashish.one/blogs/shipping-golang-logs-with-elkb-stack/</link>
      <pubDate>Sat, 06 Jun 2020 23:31:33 +0530</pubDate>
      
      <guid>https://ashish.one/blogs/shipping-golang-logs-with-elkb-stack/</guid>
      <description>Goal of this blog In this blog, I am going to show you how easily we can write logs to the files in Golang. As well as we are going to store all logs on elasticsearch with EKB (Elasticsearch, Kibana, Beats).
Why ELKB stack ? Logs are very important for debugging, reporting, insights etc. In today&amp;rsquo;s tech world, We uses multiple cloud servers, private servers etc. Which consist of lots of different applications, scripts, programs, daemons, services and they generate their logs too.</description>
    </item>
    
    <item>
      <title>[Part 1] Setup LEMP environment with Docker - Setup Nginx and PHP</title>
      <link>https://ashish.one/blogs/part-1-setup-lemp-environment-with-docker-setup-nginx-and-php/</link>
      <pubDate>Sat, 16 May 2020 17:01:47 +0530</pubDate>
      
      <guid>https://ashish.one/blogs/part-1-setup-lemp-environment-with-docker-setup-nginx-and-php/</guid>
      <description>Hi guys, In this series, we are going to setup LEMP Stack (Linux, Nginx, MySQL, PHP). Mainly it is used by web developers. I am assuming you have a basic idea about Docker &amp;amp; How it works.
In this blog, We are going to setup PHP and Nginx.
Why Docker? I will not go too much deep, You can find more resources over the internet about the docker.
Docker makes the installation process very smooth and it gives your isolated environment as the container.</description>
    </item>
    
    <item>
      <title>Challenges in linuxfromscratch</title>
      <link>https://ashish.one/blogs/challenges-in-linuxfromscratch/</link>
      <pubDate>Sat, 11 Apr 2020 13:55:52 +0530</pubDate>
      
      <guid>https://ashish.one/blogs/challenges-in-linuxfromscratch/</guid>
      <description>I have started with www.linuxfromscratch.org, I am facing some challenges and problems which I am going to share with you in this blog. I will keep updating this blog as well as I move forward.
Before we get start You need some basic linux command knowledge to use linuxfromscratch guide. I am going to build LFS on my local machine. If your machine has a different OS or different configuration, Then some solution will not work.</description>
    </item>
    
    <item>
      <title>[Part 4] Setup Grafana With Prometheus</title>
      <link>https://ashish.one/blogs/setup-grafana-with-prometheus/</link>
      <pubDate>Fri, 03 Apr 2020 21:32:48 +0530</pubDate>
      
      <guid>https://ashish.one/blogs/setup-grafana-with-prometheus/</guid>
      <description>As you know Prometheus already having UI (localhost:9090). But it is not enough to give you better visualization on one screen. For better visualization and a graphical representation, we are going to use Grafana.
What is Grafana? As grafana.com says
 ”Grafana is the open-source analytics and monitoring solution for every database.”
 This means Grafana is an independent tool for analytics and monitor which gives your various types of Graphs.</description>
    </item>
    
    <item>
      <title>Install python3.6, pip3.6, pipenv on  Ubuntu 14.04 LTS</title>
      <link>https://ashish.one/blogs/install-python3.6-pip3.6-pipenv-on-ubuntu14.04/</link>
      <pubDate>Thu, 02 Apr 2020 17:52:19 +0530</pubDate>
      
      <guid>https://ashish.one/blogs/install-python3.6-pip3.6-pipenv-on-ubuntu14.04/</guid>
      <description>Prerequisite OS: Ubuntu 14.04 LTS
Processor: 64 Bit
RAM: 2 GB
1. Install python3.6 From source Step 1.1: Compile $ wget https://www.python.org/ftp/python/3.6.3/Python-3.6.3.tgz $ tar -xvf Python-3.6.3.tgz $ cd Python-3.6.3 $ sudo ./configure --enable-optimizations Step 1.2: Check $ python3.6 --version 2. Install pip3.6 Step 2.1: Download pip $ wget https://bootstrap.pypa.io/get-pip.py Step 2.2: Execute $ sudo python3.6 get-pip.py Step 2.3: If you Got below error Error zlib not available Traceback (most recent call last): File &amp;#34;get-pip.</description>
    </item>
    
    <item>
      <title>Covid19 Data Source for India &amp; Global</title>
      <link>https://ashish.one/blogs/covid19-data-source-and-endpoints-india-global/</link>
      <pubDate>Fri, 27 Mar 2020 20:04:13 +0530</pubDate>
      
      <guid>https://ashish.one/blogs/covid19-data-source-and-endpoints-india-global/</guid>
      <description>Hi Guys, I am trying to listing all data source &amp;amp; endpoints for COVID19 - India as well as Global. It can contains offical or unofficial APIs. Anyone is working on any COVID19 project for India, Can use these sources.
APIs 1. Github: amodm/api-covid19-in (India) Repo: https://github.com/amodm/api-covid19-in APIs available: Statewise Data  StateWise StateWise History  Medica  Hospital Stats Bed Stats  Contacts  HelpLines Contacts  Patient  Tracing History  Sources The source is both types of official &amp;amp; Unofficial.</description>
    </item>
    
    <item>
      <title>[SOLVED] Golang fatal error: concurrent map writes</title>
      <link>https://ashish.one/blogs/fatal-error-concurrent-map-writes/</link>
      <pubDate>Tue, 04 Feb 2020 01:14:03 +0530</pubDate>
      
      <guid>https://ashish.one/blogs/fatal-error-concurrent-map-writes/</guid>
      <description>The Problem: Suddenly got below errors which killed my daemon:
fatal error: concurrent map writes goroutine 646 [running]: runtime.throw(0x75fd38, 0x15) /usr/local/go/src/runtime/panic.go:774 +0x72 fp=0xc000315e60 sp=0xc000315e30 pc=0x42ecf2 runtime.mapdelete_fast64(0x6f0800, 0xc00008ad50, 0x2b3e) goroutine 1 [sleep]: runtime.goparkunlock(...) /usr/local/go/src/runtime/proc.go:310 time.Sleep(0x12a05f200) /usr/local/go/src/runtime/time.go:105 +0x157 webhook/worker.Manager() goroutine 6 [IO wait]: internal/poll.runtime_pollWait(0x7fc308de6f08, 0x72, 0x0) /usr/local/go/src/runtime/netpoll.go:184 +0x55 internal/poll.(*pollDesc).wait(0xc000110018, 0x72, 0x0, 0x0, 0x75b00b) /usr/local/go/src/internal/poll/fd_poll_runtime.go:87 +0x45 internal/poll.(*pollDesc).waitRead(...) /usr/local/go/src/internal/poll/fd_poll_runtime.go:92 internal/poll.(*FD).Accept(0xc000110000, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0) /usr/local/go/src/internal/poll/fd_unix.go:384 +0x1f8 net.(*netFD).accept(0xc000110000, 0xc000050d50, 0xc000046700, 0x7fc308e426d0) /usr/local/go/src/net/fd_unix.go:238 +0x42 net.</description>
    </item>
    
    <item>
      <title>How to reset 1-Click Installed WordPress on DigitalOcean?</title>
      <link>https://ashish.one/blogs/how-to-reset-1-click-installed-wordpress-on-digitalocean/</link>
      <pubDate>Tue, 03 Dec 2019 00:49:07 +0530</pubDate>
      
      <guid>https://ashish.one/blogs/how-to-reset-1-click-installed-wordpress-on-digitalocean/</guid>
      <description>The Requirement Need to install fresh wordpress with same version on wordpress droplet of digitalocean.
The Problem My setup (wordpress droplet) was suddenly stop working. I started debugging.
Debug Checked apache2 and mysql service:
service mysql status service apache2 status Both services was active. Then I checked the apache2 processes with below command:
$ ps -ef | grep apache2 | wc -l 151 Lots of apache child process has been forked.</description>
    </item>
    
    <item>
      <title>[Part 3] How to write custom prometheus exporter?</title>
      <link>https://ashish.one/blogs/write-custom-exporters-prometheus/</link>
      <pubDate>Fri, 29 Nov 2019 22:51:27 +0530</pubDate>
      
      <guid>https://ashish.one/blogs/write-custom-exporters-prometheus/</guid>
      <description>Introduction In PART-1 and PART-2, We have seen how prometheus works and how to setup Prometheus and exporters. We have readymade exporters available on the internet.
But sometime there is situation where you need to store your own custom metrics on prometheus. In such case you have to write your own exporters which will exporters the data into Prometheus.
There is two way to exporting the data on prometheus: 1. Exporting to a Pushgateway Here we metrics are getting the push to prometheus server.</description>
    </item>
    
    <item>
      <title>[Part 2] How to setup alertmanager and send alerts ?</title>
      <link>https://ashish.one/blogs/setup-alertmanager/</link>
      <pubDate>Wed, 23 Oct 2019 15:24:26 +0530</pubDate>
      
      <guid>https://ashish.one/blogs/setup-alertmanager/</guid>
      <description>Introduction In PART - 1, We have successfully setup Prometheus and exporters. In this part, we are going to setup alertmanager and will send our first alert.
Alertmanager is software that is maintained by the prometheus and it is written in Go. It takes care of deduplicating, grouping, and routing them to the correct receiver integration such as email, PagerDuty, or OpsGenie. It also takes care of silencing and inhibition of alerts.</description>
    </item>
    
    <item>
      <title>[Part 1] How To Setup Prometheus And Exporters For Alerts And Monitoring?</title>
      <link>https://ashish.one/blogs/setup-prometheus-and-exporters/</link>
      <pubDate>Sun, 22 Sep 2019 15:20:39 +0530</pubDate>
      
      <guid>https://ashish.one/blogs/setup-prometheus-and-exporters/</guid>
      <description>As a developer, many times you would have worried, whether your services are up and running or not. Not only that, sometimes as an infrastructure guy you might be also worried about your server’s health too. What is the current RAM or disk utilization? or whether they are going to be fully occupied which in turn can completely bring the system down. These are just the basics and in fact there are tons of more such things which need to be monitored and fixed in everyday&amp;rsquo;s life.</description>
    </item>
    
    <item>
      <title>What should be the value of max_gram and min_gram in Elasticsearch?</title>
      <link>https://ashish.one/blogs/min-gram-and-max-gram-elasticsearch/</link>
      <pubDate>Sun, 22 Sep 2019 15:20:39 +0530</pubDate>
      
      <guid>https://ashish.one/blogs/min-gram-and-max-gram-elasticsearch/</guid>
      <description>I was working on elasticsearch and the requirement was to implement like query “%text%” ( like mysql %like% ). We could use wildcard, regex or query string but those are slow. Hence i took decision to use ngram token filter for like query. It was quickly implemented on local and works exactly i want.
The problem To know the actual behavior, I implemented the same on staging server. I found some problem while we start indexing on staging.</description>
    </item>
    
  </channel>
</rss>

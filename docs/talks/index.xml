<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Talks on ashish.one</title>
    <link>https://ashish.one/talks/</link>
    <description>Recent content in Talks on ashish.one</description>
    <image>
      <title>ashish.one</title>
      <url>https://www.gravatar.com/avatar/dcb52889deff3e5017a18de40c57add8?s=200</url>
      <link>https://www.gravatar.com/avatar/dcb52889deff3e5017a18de40c57add8?s=200</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 01 Feb 2024 10:54:52 +0530</lastBuildDate><atom:link href="https://ashish.one/talks/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Elasticsearch Query Language (ES|QL)</title>
      <link>https://ashish.one/talks/esql/</link>
      <pubDate>Thu, 01 Feb 2024 10:54:52 +0530</pubDate>
      
      <guid>https://ashish.one/talks/esql/</guid>
      <description>Introduction ES|QL is a new query language for Elasticsearch. It is the unified language for all kinds of use cases like simple queries, aggregations, performing correlations, finding logs, etc. It provides simple easy syntax to perform complex queries. If you come from SQL background, You going to find this very handy.
It is a piped separated langugage with a combination of source commands and process commands. The Elasticsearch Query Language (ES|QL) makes use of &amp;ldquo;pipes&amp;rdquo; (|) to manipulate and transform data in a step-by-step fashion.</description>
      <content:encoded><![CDATA[<h2 id="introduction">Introduction</h2>
<p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/esql.html" target="_blank" rel="noopener">ES|QL</a>
 is a new query language for Elasticsearch. It is the unified language for all kinds of use cases like simple queries, aggregations, performing correlations, finding logs, etc. It provides simple easy syntax to perform complex queries. If you come from SQL background, You going to find this very handy.</p>
<p>It is a piped separated langugage with a combination of <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/esql-commands.html#esql-source-commands" target="_blank" rel="noopener">source commands</a>
 and <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/esql-commands.html#esql-processing-commands" target="_blank" rel="noopener">process</a>
 commands. The Elasticsearch Query Language (ES|QL) makes use of &ldquo;pipes&rdquo; (|) to manipulate and transform data in a step-by-step fashion. This means output of the first step will go as an input for second step.</p>
<p>ES|QL is more than langugage. The execution engine is developed by considering performance in mind. Here ES|QL is not going to convert into Query DSL instead it will be directly executed within Elasticsearch. It operates on blocks at a time instead of per row, targets vectorization and cache locality, and embraces specialization and multi-threading.</p>
<blockquote>
<p>ES|QL - Filter, Transform and Analyze</p>
</blockquote>
<h2 id="example">Example</h2>
<p>Below is a few examples of ES|QL. I am considering you have an Elasticsearch and kibana is <a href="https://www.elastic.co/search-labs/tutorials/install-elasticsearch" target="_blank" rel="noopener">installed</a>
 and running. Please <a href="https://www.elastic.co/guide/en/kibana/current/get-started.html#gs-get-data-into-kibana" target="_blank" rel="noopener">import the sample dataset (Sample web logs)</a>
 from kibana. Navigate in side menu  -&gt; <code>Management</code> -&gt; <code>Dev Tools</code>  to perform the below query.</p>
<h3 id="source-commands">Source commands</h3>
<h4 id="from">FROM</h4>
<pre tabindex="0"><code># Format

POST /_query?format=csv
{
  &#34;query&#34;: &#34;&#34;&#34;
    from kibana_sample_data_logs
  &#34;&#34;&#34;
}
</code></pre><h4 id="row">ROW</h4>
<pre tabindex="0"><code>POST _query?format=txt
{
  &#34;query&#34;:&#34;&#34;&#34;
    row a = &#34;Mozilla/5.0 (X11; Linux x86_64; rv:6.0a1) Gecko/20110421 Firefox/6.0a1&#34;
    | dissect a &#34;%{browser}/%{version}&#34;
    | keep browser
  &#34;&#34;&#34;
}
</code></pre><h4 id="show">SHOW</h4>
<pre tabindex="0"><code>POST /_query?format=txt
{
  &#34;query&#34;: &#34;&#34;&#34;
    show info
  &#34;&#34;&#34;
}
</code></pre><h3 id="processing-commands">Processing commands</h3>
<h4 id="keep">keep</h4>
<pre tabindex="0"><code>POST _query?format=txt
{
  &#34;query&#34;: &#34;&#34;&#34;
    from kibana_sample_data_logs
    | keep @timestamp, clientip, host, tags, bytes
  &#34;&#34;&#34;
}
</code></pre><h4 id="where-limit-sort">where, limit, sort</h4>
<pre tabindex="0"><code>POST _query?format=txt
{
  &#34;query&#34;: &#34;&#34;&#34;
    from kibana_sample_data_logs
    | keep @timestamp, clientip, host, tags, bytes
    | where bytes &gt; 1000
    | sort bytes desc
    | limit 5
  &#34;&#34;&#34;
}
</code></pre><h4 id="like">like</h4>
<pre tabindex="0"><code>POST _query?format=txt
{
  &#34;query&#34;:&#34;&#34;&#34;
    FROM sample_data
    | where message like &#34;*error*&#34;
  &#34;&#34;&#34;
}
</code></pre><h4 id="grok-statsby">GROK, STATS&hellip;BY</h4>
<pre tabindex="0"><code>POST _query?format=txt
{
  &#34;query&#34;:&#34;&#34;&#34;
    from kibana_sample_data_logs
    | grok agent &#34;%{WORD:browser}/%{NUMBER:version}&#34;
    | keep browser, version, @timestamp
  &#34;&#34;&#34;
}

POST _query?format=txt
{
  &#34;query&#34;:&#34;&#34;&#34;
    from kibana_sample_data_logs
    | grok agent &#34;%{WORD:browser}/%{NUMBER:version}&#34;
    | keep browser, version, @timestamp
    | stats count(*) by version
  &#34;&#34;&#34;
}
</code></pre><h4 id="dissect">DISSECT</h4>
<pre tabindex="0"><code>POST _query?format=txt
{
  &#34;query&#34;: &#34;&#34;&#34;
    from kibana_sample_data_logs 
    | dissect message &#34;%{ip} - - %{time} %{web_call} &#34;
    | keep ip, time, web_call
  &#34;&#34;&#34;
}
</code></pre><h4 id="eval">EVAL</h4>
<pre tabindex="0"><code>POST /_query?format=txt
{
  &#34;query&#34;: &#34;&#34;&#34;
    from kibana_sample_data_logs
    | eval t = replace(agent, &#34;Mozilla&#34;, &#34;Chrome&#34;)
    | eval l = length(agent)
    | dissect agent &#34;%{browser}/%{version} &#34;
    | eval lt = left(t, 6)
    | keep lt, browser, version, t, l
  &#34;&#34;&#34;
}
</code></pre><p>You can check more <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/esql-functions-operators.html#esql-string-functions" target="_blank" rel="noopener">string functions</a>
.</p>
<h4 id="data-enrichment-enrich">Data enrichment (ENRICH)</h4>
<pre tabindex="0"><code>
# Create mappings

PUT lang
{
  &#34;mappings&#34;: {
    &#34;properties&#34;: {
      &#34;lang_id&#34;: {
        &#34;type&#34;: &#34;keyword&#34;
      },
      &#34;name&#34;: {
        &#34;type&#34;: &#34;keyword&#34;
      }
    }
  }
}

PUT devs
{
  &#34;mappings&#34;: {
    &#34;properties&#34;: {
      &#34;lang_id&#34;: {
        &#34;type&#34;: &#34;keyword&#34;
      },
      &#34;name&#34;: {
        &#34;type&#34;: &#34;keyword&#34;
      }
    }
  }
}

# Create index &#34;lang&#34;

PUT lang/_bulk
{ &#34;index&#34; : {}}
{ &#34;lang_id&#34;: &#34;1x&#34;, &#34;name&#34;: &#34;java&#34; }
{ &#34;index&#34; : {}}
{ &#34;lang_id&#34;: &#34;2x&#34;, &#34;name&#34;: &#34;php&#34; }
{ &#34;index&#34; : {}}
{ &#34;lang_id&#34;: &#34;3x&#34;, &#34;name&#34;: &#34;node&#34; }
{ &#34;index&#34; : {}}
{ &#34;lang_id&#34;: &#34;4x&#34;, &#34;name&#34;: &#34;python&#34; }
{ &#34;index&#34; : {}}
{ &#34;lang_id&#34;: &#34;5x&#34;, &#34;name&#34;: &#34;ruby&#34; }

# create index &#34;devs&#34;

PUT devs/_bulk
{ &#34;index&#34; : {}}
{ &#34;lang_id&#34;: &#34;5x&#34;, &#34;developer&#34;: &#34;bob&#34; }
{ &#34;index&#34; : {}}
{ &#34;lang_id&#34;: &#34;3x&#34;, &#34;developer&#34;: &#34;mark&#34; }
{ &#34;index&#34; : {}}
{ &#34;lang_id&#34;: &#34;1x&#34;, &#34;developer&#34;: &#34;max&#34; }
{ &#34;index&#34; : {}}
{ &#34;lang_id&#34;: &#34;2x&#34;, &#34;developer&#34;: &#34;david&#34; }
{ &#34;index&#34; : {}}
{ &#34;lang_id&#34;: &#34;4x&#34;, &#34;developer&#34;: &#34;ashish&#34; }


# Create enrich policy

PUT /_enrich/policy/dev_lang
{
  &#34;match&#34;: {
    &#34;indices&#34;: &#34;lang&#34;,
    &#34;match_field&#34;: &#34;lang_id&#34;,
    &#34;enrich_fields&#34;: [&#34;name&#34;]
  }
}

PUT /_enrich/policy/dev_lang/_execute?wait_for_completion=true

POST _query?format=txt
{
  &#34;query&#34;:&#34;&#34;&#34;
    from devs
    | keep lang_id, name, developer
    | enrich dev_lang on lang_id with name
  &#34;&#34;&#34;
}
</code></pre>]]></content:encoded>
    </item>
    
    <item>
      <title>Elasticsearch: Vector and Hybrid Search</title>
      <link>https://ashish.one/talks/vector-hybrid-search/</link>
      <pubDate>Tue, 29 Aug 2023 21:41:03 +0530</pubDate>
      
      <guid>https://ashish.one/talks/vector-hybrid-search/</guid>
      <description>Introduction Search is not just traditional TF/IDF any more but the current trend of machine learning and models has opened another dimension for search.
This talk gives an overview of:
Classic search and its limitations. What is a model and how can you use it. How to use vector search or hybrid search in Elasticsearch. Where OpenAI&amp;rsquo;s ChatGPT or similar LLMs come into play to with Elastic. Check how to leverage Leverage ChatGPT with Elasticsearch .</description>
      <content:encoded><![CDATA[<h1 id="introduction">Introduction</h1>
<p>Search is not just traditional TF/IDF any more but the current trend of machine learning and models has opened another dimension for search.</p>
<p>This talk gives an overview of:</p>
<ul>
<li><strong>Classic</strong> search and its limitations.</li>
<li>What is a model and how can you use it.</li>
<li>How to use vector search or hybrid search in Elasticsearch.</li>
<li>Where OpenAI&rsquo;s ChatGPT or similar LLMs come into play to with Elastic.</li>
</ul>
<p>Check how to leverage <a href="https://ashish.one/talks/chatgpt-elasticsearch/" target="_blank" rel="noopener">Leverage ChatGPT with Elasticsearch</a>
.</p>
<h2 id="talk-video">Talk Video</h2>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/AljarsLZRW0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

]]></content:encoded>
    </item>
    
    <item>
      <title>Monitor Kubernetes cluster with Elastic</title>
      <link>https://ashish.one/talks/monitor_k8_elastic_observability/</link>
      <pubDate>Fri, 28 Jul 2023 21:41:03 +0530</pubDate>
      
      <guid>https://ashish.one/talks/monitor_k8_elastic_observability/</guid>
      <description>Introduction Bring logs, metrics, and traces from your Kubernetes cluster and the workloads running on it into a single, unified solution. Elastic observability gives better visibility on your kubernetes ecosystem where you can monitor your pods, services, workload etc. Use a centrally managed Elastic Agent to gain visibility into your Kubernetes deployments on EKS, AKS, GKE or self-managed clusters.
Talk Video </description>
      <content:encoded><![CDATA[<h1 id="introduction">Introduction</h1>
<p>Bring logs, metrics, and traces from your Kubernetes cluster and the workloads running on it into a single, unified solution. Elastic observability gives better visibility on your kubernetes ecosystem where you can monitor your pods, services, workload etc. Use a centrally managed Elastic Agent to gain visibility into your Kubernetes deployments on EKS, AKS, GKE or self-managed clusters.</p>
<h2 id="talk-video">Talk Video</h2>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/8qOt_gYjwcw" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

]]></content:encoded>
    </item>
    
    <item>
      <title>Workshop - Leverage ChatGPT with Elasticsearch</title>
      <link>https://ashish.one/talks/chatgpt-elasticsearch/</link>
      <pubDate>Fri, 21 Jul 2023 15:52:06 +0530</pubDate>
      
      <guid>https://ashish.one/talks/chatgpt-elasticsearch/</guid>
      <description>Connect ChatGPT to proprietary data stores using Elasticsearch</description>
      <content:encoded><![CDATA[<h1 id="objective">Objective</h1>
<p>In this hands-on workshop, We will learn how to connect ChatGPT to proprietary data stores using Elasticsearch and build question/answer capabilities for your data. In a demo, We will quickly convert your website, FAQ, or any documentation into prompt chat where your user can directly ask a question on your data.</p>
<h1 id="flow">Flow</h1>
<p><img loading="lazy" src="/img/talks/elasticsearch-chatgpt/flow.png" alt="ChatGPT with Elasticsearch"  />
</p>
<h1 id="prerequisites">Prerequisites</h1>
<ol>
<li>
<p>You have used ChatGPT :)</p>
</li>
<li>
<p>Good to have understanding around Elasticsearch (Not mandatory, Introduction will be cover)</p>
</li>
<li>
<p>System + Internet connection</p>
</li>
<li>
<p>OpenAI account with API key - Create new one from <a href="https://platform.openai.com/account/api-keys" target="_blank" rel="noopener">https://platform.openai.com/account/api-keys</a>
. Make sure it having <a href="https://platform.openai.com/account/usage" target="_blank" rel="noopener">free credits</a>
.</p>
</li>
</ol>
<h2 id="without-local-setup">Without local setup</h2>
<ol>
<li>
<p>Google account to use <a href="https://colab.research.google.com/" target="_blank" rel="noopener">google Colab</a>
.</p>
</li>
<li>
<p><a href="https://render.com/" target="_blank" rel="noopener">Render</a>
 account.</p>
</li>
</ol>
<h2 id="local-setup">Local setup</h2>
<ol>
<li>
<p>Git - Install it from <a href="https://git-scm.com/downloads" target="_blank" rel="noopener">https://git-scm.com/downloads</a>
</p>
</li>
<li>
<p>Docker - Good to have. Install it from <a href="https://docs.docker.com/engine/install/" target="_blank" rel="noopener">https://docs.docker.com/engine/install/</a>
.</p>
</li>
<li>
<p>Having basic python knowledge will be good.</p>
</li>
</ol>
<p>For a workshop we going to follow without local setup.</p>
<h1 id="1-setup-cluster">1. Setup cluster</h1>
<ol>
<li>
<p>Visit <a href="https://cloud.elastic.co" target="_blank" rel="noopener">cloud.elastic.co</a>
 and signup.</p>
</li>
<li>
<p>Click on <em><strong>Create deployment</strong></em>. In the pop-up, you can change the settings or leave it default.</p>
</li>
<li>
<p>We need to add machine learning instance. For that, simply click on &ldquo;<em><strong>advance settings</strong></em>&rdquo; .</p>
</li>
<li>
<p>Go to <em><strong>&ldquo;Machine Learning instances&rdquo; -&gt; click on &ldquo;Add Capacity&rdquo;</strong></em> and select at least <strong>4GB</strong> ram capacity.</p>
</li>
<li>
<p>Finally click on &ldquo;<em><strong>Create deployment</strong></em>&rdquo;.</p>
</li>
<li>
<p>Download / Copy the deployment credentials.</p>
</li>
<li>
<p>Once deployment ready, click on &ldquo;Continue&rdquo; (or click on <em><strong>Open Kibana</strong></em>). It will redirect you on kibana dashboard.</p>
</li>
</ol>
<h1 id="2-deploy-model">2. Deploy Model</h1>
<h2 id="elser-model-by-elastic-recommended">ELSER Model by Elastic (Recommended)</h2>
<p>Go to the kibana panel. Navigate to <em><strong>Menu -&gt; Machine Learning</strong></em> (In <em>Analytics</em> section). In left menu, Click on <em><strong>Trained Models</strong></em> (In <em>Model Management</em> Section).</p>
<ol>
<li>ELSER can be found in the list of trained models.</li>
<li>Click the <em><strong>Download model</strong></em> button under <em><strong>Actions</strong></em>.</li>
<li>After the download is finished, start the deployment by clicking the <em><strong>Start deployment</strong></em> button.</li>
<li>Provide a deployment ID, select the priority, and set the number of allocations and threads per allocation values.</li>
<li>Click <em><strong>Start</strong></em>.</li>
</ol>
<h2 id="third-party-model">Third party model</h2>
<p>We are going to use <a href="https://huggingface.co/sentence-transformers/all-distilroberta-v1" target="_blank" rel="noopener">all-distilroberta-v1</a>
 model hosted on a hugging face. Lets import on an elastic cluster using eland.</p>
<p><strong>Get your credentials ready</strong></p>
<ul>
<li><code>cloud_id</code> : Visit ‚Äú<em><strong><a href="https://cloud.elastic.co" target="_blank" rel="noopener">cloud.elastic.co</a>
</strong></em>‚Äù -&gt; Navigate to your deployment and click on ‚Äú<em><strong>manage</strong></em>‚Äù. Simply copy Cloud ID and save it.</li>
<li><code>cloud_user</code>: <code>elastic</code></li>
<li><code>cloud_password</code>: You will get it from step 1.6. If you forget to save, Simply click on <em><strong>‚ÄúAction‚Äù -&gt; ‚ÄúReset password‚Äù</strong></em>. (Username will be <code>elastic</code> only)</li>
<li><code>hf_model_id</code>: <code>sentence-transformers/all-distilroberta-v1</code> (Go to model <a href="https://huggingface.co/sentence-transformers/all-distilroberta-v1" target="_blank" rel="noopener">page</a>
 on huggingface &amp; copy the ID <code>sentence-transformers/all-distilroberta-v1</code>)</li>
</ul>
<p>Now there is two way, You can upload the model using <code>docker</code> as well as <code>Google colab</code>.</p>
<h3 id="using-google-colab-recommended">Using Google Colab (Recommended)</h3>
<p>Simply click on below link. It will open ready made notebook. You just need to click on <code>play</code> button to run notebood.</p>
<p><a href="https://colab.research.google.com/github/ashishtiwari1993/elasticsearch-chatgpt/blob/main/load_model_eland.ipynb" target="_blank" rel="noopener"><img loading="lazy" src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"  />
</a>
</p>
<h3 id="using-docker">Using Docker</h3>
<ol start="2">
<li>
<p>We‚Äôre going to use docker for import model to the elastic cluster</p>
<ol>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span> git clone https://github.com/elastic/eland.git 
</span></span><span style="display:flex;"><span> cd eland
</span></span></code></pre></div></li>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span> docker build -t elastic/eland .
</span></span></code></pre></div></li>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span> docker run -it --rm elastic/eland eland_import_hub_model <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>     --cloud-id &lt;cloud_id&gt; <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>     -u elastic -p &lt;elastic_cloud_password&gt; <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>     --hub-model-id sentence-transformers/all-distilroberta-v1 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>     --task-type text_embedding <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>     --start
</span></span></code></pre></div></li>
<li>
<p>Let&rsquo;s wait till the model gets uploaded without any error.</p>
</li>
<li>
<p>Exit from <code>eland</code> folder.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>cd ..
</span></span></code></pre></div></li>
</ol>
</li>
</ol>
<h3 id="verify-uploaded-model">Verify uploaded model</h3>
<p>Go to the kibana panel. Navigate to <em><strong>Menu -&gt; Machine Learning (In <code>Analytics</code> section)</strong></em>. In left menu, Click on <em><strong>Trained Models</strong></em>(<code>Model Management</code> Section). You must see your model here in the ‚Äú<em><strong>Started</strong></em>‚Äù state.</p>
<p>In case if a warning message is displayed at the top of the page that says <em><strong>ML job and trained model synchronization required</strong></em>. Follow the link to <em><strong>Synchronize your jobs and trained models.</strong></em> Then click <em><strong>Synchronize</strong></em>.</p>
<h1 id="3-crawling-private-data">3. Crawling private data</h1>
<ol>
<li>Click on <em><strong>Menu -&gt; Enterprise Search -&gt; ‚ÄúCreate an Elasticsearch index‚Äù</strong></em> button</li>
<li>Click on <em><strong>Web crawler</strong></em>.</li>
<li>Add index name (It will add prefix <em><strong>search</strong></em>) and  hit ‚Äú<em><strong>Create index</strong></em>‚Äù. In my case index name is (search-ashish.one)</li>
<li>Go to ‚Äú<em><strong>Pipelines</strong></em>‚Äù to create a pipeline.</li>
<li>Click ‚Äú<em><strong>Copy and customize</strong></em>‚Äù in the Ingest Pipeline Box.</li>
<li>Click ‚Äú<em><strong>Add Inference Pipeline</strong></em>‚Äù in the Machine Learning Inference Pipelines box.</li>
<li>Give the unique pipeline name e.g. ‚Äú<em><strong>ml-inference-ashish-one</strong></em>‚Äù</li>
<li>Select a trained ML Model from the dropdown ‚Äú<em><strong>sentence-transformers__all-distilroberta-v1</strong></em>‚Äù (For ELSER choose &ldquo;<em><strong>.elser_model_1</strong></em>&rdquo;)</li>
<li>Select ‚Äú<em><strong>title</strong></em>‚Äù as the Source field and set ‚Äú<em><strong>title-vector</strong></em>‚Äù as a destination. You can specify your own destination field name. (In case of ELSER, just select the &ldquo;<em><strong>Source</strong></em>&rdquo; field e.g <em>title, body_content</em>)</li>
<li>Let&rsquo;s click on ‚Äú<em><strong>Continue</strong></em>‚Äù and move to the Test(Optional) tab.  Click on ‚Äú<em><strong>Continue</strong></em>‚Äù again.</li>
<li>At the Review stage let&rsquo;s click on ‚Äú<em><strong>Create pipeline</strong></em>‚Äù.</li>
<li>(Skip this for <em><strong>ELSER</strong></em>) Go to <em><strong>Menu -&gt; Management -&gt; Dev Tools</strong></em>. Let&rsquo;s create a mapping</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>POST &lt;index_name&gt;/_mapping
</span></span><span style="display:flex;"><span><span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;properties&#34;</span>: <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&lt;vector_field_name&gt;&#34;</span>: <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;dense_vector&#34;</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;dims&#34;</span>: 768,
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;index&#34;</span>: true,
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;similarity&#34;</span>: <span style="color:#e6db74">&#34;dot_product&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">}</span>
</span></span></code></pre></div><p>In my case mapping will be:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>POST search-ashish.one/_mapping
</span></span><span style="display:flex;"><span><span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;properties&#34;</span>: <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;title-vector&#34;</span>: <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;dense_vector&#34;</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;dims&#34;</span>: 768,
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;index&#34;</span>: true,
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;similarity&#34;</span>: <span style="color:#e6db74">&#34;dot_product&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">}</span>
</span></span></code></pre></div><p>Paste above query in <code>cosole</code> and hit on play button.</p>
<ol start="13">
<li>Go to <em><strong>Enterprise search -&gt; indices -&gt; your_index_name -&gt; Manage Domains</strong></em>. Enter the domain (e.g. <a href="https://ashish.one" target="_blank" rel="noopener">https://ashish.one</a>
. You can add your own domain) to crawl and hit ‚Äú<em><strong>Validate Domain</strong></em>‚Äù.</li>
<li>If everything is fine, simply click on ‚Äú<em><strong>Add domain</strong></em>‚Äù and start crawling by click on <em><strong>Crawl -&gt; Crawl all domains on this index</strong></em>.</li>
<li>Go to <em><strong>Enterprise Search -&gt; Indices</strong></em>. You should see your index name.</li>
</ol>
<h1 id="4-setup-interface">4. Setup Interface</h1>
<p>** Get your credentials ready **</p>
<ol>
<li><code>cloud_id</code> : Visit ‚Äú<em><strong><a href="https://cloud.elastic.co" target="_blank" rel="noopener">cloud.elastic.co</a>
</strong></em>‚Äù -&gt; Navigate to your deployment and click on ‚Äú<em><strong>manage</strong></em>‚Äù. Simply copy Cloud ID and save it.</li>
<li><code>cloud_user</code>: elastic</li>
<li><code>cloud_password</code>: You will get it from step 1.6. If you forget to save, Simply click on <em><strong>‚ÄúAction‚Äù -&gt; ‚ÄúReset password‚Äù</strong></em>. (Username will be elastic)</li>
<li><code>openai_api</code>: Create open ai api key from <a href="https://platform.openai.com/account/api-keys" target="_blank" rel="noopener">https://platform.openai.com/account/api-keys</a>
.</li>
<li><code>es_index</code>: Index name which we created in step 3.3. (search-ashish.one)</li>
<li><code>vector_field</code>: The field which we&rsquo;ve set for destination at step 3.9. i.e. <strong>title-vector</strong></li>
</ol>
<h2 id="setup-on-local-with-docker">Setup on local with Docker</h2>
<ol>
<li>Clone</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>git clone https://github.com/ashishtiwari1993/elasticsearch-chatgpt.git
</span></span><span style="display:flex;"><span>cd elasticsearch-chatgpt
</span></span></code></pre></div><ol start="2">
<li>Replace credentials in <code>Dockerfile</code></li>
</ol>
<p>Open <code>Dockerfile</code> and change below creds</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>ENV openai_api<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&lt;open_api_key&gt;&#34;</span>
</span></span><span style="display:flex;"><span>ENV cloud_id<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&lt;elastic cloud id&gt;&#34;</span>
</span></span><span style="display:flex;"><span>ENV cloud_user<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;elastic&#34;</span>
</span></span><span style="display:flex;"><span>ENV cloud_pass<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&lt;elastic_cloud_password&gt;&#34;</span>
</span></span><span style="display:flex;"><span>ENV es_index<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&lt;elasticsearch_index_name&gt;&#34;</span>
</span></span><span style="display:flex;"><span>ENV chat_title<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&lt;Any title for your page e.g. ashish.one GPT&gt;&#34;</span>
</span></span><span style="display:flex;"><span>ENV vector_field<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&lt; specify vector field where embedding will be save. e.g. title-vector&gt;&#34;</span>
</span></span></code></pre></div><ol start="3">
<li>Build</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>docker build -t es-gpt .
</span></span></code></pre></div><ol start="4">
<li>Run</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>docker run -p 8501:8501 es-gpt
</span></span></code></pre></div><p>Simply visit on <a href="!http://localhost:8501">localhost:8501</a>
</p>
<h2 id="setup-on-renderhttpsrendercom-with-docker">Setup on <a href="https://render.com/" target="_blank" rel="noopener">Render</a>
 with Docker</h2>
<ol>
<li>
<p>Signup on <a href="https://render.com" target="_blank" rel="noopener">https://render.com</a>
.</p>
</li>
<li>
<p>Create <strong>Web Service</strong>.</p>
</li>
<li>
<p>Go to <strong>Public Git repository</strong> section and add below repo url</p>
</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>https://github.com/ashishtiwari1993/elasticsearch-chatgpt
</span></span></code></pre></div><p>Hit on <strong>Continue</strong>.</p>
<ol start="4">
<li>
<p>Add <strong>Name</strong> and select <strong>Free</strong> Instance Type.</p>
</li>
<li>
<p>Click on <strong>Advanced</strong> and <strong>Add Environment Variable</strong></p>
</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>openai_api<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&lt;open_api_key&gt;&#34;</span>
</span></span><span style="display:flex;"><span>cloud_id<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&lt;elastic cloud id&gt;&#34;</span>
</span></span><span style="display:flex;"><span>cloud_user<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;elastic&#34;</span>
</span></span><span style="display:flex;"><span>cloud_pass<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&lt;elastic_cloud_password&gt;&#34;</span>
</span></span><span style="display:flex;"><span>es_index<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&lt;elasticsearch_index_name&gt;&#34;</span>                                                 
</span></span><span style="display:flex;"><span>chat_title<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&lt;Any title for your page e.g. ashish.one GPT&gt;&#34;</span>
</span></span><span style="display:flex;"><span>vector_field<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&lt; specify vector field where embedding will be save. e.g. title-vector&gt;&#34;</span>
</span></span></code></pre></div><ol start="6">
<li>Finally click on <strong>Create Web Service</strong></li>
</ol>
<h2 id="output">Output</h2>
<p><img loading="lazy" src="/img/talks/elasticsearch-chatgpt/ashish_one_gpt.gif" alt="ashish.one ChatGPT"  />
</p>
<h1 id="reference">Reference</h1>
<p><a href="https://www.elastic.co/blog/chatgpt-elasticsearch-openai-meets-private-data" target="_blank" rel="noopener">Blog - ChatGPT and Elasticsearch: OpenAI meets private data</a>
</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Getting started with Elastic stack</title>
      <link>https://ashish.one/talks/getting_started_elastic_stack/</link>
      <pubDate>Sat, 17 Sep 2022 19:24:45 +0000</pubDate>
      
      <guid>https://ashish.one/talks/getting_started_elastic_stack/</guid>
      <description>What this talk is all about ? Elastic Stack (Elasticsearch, Logstash, Kibana and Beats) is such a platform which is built for scalability, performance and ‚ÄúYou know&amp;hellip; for Search‚Äù. When you have a system which scales to the horizons of your data, helps you in your data quest, shows you insights - imagine what you can do with it.
Talk Video Feel free to comment below, If you have any doubts or suggestion about this talk.</description>
      <content:encoded><![CDATA[<h2 id="what-this-talk-is-all-about-">What this talk is all about ?</h2>
<p>Elastic Stack (Elasticsearch, Logstash, Kibana and Beats) is such a platform which is built for scalability, performance and ‚ÄúYou know&hellip; for Search‚Äù. When you have a system which scales to the horizons of your data, helps you in your data quest, shows you insights - imagine what you can do with it.</p>
<h2 id="talk-video">Talk Video</h2>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/hJoorF6zxBA" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

<h4 id="feel-free-to-comment-below-if-you-have-any-doubts-or-suggestion-about-this-talk">Feel free to comment below, If you have any doubts or suggestion about this talk.</h4>
]]></content:encoded>
    </item>
    
    <item>
      <title>Getting started with Elasticsearch</title>
      <link>https://ashish.one/talks/ws-es/</link>
      <pubDate>Wed, 14 Sep 2022 17:44:43 +0530</pubDate>
      
      <guid>https://ashish.one/talks/ws-es/</guid>
      <description>Sample Queries for Elasticsearch Workshop CRUD # Insert POST meetup/_doc/ { &amp;#34;name&amp;#34;:&amp;#34;Ashish Tiwari&amp;#34; } # Insert with id POST meetup/_doc/1 { &amp;#34;name&amp;#34;:&amp;#34;Ashish Tiwari&amp;#34; } # Search GET meetup/_search # Update POST meetup/_doc/1 { &amp;#34;name&amp;#34;:&amp;#34;Ashish&amp;#34;, &amp;#34;company&amp;#34;:&amp;#34;elastic&amp;#34;, &amp;#34;address&amp;#34;:&amp;#34;Navi Mumbai kharghar&amp;#34;, &amp;#34;skills&amp;#34;:{ &amp;#34;language&amp;#34;:[&amp;#34;php&amp;#34;,&amp;#34;java&amp;#34;,&amp;#34;node&amp;#34;], &amp;#34;database&amp;#34;:[&amp;#34;mysql&amp;#34;,&amp;#34;mongodb&amp;#34;], &amp;#34;search&amp;#34;:&amp;#34;elasticsearch&amp;#34; } } # search with query GET meetup/_search { &amp;#34;query&amp;#34;: { &amp;#34;match&amp;#34;: { &amp;#34;address&amp;#34;: &amp;#34;navi&amp;#34; } } } # delete DELETE meetup BULK POST _bulk {&amp;#34;index&amp;#34;:{&amp;#34;_index&amp;#34;:&amp;#34;meetup&amp;#34;}} {&amp;#34;user_id&amp;#34;:1,&amp;#34;first_name&amp;#34;:&amp;#34;Yvonne&amp;#34;,&amp;#34;last_name&amp;#34;:&amp;#34;Willmott&amp;#34;,&amp;#34;email&amp;#34;:&amp;#34;ywillmott0@live.com&amp;#34;,&amp;#34;gender&amp;#34;:&amp;#34;Female&amp;#34;,&amp;#34;street_address&amp;#34;:&amp;#34;38 Helena Avenue&amp;#34;,&amp;#34;ip_address&amp;#34;:&amp;#34;104.</description>
      <content:encoded><![CDATA[<h1 id="sample-queries-for-elasticsearch-workshop">Sample Queries for Elasticsearch Workshop</h1>
<h2 id="crud">CRUD</h2>
<pre tabindex="0"><code>
# Insert

POST meetup/_doc/
{
  &#34;name&#34;:&#34;Ashish Tiwari&#34;
}

# Insert with id

POST meetup/_doc/1
{
  &#34;name&#34;:&#34;Ashish Tiwari&#34;
}

# Search

GET meetup/_search

# Update

POST meetup/_doc/1
{
  &#34;name&#34;:&#34;Ashish&#34;,
  &#34;company&#34;:&#34;elastic&#34;,
  &#34;address&#34;:&#34;Navi Mumbai kharghar&#34;,
  &#34;skills&#34;:{
    &#34;language&#34;:[&#34;php&#34;,&#34;java&#34;,&#34;node&#34;],
    &#34;database&#34;:[&#34;mysql&#34;,&#34;mongodb&#34;],
    &#34;search&#34;:&#34;elasticsearch&#34;
  }
}

# search with query

GET meetup/_search
{
  &#34;query&#34;: {
    &#34;match&#34;: {
      &#34;address&#34;: &#34;navi&#34;
    }
  }
}

# delete

DELETE meetup
</code></pre><h2 id="bulk">BULK</h2>
<pre tabindex="0"><code>POST _bulk
{&#34;index&#34;:{&#34;_index&#34;:&#34;meetup&#34;}}
{&#34;user_id&#34;:1,&#34;first_name&#34;:&#34;Yvonne&#34;,&#34;last_name&#34;:&#34;Willmott&#34;,&#34;email&#34;:&#34;ywillmott0@live.com&#34;,&#34;gender&#34;:&#34;Female&#34;,&#34;street_address&#34;:&#34;38 Helena Avenue&#34;,&#34;ip_address&#34;:&#34;104.221.25.110&#34;,&#34;company&#34;:&#34;Flashset&#34;}
{&#34;index&#34;:{&#34;_index&#34;:&#34;meetup&#34;}}
{&#34;user_id&#34;:2,&#34;first_name&#34;:&#34;Immanuel&#34;,&#34;last_name&#34;:&#34;Philbrick&#34;,&#34;email&#34;:&#34;iphilbrick1@wunderground.com&#34;,&#34;gender&#34;:&#34;Male&#34;,&#34;street_address&#34;:&#34;01 Bunting Pass&#34;,&#34;ip_address&#34;:&#34;9.20.164.27&#34;,&#34;company&#34;:&#34;Babblestorm&#34;}
{&#34;index&#34;:{&#34;_index&#34;:&#34;meetup&#34;}}
{&#34;user_id&#34;:3,&#34;first_name&#34;:&#34;Clotilda&#34;,&#34;last_name&#34;:&#34;Danelut&#34;,&#34;email&#34;:&#34;cdanelut2@deliciousdays.com&#34;,&#34;gender&#34;:&#34;Agender&#34;,&#34;street_address&#34;:&#34;0 Crowley Trail&#34;,&#34;ip_address&#34;:&#34;158.94.144.140&#34;,&#34;company&#34;:&#34;Riffpedia&#34;}
{&#34;index&#34;:{&#34;_index&#34;:&#34;meetup&#34;}}
{&#34;user_id&#34;:4,&#34;first_name&#34;:&#34;Nahum&#34;,&#34;last_name&#34;:&#34;Attfield&#34;,&#34;email&#34;:&#34;nattfield3@blog.com&#34;,&#34;gender&#34;:&#34;Male&#34;,&#34;street_address&#34;:&#34;7 Garrison Court&#34;,&#34;ip_address&#34;:&#34;225.144.148.44&#34;,&#34;company&#34;:&#34;Chatterpoint&#34;}
{&#34;index&#34;:{&#34;_index&#34;:&#34;meetup&#34;}}
{&#34;user_id&#34;:5,&#34;first_name&#34;:&#34;Vaughan&#34;,&#34;last_name&#34;:&#34;Middis&#34;,&#34;email&#34;:&#34;vmiddis4@ted.com&#34;,&#34;gender&#34;:&#34;Male&#34;,&#34;street_address&#34;:&#34;7 Cody Way&#34;,&#34;ip_address&#34;:&#34;66.198.31.108&#34;,&#34;company&#34;:&#34;Mynte&#34;}
{&#34;index&#34;:{&#34;_index&#34;:&#34;meetup&#34;}}
{&#34;user_id&#34;:6,&#34;first_name&#34;:&#34;Nolie&#34;,&#34;last_name&#34;:&#34;Alessandrucci&#34;,&#34;email&#34;:&#34;nalessandrucci5@networksolutions.com&#34;,&#34;gender&#34;:&#34;Male&#34;,&#34;street_address&#34;:&#34;826 Brown Hill&#34;,&#34;ip_address&#34;:&#34;96.77.221.95&#34;,&#34;company&#34;:&#34;Feedfish&#34;}
{&#34;index&#34;:{&#34;_index&#34;:&#34;meetup&#34;}}
{&#34;user_id&#34;:7,&#34;first_name&#34;:&#34;Beverlie&#34;,&#34;last_name&#34;:&#34;Ovitts&#34;,&#34;email&#34;:&#34;bovitts6@tripod.com&#34;,&#34;gender&#34;:&#34;Male&#34;,&#34;street_address&#34;:&#34;6 Sycamore Pass&#34;,&#34;ip_address&#34;:&#34;102.24.117.107&#34;,&#34;company&#34;:&#34;Zazio&#34;}
{&#34;index&#34;:{&#34;_index&#34;:&#34;meetup&#34;}}
{&#34;user_id&#34;:8,&#34;first_name&#34;:&#34;Graeme&#34;,&#34;last_name&#34;:&#34;Dopson&#34;,&#34;email&#34;:&#34;gdopson7@free.fr&#34;,&#34;gender&#34;:&#34;Female&#34;,&#34;street_address&#34;:&#34;26 Dunning Avenue&#34;,&#34;ip_address&#34;:&#34;198.33.215.93&#34;,&#34;company&#34;:&#34;Flashset&#34;}
{&#34;index&#34;:{&#34;_index&#34;:&#34;meetup&#34;}}
{&#34;user_id&#34;:9,&#34;first_name&#34;:&#34;Mellisa&#34;,&#34;last_name&#34;:&#34;Hurich&#34;,&#34;email&#34;:&#34;mhurich8@nbcnews.com&#34;,&#34;gender&#34;:&#34;Male&#34;,&#34;street_address&#34;:&#34;6371 Browning Way&#34;,&#34;ip_address&#34;:&#34;66.0.3.199&#34;,&#34;company&#34;:&#34;Divanoodle&#34;}
{&#34;index&#34;:{&#34;_index&#34;:&#34;meetup&#34;}}
{&#34;user_id&#34;:10,&#34;first_name&#34;:&#34;Dyan&#34;,&#34;last_name&#34;:&#34;Loude&#34;,&#34;email&#34;:&#34;dloude9@berkeley.edu&#34;,&#34;gender&#34;:&#34;Female&#34;,&#34;street_address&#34;:&#34;9818 Reindahl Road&#34;,&#34;ip_address&#34;:&#34;16.56.137.54&#34;,&#34;company&#34;:&#34;Agivu&#34;}
{&#34;index&#34;:{&#34;_index&#34;:&#34;meetup&#34;}}
{&#34;user_id&#34;:11,&#34;first_name&#34;:&#34;Becky&#34;,&#34;last_name&#34;:&#34;Shank&#34;,&#34;email&#34;:&#34;bshanka@tinypic.com&#34;,&#34;gender&#34;:&#34;Male&#34;,&#34;street_address&#34;:&#34;1206 Warrior Terrace&#34;,&#34;ip_address&#34;:&#34;90.63.35.111&#34;,&#34;company&#34;:&#34;Izio&#34;}
{&#34;index&#34;:{&#34;_index&#34;:&#34;meetup&#34;}}
{&#34;user_id&#34;:12,&#34;first_name&#34;:&#34;Bar&#34;,&#34;last_name&#34;:&#34;Bedburrow&#34;,&#34;email&#34;:&#34;bbedburrowb@vistaprint.com&#34;,&#34;gender&#34;:&#34;Male&#34;,&#34;street_address&#34;:&#34;75 Onsgard Crossing&#34;,&#34;ip_address&#34;:&#34;85.122.33.250&#34;,&#34;company&#34;:&#34;Zoombox&#34;}
{&#34;index&#34;:{&#34;_index&#34;:&#34;meetup&#34;}}
{&#34;user_id&#34;:13,&#34;first_name&#34;:&#34;Dorey&#34;,&#34;last_name&#34;:&#34;Isenor&#34;,&#34;email&#34;:&#34;disenorc@privacy.gov.au&#34;,&#34;gender&#34;:&#34;Female&#34;,&#34;street_address&#34;:&#34;53682 Parkside Crossing&#34;,&#34;ip_address&#34;:&#34;150.158.150.213&#34;,&#34;company&#34;:&#34;Rhyzio&#34;}
{&#34;index&#34;:{&#34;_index&#34;:&#34;meetup&#34;}}
{&#34;user_id&#34;:14,&#34;first_name&#34;:&#34;Torrin&#34;,&#34;last_name&#34;:&#34;Rangall&#34;,&#34;email&#34;:&#34;trangalld@buzzfeed.com&#34;,&#34;gender&#34;:&#34;Male&#34;,&#34;street_address&#34;:&#34;24247 Old Shore Plaza&#34;,&#34;ip_address&#34;:&#34;40.151.17.2&#34;,&#34;company&#34;:&#34;Devpoint&#34;}
{&#34;index&#34;:{&#34;_index&#34;:&#34;meetup&#34;}}
{&#34;user_id&#34;:15,&#34;first_name&#34;:&#34;Genvieve&#34;,&#34;last_name&#34;:&#34;Beslier&#34;,&#34;email&#34;:&#34;gbesliere@yolasite.com&#34;,&#34;gender&#34;:&#34;Male&#34;,&#34;street_address&#34;:&#34;96214 Miller Trail&#34;,&#34;ip_address&#34;:&#34;115.143.68.208&#34;,&#34;company&#34;:&#34;Oyonder&#34;}
{&#34;index&#34;:{&#34;_index&#34;:&#34;meetup&#34;}}
{&#34;user_id&#34;:16,&#34;first_name&#34;:&#34;Arden&#34;,&#34;last_name&#34;:&#34;Ramas&#34;,&#34;email&#34;:&#34;aramasf@whitehouse.gov&#34;,&#34;gender&#34;:&#34;Polygender&#34;,&#34;street_address&#34;:&#34;390 Gulseth Alley&#34;,&#34;ip_address&#34;:&#34;36.83.126.154&#34;,&#34;company&#34;:&#34;Youbridge&#34;}
{&#34;index&#34;:{&#34;_index&#34;:&#34;meetup&#34;}}
{&#34;user_id&#34;:17,&#34;first_name&#34;:&#34;Alyosha&#34;,&#34;last_name&#34;:&#34;Domm&#34;,&#34;email&#34;:&#34;adommg@washingtonpost.com&#34;,&#34;gender&#34;:&#34;Female&#34;,&#34;street_address&#34;:&#34;32 Oxford Way&#34;,&#34;ip_address&#34;:&#34;174.71.176.45&#34;,&#34;company&#34;:&#34;Wikizz&#34;}
</code></pre><h2 id="upload-sample-json-data-from-kibana">Upload sample json data from kibana</h2>
<p>Download <a href="/data/movies.json">movies.json</a>
 and insert into elasticsearch by using below command:</p>
<p><em>Open Kibana -&gt; Menu -&gt; Home -&gt; Upload a file</em></p>
<h2 id="create-data-view-in-kibana">Create Data view in Kibana</h2>
<p><em>Open Kibana -&gt; Menu -&gt; Stack Management -&gt; Data Views (Kibana)</em></p>
<h2 id="create-dashboard">Create Dashboard</h2>
<p><em>Open Kibana -&gt; Menu -&gt; Analytics -&gt; Dashboard</em></p>
<h2 id="create-mapping">Create mapping</h2>
<pre tabindex="0"><code>PUT /devfest-raipur
{
  &#34;mappings&#34;: {
    &#34;properties&#34;: {
      &#34;age&#34;:    { &#34;type&#34;: &#34;integer&#34; },  
      &#34;email&#34;:  { &#34;type&#34;: &#34;keyword&#34;  }, 
      &#34;name&#34;:   { &#34;type&#34;: &#34;text&#34;  }     
    }
  }
}
</code></pre><h2 id="analyze">Analyze</h2>
<pre tabindex="0"><code># analyze

GET /_analyze?pretty
{
  &#34;text&#34; : &#34;Quick Brown Foxes!&#34;
}

# Whitespace

GET _analyze
{
  &#34;analyzer&#34;: &#34;whitespace&#34;,
  &#34;text&#34;: &#34;The 2 QUICK Brown-Foxes jumped over the lazy dog\u0027s bone.&#34;
}
</code></pre><h3 id="what-is-an-analyzer">What is an analyzer?</h3>
<p>An analyzer is made of character filters, tokenizer and token filters.</p>
<p>Let&rsquo;s build one</p>
<pre tabindex="0"><code>POST _analyze
{
  &#34;char_filter&#34;: [], 
  &#34;tokenizer&#34;:   &#34;standard&#34;,
  &#34;filter&#34;:      [], 
  &#34;text&#34;: [ 
    &#34;I like when the &lt;strong&gt;quick&lt;/strong&gt; foxes jumps over lazy DOGS!&#34;,
    &#34;and &lt;strong&gt;fast&lt;/strong&gt;&#34;
  ]
}
</code></pre><p>Let&rsquo;s remove the html code.</p>
<pre tabindex="0"><code>POST _analyze
{
  &#34;char_filter&#34;: [&#34;html_strip&#34;], 
  &#34;tokenizer&#34;:   &#34;standard&#34;,
  &#34;filter&#34;:      [], 
  &#34;text&#34;: [ 
    &#34;I like when the &lt;strong&gt;quick&lt;/strong&gt; foxes jumps over lazy DOGS!&#34;,
    &#34;and &lt;strong&gt;fast&lt;/strong&gt;&#34;
  ]
}
</code></pre><p>Some words don&rsquo;t bring us any value. Let&rsquo;s skip them.</p>
<pre tabindex="0"><code>POST _analyze
{
  &#34;char_filter&#34;: [&#34;html_strip&#34;], 
  &#34;tokenizer&#34;:   &#34;standard&#34;,
  &#34;filter&#34;:      [
    {
      &#34;type&#34;:       &#34;stop&#34;,
      &#34;stopwords&#34;:  [ &#34;_english_&#34;]
    }
  ], 
  &#34;text&#34;:
  [ 
    &#34;I like when the &lt;strong&gt;quick&lt;/strong&gt; foxes jumps over lazy DOGS!&#34;,
    &#34;and &lt;strong&gt;fast&lt;/strong&gt;&#34;
  ]
}
</code></pre><p>We can also remove &ldquo;I&rdquo;, &ldquo;when&rdquo; and &ldquo;over&rdquo;.</p>
<pre tabindex="0"><code>POST _analyze
{
  &#34;char_filter&#34;: [&#34;html_strip&#34;], 
  &#34;tokenizer&#34;:   &#34;standard&#34;,
  &#34;filter&#34;:      [
    {
      &#34;type&#34;:       &#34;stop&#34;,
      &#34;ignore_case&#34;:true, 
      &#34;stopwords&#34;:  [ &#34;_english_&#34;, &#34;I&#34;, &#34;when&#34;, &#34;over&#34;]
    }
  ], 
  &#34;text&#34;:
  [ 
    &#34;I like when the &lt;strong&gt;quick&lt;/strong&gt; foxes jumps over lazy DOGS!&#34;,
    &#34;and &lt;strong&gt;fast&lt;/strong&gt;&#34;
  ]
}
</code></pre><p><code>DOGS</code> and <code>dogs</code> should match.</p>
<pre tabindex="0"><code>POST _analyze
{
  &#34;char_filter&#34;: [&#34;html_strip&#34;], 
  &#34;tokenizer&#34;:   &#34;standard&#34;,
  &#34;filter&#34;:      [
    {
      &#34;type&#34;:       &#34;stop&#34;,
      &#34;ignore_case&#34;:true, 
      &#34;stopwords&#34;:  [ &#34;_english_&#34;, &#34;I&#34;, &#34;when&#34;, &#34;over&#34;]
    },
    &#34;lowercase&#34;
  ], 
  &#34;text&#34;:
  [ 
    &#34;I like when the &lt;strong&gt;quick&lt;/strong&gt; foxes jumps over lazy DOGS!&#34;,
    &#34;and &lt;strong&gt;fast&lt;/strong&gt;&#34;
  ]
}
</code></pre><p><code>dog</code>, <code>dogs</code> and <code>fox</code>, <code>foxes</code> and <code>jump</code>, <code>jumps</code>, <code>jumping</code>, <code>jumped</code> should match. Let&rsquo;s use a <code>stemmer</code>.</p>
<pre tabindex="0"><code>POST _analyze
{
  &#34;char_filter&#34;: [&#34;html_strip&#34;], 
  &#34;tokenizer&#34;:   &#34;standard&#34;,
  &#34;filter&#34;:      [
    {
      &#34;type&#34;:       &#34;stop&#34;,
      &#34;ignore_case&#34;:true, 
      &#34;stopwords&#34;:  [ &#34;_english_&#34;, &#34;I&#34;, &#34;when&#34;, &#34;over&#34;]
    },
    &#34;lowercase&#34;,
    {
      &#34;type&#34;:       &#34;stemmer&#34;,
      &#34;language&#34;:   &#34;english&#34; 
    }
  ], 
  &#34;text&#34;:
  [ 
    &#34;jumping jumps jump jumped&#34;,
    &#34;I like when the &lt;strong&gt;quick&lt;/strong&gt; foxes jumps over lazy DOGS!&#34;,
    &#34;and &lt;strong&gt;fast&lt;/strong&gt;&#34;
  ]
}
</code></pre><h1 id="language-analyzer">Language analyzer</h1>
<pre tabindex="0"><code>GET /_analyze?pretty
{
  &#34;analyzer&#34;: &#34;hindi&#34;, 
  &#34;text&#34; : &#34;‡§ö‡§æ‡§£‡§ï‡•ç‡§Ø ‡§®‡•á ‡§ö‡§Ç‡§¶‡•ç‡§∞‡§ó‡•Å‡§™‡•ç‡§§ ‡§î‡§∞ ‡§¨‡§ø‡§Ç‡§¶‡•Ç‡§∏‡§æ‡§∞ ‡§¶‡•ã‡§®‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§™‡•ç‡§∞‡§ß‡§æ‡§®‡§Æ‡§Ç‡§§‡•ç‡§∞‡•Ä ‡§î‡§∞ ‡§∞‡§æ‡§ú‡§®‡§Ø‡§ø‡§ï ‡§∏‡§≤‡§æ‡§π‡§ï‡§æ‡§∞ ‡§ï‡•á ‡§∞‡•Ç‡§™ ‡§Æ‡•á‡§Ç ‡§ï‡§æ‡§Æ ‡§ï‡§ø‡§Ø‡§æ‡•§&#34;
}
</code></pre><h2 id="lets-create-hindi-search-engine-‡§ó‡§§‡§Ø‡§§‡§∞">Let&rsquo;s create Hindi search engine (‡§ó‡•Ä‡§§‡§Ø‡§Ç‡§§‡•ç‡§∞)</h2>
<h3 id="create-mapping-1">Create mapping</h3>
<pre tabindex="0"><code>PUT geetyantra
{
  &#34;settings&#34;: {
    &#34;analysis&#34;: {
      &#34;analyzer&#34;: {
        &#34;geetyantra-analyzer&#34;:{
          &#34;type&#34;:&#34;hindi&#34;
        }
      }
    }
  },
  &#34;mappings&#34;: {
    &#34;properties&#34;: {
      &#34;adhyay&#34;: {&#34;type&#34;: &#34;integer&#34;},
      &#34;updesh&#34;: {&#34;type&#34;: &#34;text&#34;,&#34;analyzer&#34;: &#34;geetyantra-analyzer&#34;}
    }
  }
}
</code></pre><h3 id="insert-data">Insert data</h3>
<p>Taking data from üôè<a href="https://hi.wikipedia.org/wiki/%E0%A4%B6%E0%A5%8D%E0%A4%B0%E0%A5%80%E0%A4%AE%E0%A4%A6%E0%A5%8D%E0%A4%AD%E0%A4%97%E0%A4%B5%E0%A4%A6%E0%A5%8D%E0%A4%97%E0%A5%80%E0%A4%A4%E0%A4%BE" target="_blank" rel="noopener">‡§µ‡§ø‡§ï‡§ø‡§™‡•Ä‡§°‡§ø‡§Ø‡§æ-‡§∂‡•ç‡§∞‡•Ä‡§Æ‡§¶‡•ç‡§≠‡§ó‡§µ‡§¶‡•ç‡§ó‡•Ä‡§§‡§æ</a>
</p>
<p>Lets insert some data like below:</p>
<pre tabindex="0"><code>POST geetyantra/_doc
{
  &#34;adhyay&#34;:1,
  &#34;updesh&#34;:&#34;‡§ï‡•É‡§∑‡•ç‡§£ ‡§®‡•á ‡§Ö‡§∞‡•ç‡§ú‡•Å‡§® ‡§ï‡•Ä ‡§µ‡§π ‡§∏‡•ç‡§•‡§ø‡§§‡§ø ‡§¶‡•á‡§ñ‡§ï‡§∞ ‡§ú‡§æ‡§® ‡§≤‡§ø‡§Ø‡§æ ‡§ï‡§ø ‡§Ö‡§∞‡•ç‡§ú‡•Å‡§® ‡§ï‡§æ ‡§∂‡§∞‡•Ä‡§∞ ‡§†‡•Ä‡§ï ‡§π‡•à ‡§ï‡§ø‡§Ç‡§§‡•Å ‡§Ø‡•Å‡§¶‡•ç‡§ß ‡§Ü‡§∞‡§Ç‡§≠ ‡§π‡•ã‡§®‡•á ‡§∏‡•á ‡§™‡§π‡§≤‡•á ‡§π‡•Ä ‡§â‡§∏ ‡§Ö‡§¶‡•ç‡§≠‡•Å‡§§ ‡§ï‡•ç‡§∑‡§§‡•ç‡§∞‡§ø‡§Ø ‡§ï‡§æ ‡§Æ‡§®‡•ã‡§¨‡§≤ ‡§ü‡•Ç‡§ü ‡§ö‡•Å‡§ï‡§æ ‡§π‡•à‡•§ ‡§¨‡§ø‡§®‡§æ ‡§Æ‡§® ‡§ï‡•á ‡§Ø‡§π ‡§∂‡§∞‡•Ä‡§∞ ‡§ñ‡§°‡§º‡§æ ‡§®‡§π‡•Ä‡§Ç ‡§∞‡§π ‡§∏‡•§&#34;
}

POST geetyantra/_doc
{
  &#34;adhyay&#34;:2,
  &#34;updesh&#34;:&#34;‡§¶‡•Ç‡§∏‡§∞‡•á ‡§Ö‡§ß‡•ç‡§Ø‡§æ‡§Ø ‡§ï‡§æ ‡§®‡§æ‡§Æ ‡§∏‡§æ‡§Ç‡§ñ‡•ç‡§Ø‡§Ø‡•ã‡§ó ‡§π‡•à‡•§ ‡§á‡§∏‡§Æ‡•á‡§Ç ‡§ú‡•Ä‡§µ‡§® ‡§ï‡•Ä ‡§¶‡•ã ‡§™‡•ç‡§∞‡§æ‡§ö‡•Ä‡§® ‡§∏‡§Ç‡§Æ‡§æ‡§®‡§ø‡§§ ‡§™‡§∞‡§Ç‡§™‡§∞‡§æ‡§ì‡§Ç ‡§ï‡§æ ‡§§‡§∞‡•ç‡§ï‡•ã‡§Ç ‡§¶‡•ç‡§µ‡§æ‡§∞‡§æ ‡§µ‡§∞‡•ç‡§£‡§® ‡§Ü‡§Ø‡§æ ‡§π‡•à‡•§ ‡§Ö‡§∞‡•ç‡§ú‡•Å‡§® ‡§ï‡•ã ‡§â‡§∏ ‡§ï‡•É‡§™‡§£ ‡§∏‡•ç‡§•‡§ø‡§§‡§ø ‡§Æ‡•á‡§Ç ‡§∞‡•ã‡§§‡•á ‡§¶‡•á‡§ñ‡§ï‡§∞ ‡§ï‡•É‡§∑‡•ç‡§£ ‡§®‡•á ‡§â‡§®‡§ï‡§æ ‡§ß‡•ç‡§Ø‡§æ‡§® ‡§¶‡§ø‡§≤‡§æ‡§Ø‡§æ ‡§π‡•à ‡§ï‡§ø ‡§á‡§∏ ‡§™‡•ç‡§∞‡§ï‡§æ‡§∞ ‡§ï‡§æ ‡§ï‡•ç‡§≤‡•à‡§µ‡•ç‡§Ø ‡§î‡§∞ ‡§π‡•É‡§¶‡§Ø ‡§ï‡•Ä ‡§ï‡•ç‡§∑‡•Å‡§¶‡•ç‡§∞ ‡§¶‡•Å‡§∞‡•ç‡§¨‡§≤‡§§‡§æ ‡§Ö‡§∞‡•ç‡§ú‡•Å‡§® ‡§ú‡•à‡§∏‡•á ‡§µ‡•Ä‡§∞ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§â‡§ö‡§ø‡§§ ‡§®‡§π‡•Ä‡§Ç‡•§&#34;
}

POST geetyantra/_doc
{
  &#34;adhyay&#34;:3,
  &#34;updesh&#34;:&#34;‡§®‡§ø‡§§‡•ç‡§Ø ‡§ï‡§∞‡•ç‡§Æ ‡§ï‡§∞‡§®‡•á ‡§µ‡§æ‡§≤‡•á ‡§ï‡•Ä ‡§∂‡•ç‡§∞‡•á‡§∑‡•ç‡§†‡§§‡§æ&#34;
}

POST geetyantra/_doc
{
  &#34;adhyay&#34;:4,
  &#34;updesh&#34;:&#34;‡§ö‡•å‡§•‡•á ‡§Ö‡§ß‡•ç‡§Ø‡§æ‡§Ø ‡§Æ‡•á‡§Ç, ‡§ú‡§ø‡§∏‡§ï‡§æ ‡§®‡§æ‡§Æ ‡§ú‡•ç‡§û‡§æ‡§®-‡§ï‡§∞‡•ç‡§Æ-‡§∏‡§Ç‡§®‡•ç‡§Ø‡§æ‡§∏-‡§Ø‡•ã‡§ó ‡§π‡•à, ‡§Ø‡§π ‡§¨‡§æ‡§§‡§æ‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à ‡§ï‡§ø ‡§ú‡•ç‡§û‡§æ‡§® ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡§∞‡§ï‡•á ‡§ï‡§∞‡•ç‡§Æ ‡§ï‡§∞‡§§‡•á ‡§π‡•Å‡§è ‡§≠‡•Ä ‡§ï‡§∞‡•ç‡§Æ‡§∏‡§Ç‡§®‡•ç‡§Ø‡§æ‡§∏ ‡§ï‡§æ ‡§´‡§≤ ‡§ï‡§ø‡§∏ ‡§â‡§™‡§æ‡§Ø ‡§∏‡•á ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ ‡§∏‡§ï‡§§‡§æ ‡§π‡•à‡•§&#34;,
  &#34;shloka&#34;:&#34;‡§Ø‡§¶‡§æ ‡§Ø‡§¶‡§æ ‡§π‡§ø ‡§ß‡§∞‡•ç‡§Æ‡§∏‡•ç‡§Ø ‡§ó‡•ç‡§≤‡§æ‡§®‡§ø‡§∞‡•ç‡§≠‡§µ‡§§‡§ø ‡§≠‡§æ‡§∞‡§§,‡§Ö‡§≠‡•ç‡§Ø‡•Å‡§§‡•ç‡§•‡§æ‡§®‡§Æ‡§ß‡§∞‡•ç‡§Æ‡§∏‡•ç‡§Ø ‡§§‡§¶‡§æ‡§§‡•ç‡§Æ‡§æ‡§®‡§Ç ‡§∏‡•É‡§ú‡§æ‡§Æ‡•ç‡§Ø‡§π‡§Æ‡•ç&#34;
}

POST geetyantra/_doc
{
  &#34;adhyay&#34;:5,
  &#34;updesh&#34;:&#34;‡§ú‡•ç‡§û‡§æ‡§®‡•Ä ‡§Æ‡§π‡§æ‡§™‡•Å‡§∞‡•Å‡§∑ ‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ-‡§µ‡§ø‡§®‡§Ø‡§Ø‡•Å‡§ï‡•ç‡§§ ‡§¨‡•ç‡§∞‡§æ‡§π‡•ç‡§Æ‡§£ ‡§Æ‡•á‡§Ç ‡§î‡§∞ ‡§ö‡§æ‡§£‡•ç‡§°‡§æ‡§≤ ‡§Æ‡•á‡§Ç ‡§§‡§•‡§æ ‡§ó‡§æ‡§Ø, ‡§π‡§æ‡§•‡•Ä ‡§è‡§µ‡§Ç ‡§ï‡•Å‡§§‡•ç‡§§‡•á ‡§Æ‡•á‡§Ç ‡§≠‡•Ä ‡§∏‡§Æ‡§∞‡•Ç‡§™ ‡§™‡§∞‡§Æ‡§æ‡§§‡•ç‡§Æ‡§æ ‡§ï‡•ã ‡§¶‡•á‡§ñ‡§®‡•á ‡§µ‡§æ‡§≤‡•á ‡§π‡•ã‡§§‡•á ‡§π‡•à‡§Ç‡•§&#34;,
  &#34;shloka&#34;:&#34;‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ‡§µ‡§ø‡§®‡§Ø‡§∏‡§Ç‡§™‡§®‡•ç‡§®‡•á ‡§¨‡•ç‡§∞‡§æ‡§π‡•ç‡§Æ‡§£‡•á ‡§ó‡§µ‡§ø ‡§π‡§∏‡•ç‡§§‡§ø‡§®‡§ø,‡§∂‡•Å‡§®‡§ø ‡§ö‡•à‡§µ ‡§∂‡•ç‡§µ‡§™‡§æ‡§ï‡•á ‡§ö ‡§™‡§Ç‡§°‡§ø‡§§‡§æ: ‡§∏‡§Æ‡§¶‡§∞‡•ç‡§∂‡§ø‡§®&#34;
}


POST geetyantra/_doc
{
  &#34;adhyay&#34;:6,
  &#34;updesh&#34;:&#34;‡§õ‡§†‡§æ ‡§Ö‡§ß‡•ç‡§Ø‡§æ‡§Ø ‡§Ü‡§§‡•ç‡§Æ‡§∏‡§Ç‡§Ø‡§Æ ‡§Ø‡•ã‡§ó ‡§π‡•à ‡§ú‡§ø‡§∏‡§ï‡§æ ‡§µ‡§ø‡§∑‡§Ø ‡§®‡§æ‡§Æ ‡§∏‡•á ‡§π‡•Ä ‡§™‡•ç‡§∞‡§ï‡§ü ‡§π‡•à‡•§ ‡§ú‡§ø‡§§‡§®‡•á ‡§µ‡§ø‡§∑‡§Ø ‡§π‡•à‡§Ç ‡§â‡§® ‡§∏‡§¨‡§∏‡•á ‡§á‡§Ç‡§¶‡•ç‡§∞‡§ø‡§Ø‡•ã‡§Ç ‡§ï‡§æ ‡§∏‡§Ç‡§Ø‡§Æ-‡§Ø‡§π‡•Ä ‡§ï‡§∞‡•ç‡§Æ ‡§î‡§∞ ‡§ú‡•ç‡§û‡§æ‡§® ‡§ï‡§æ ‡§®‡§ø‡§ö‡•ã‡§°‡§º ‡§π‡•à‡•§ ‡§∏‡•Å‡§ñ ‡§Æ‡•á‡§Ç ‡§î‡§∞ ‡§¶‡•Å‡§ñ ‡§Æ‡•á‡§Ç ‡§Æ‡§® ‡§ï‡•Ä ‡§∏‡§Æ‡§æ‡§® ‡§∏‡•ç‡§•‡§ø‡§§‡§ø, ‡§á‡§∏‡•á ‡§π‡•Ä ‡§Ø‡•ã‡§ó ‡§ï‡§π‡§§‡•á ‡§π‡•à‡§Ç‡•§&#34;
}

POST geetyantra/_doc
{
  &#34;adhyay&#34;:7,
  &#34;updesh&#34;:&#34;‡§™‡§Ç‡§ö‡§§‡§§‡•ç‡§µ, ‡§Æ‡§®, ‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø ‡§≠‡•Ä ‡§Æ‡•à‡§Ç ‡§π‡•Ç‡§Å| ‡§Æ‡•à‡§Ç ‡§π‡•Ä ‡§∏‡§Ç‡§∏‡§æ‡§∞ ‡§ï‡•Ä ‡§â‡§§‡•ç‡§™‡§§‡•ç‡§§‡§ø ‡§ï‡§∞‡§§‡§æ ‡§π‡•Ç‡§Å ‡§î‡§∞ ‡§µ‡§ø‡§®‡§æ‡§∂ ‡§≠‡•Ä ‡§Æ‡•à‡§Ç ‡§π‡•Ä ‡§ï‡§∞‡§§‡§æ ‡§π‡•Ç‡§Å‡•§ ‡§Æ‡•á‡§∞‡•á ‡§≠‡§ï‡•ç‡§§ ‡§ö‡§æ‡§π‡•á ‡§ú‡§ø‡§∏ ‡§™‡•ç‡§∞‡§ï‡§æ‡§∞ ‡§≠‡§ú‡•á‡§Ç ‡§™‡§∞‡§®‡•ç‡§§‡•Å ‡§Ö‡§Ç‡§§‡§§‡§É ‡§Æ‡•Å‡§ù‡•á ‡§π‡•Ä ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§π‡•ã‡§§‡•á ‡§π‡•à‡§Ç‡•§ ‡§Æ‡•à‡§Ç ‡§Ø‡•ã‡§ó‡§Æ‡§æ‡§Ø‡§æ ‡§∏‡•á ‡§Ö‡§™‡•ç‡§∞‡§ï‡§ü ‡§∞‡§π‡§§‡§æ ‡§π‡•Ç‡§Å ‡§î‡§∞ ‡§Æ‡•Å‡§∞‡•ç‡§ñ ‡§Æ‡•Å‡§ù‡•á ‡§ï‡•á‡§µ‡§≤ ‡§∏‡§æ‡§ß‡§æ‡§∞‡§£ ‡§Æ‡§®‡•Å‡§∑‡•ç‡§Ø ‡§π‡•Ä ‡§∏‡§Æ‡§ù‡§§‡•á ‡§π‡•à‡§Ç‡•§&#34;,
  &#34;shloka&#34;:&#34;‡§Ø‡•ã ‡§Ø‡•ã ‡§Ø‡§æ‡§Ç ‡§Ø‡§æ‡§Ç ‡§§‡§®‡•Å‡§Ç ‡§≠‡§ï‡•ç‡§§‡§É ‡§∂‡•ç‡§∞‡§¶‡•ç‡§ß‡§Ø‡§æ‡§∞‡•ç‡§ö‡§ø‡§§‡•Å‡§Æ‡§ø‡§ö‡•ç‡§õ‡§§‡§ø,‡§§‡§∏‡•ç‡§Ø ‡§§‡§∏‡•ç‡§Ø‡§æ‡§ö‡§≤‡§æ‡§Ç ‡§∂‡•ç‡§∞‡§¶‡•ç‡§ß‡§æ‡§Ç ‡§§‡§æ‡§Æ‡•á‡§µ ‡§µ‡§ø‡§¶‡§ß‡§æ‡§Æ‡•ç‡§Ø‡§π‡§Æ‡•ç&#34;
}

POST geetyantra/_doc
{
  &#34;adhyay&#34;:8,
  &#34;updesh&#34;:&#34;‡§ï‡•Ä ‡§∏‡§Ç‡§ú‡•ç‡§û‡§æ ‡§Ö‡§ï‡•ç‡§∑‡§∞ ‡§¨‡•ç‡§∞‡§π‡•ç‡§Æ‡§Ø‡•ã‡§ó ‡§π‡•à‡•§ ‡§â‡§™‡§®‡§ø‡§∑‡§¶‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§Ö‡§ï‡•ç‡§∑‡§∞ ‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ ‡§ï‡§æ ‡§µ‡§ø‡§∏‡•ç‡§§‡§æ‡§∞ ‡§π‡•Å‡§Ü‡•§ ‡§ó‡•Ä‡§§‡§æ ‡§Æ‡•á‡§Ç ‡§â‡§∏ ‡§Ö‡§ï‡•ç‡§∑‡§∞‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ ‡§ï‡§æ ‡§∏‡§æ‡§∞ ‡§ï‡§π ‡§¶‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à-‡§Ö‡§ï‡•ç‡§∑‡§∞ ‡§¨‡•ç‡§∞‡§π‡•ç‡§Æ ‡§™‡§∞‡§Æ‡§Ç, ‡§Ö‡§∞‡•ç‡§•‡§æ‡§§‡•ç ‡§™‡§∞‡§¨‡•ç‡§∞‡§π‡•ç‡§Æ ‡§ï‡•Ä ‡§∏‡§Ç‡§ú‡•ç‡§û‡§æ ‡§Ö‡§ï‡•ç‡§∑‡§∞ ‡§π‡•à‡•§ ‡§Æ‡§®‡•Å‡§∑‡•ç‡§Ø, ‡§Ö‡§∞‡•ç‡§•‡§æ‡§§‡•ç ‡§ú‡•Ä‡§µ ‡§î‡§∞ ‡§∂‡§∞‡•Ä‡§∞ ‡§ï‡•Ä ‡§∏‡§Ç‡§Ø‡•Å‡§ï‡•ç‡§§ ‡§∞‡§ö‡§®‡§æ ‡§ï‡§æ ‡§π‡•Ä ‡§®‡§æ‡§Æ ‡§Ö‡§ß‡•ç‡§Ø‡§æ‡§§‡•ç‡§Æ ‡§π‡•à‡•§&#34;
}

POST geetyantra/_doc
{
  &#34;adhyay&#34;:9,
  &#34;updesh&#34;:&#34;‡§ï‡•ã ‡§∞‡§æ‡§ú‡§ó‡•Å‡§π‡•ç‡§Ø‡§Ø‡•ã‡§ó ‡§ï‡§π‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à, ‡§Ö‡§∞‡•ç‡§•‡§æ‡§§‡•ç ‡§Ø‡§π ‡§Ö‡§ß‡•ç‡§Ø‡§æ‡§§‡•ç‡§Æ ‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ ‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ‡§∞‡§æ‡§ú‡•ç‡§û‡•Ä ‡§π‡•à ‡§î‡§∞ ‡§Ø‡§π ‡§ó‡•Å‡§π‡•ç‡§Ø ‡§ú‡•ç‡§û‡§æ‡§® ‡§∏‡§¨‡§Æ‡•á‡§Ç ‡§∂‡•ç‡§∞‡•á‡§∑‡•ç‡§† ‡§π‡•à‡•§ ‡§∞‡§æ‡§ú‡§æ ‡§∂‡§¨‡•ç‡§¶‡§ï‡§æ ‡§è‡§ï ‡§Ö‡§∞‡•ç‡§• ‡§Æ‡§® ‡§≠‡•Ä ‡§•‡§æ‡•§ ‡§Ö‡§§‡§è‡§µ ‡§Æ‡§® ‡§ï‡•Ä ‡§¶‡§ø‡§µ‡•ç‡§Ø ‡§∂‡§ï‡•ç‡§§‡§ø‡§Æ‡§Ø‡•ã‡§Ç ‡§ï‡•ã ‡§ï‡§ø‡§∏ ‡§™‡•ç‡§∞‡§ï‡§æ‡§∞ ‡§¨‡•ç‡§∞‡§π‡•ç‡§Æ‡§Æ‡§Ø ‡§¨‡§®‡§æ‡§Ø‡§æ ‡§ú‡§æ‡§Ø, ‡§á‡§∏‡§ï‡•Ä ‡§Ø‡•Å‡§ï‡•ç‡§§‡§ø ‡§π‡•Ä ‡§∞‡§æ‡§ú‡§µ‡§ø‡§¶‡•ç‡§Ø‡§æ ‡§π‡•à‡•§&#34;
}

POST geetyantra/_doc
{
  &#34;adhyay&#34;:10,
  &#34;updesh&#34;:&#34;‡§¶‡§∏‡§µ‡•á‡§Ç ‡§Ö‡§ß‡•ç‡§Ø‡§æ‡§Ø ‡§ï‡§æ ‡§®‡§æ‡§Æ ‡§µ‡§ø‡§≠‡•Ç‡§§‡§ø‡§Ø‡•ã‡§ó ‡§π‡•à‡•§ ‡§á‡§∏‡§ï‡§æ ‡§∏‡§æ‡§∞ ‡§Ø‡§π ‡§π‡•à ‡§ï‡§ø ‡§≤‡•ã‡§ï ‡§Æ‡•á‡§Ç ‡§ú‡§ø‡§§‡§®‡•á ‡§¶‡•á‡§µ‡§§‡§æ ‡§π‡•à‡§Ç, ‡§∏‡§¨ ‡§è‡§ï ‡§π‡•Ä ‡§≠‡§ó‡§µ‡§æ‡§®, ‡§ï‡•Ä ‡§µ‡§ø‡§≠‡•Ç‡§§‡§ø‡§Ø‡§æ‡§Å ‡§π‡•à‡§Ç, ‡§Æ‡§®‡•Å‡§∑‡•ç‡§Ø ‡§ï‡•á ‡§∏‡§Æ‡§∏‡•ç‡§§ ‡§ó‡•Å‡§£ ‡§î‡§∞ ‡§Ö‡§µ‡§ó‡•Å‡§£ ‡§≠‡§ó‡§µ‡§æ‡§® ‡§ï‡•Ä ‡§∂‡§ï‡•ç‡§§‡§ø ‡§ï‡•á ‡§π‡•Ä ‡§∞‡•Ç‡§™ ‡§π‡•à‡§Ç‡•§&#34;
}

POST geetyantra/_doc
{
  &#34;adhyay&#34;:11,
  &#34;updesh&#34;:&#34;‡§ï‡§æ ‡§®‡§æ‡§Æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§∞‡•Ç‡§™‡§¶‡§∞‡•ç‡§∂‡§® ‡§Ø‡•ã‡§ó ‡§π‡•à‡•§ ‡§á‡§∏‡§Æ‡•á‡§Ç ‡§Ö‡§∞‡•ç‡§ú‡•Å‡§® ‡§®‡•á ‡§≠‡§ó‡§µ‡§æ‡§® ‡§ï‡§æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§∞‡•Ç‡§™ ‡§¶‡•á‡§ñ‡§æ‡•§ ‡§µ‡§ø‡§∞‡§æ‡§ü ‡§∞‡•Ç‡§™ ‡§ï‡§æ ‡§Ö‡§∞‡•ç‡§• ‡§π‡•à ‡§Æ‡§æ‡§®‡§µ‡•Ä‡§Ø ‡§ß‡§∞‡§æ‡§§‡§≤ ‡§î‡§∞ ‡§™‡§∞‡§ø‡§ß‡§ø ‡§ï‡•á ‡§ä‡§™‡§∞ ‡§ú‡•ã ‡§Ö‡§®‡§Ç‡§§ ‡§µ‡§ø‡§∂‡•ç‡§µ ‡§ï‡§æ ‡§™‡•ç‡§∞‡§æ‡§£‡§µ‡§Ç‡§§ ‡§∞‡§ö‡§®‡§æ‡§µ‡§ø‡§ß‡§æ‡§® ‡§π‡•à, ‡§â‡§∏‡§ï‡§æ ‡§∏‡§æ‡§ï‡•ç‡§∑‡§æ‡§§ ‡§¶‡§∞‡•ç‡§∂‡§®‡•§ ‡§µ‡§ø‡§∑‡•ç‡§£‡•Å ‡§ï‡§æ ‡§ú‡•ã ‡§ö‡§§‡•Å‡§∞‡•ç‡§≠‡•Å‡§ú ‡§∞‡•Ç‡§™ ‡§π‡•à, ‡§µ‡§π ‡§Æ‡§æ‡§®‡§µ‡•Ä‡§Ø ‡§ß‡§∞‡§æ‡§§‡§≤ ‡§™‡§∞ ‡§∏‡•å‡§Æ‡•ç‡§Ø‡§∞‡•Ç‡§™ ‡§π‡•à‡•§&#34;
}

POST geetyantra/_doc
{
  &#34;adhyay&#34;:12,
  &#34;updesh&#34;:&#34;‡§ï‡§æ ‡§®‡§æ‡§Æ ‡§≠‡§ï‡•ç‡§§‡§ø ‡§Ø‡•ã‡§ó ‡§π‡•à‡•§ ‡§ú‡•ã ‡§ú‡§æ‡§®‡§®‡•á ‡§Ø‡•ã‡§ó‡•ç‡§Ø ‡§π‡•à‡•§ ‡§ú‡§ø‡§∏‡§ï‡•ã ‡§ú‡§æ‡§®‡§ï‡§∞ ‡§Æ‡§®‡•Å‡§∑‡•ç‡§Ø ‡§™‡§∞‡§Æ‡§æ‡§®‡§®‡•ç‡§¶ ‡§ï‡•ã ‡§™‡•ç‡§∞‡§æ‡§™‡•ç‡§§ ‡§π‡•ã ‡§ú‡§æ‡§§‡§æ ‡§π‡•à ‡§Ö‡§∞‡•ç‡§•‡§æ‡§§ ‡§µ‡•ã ‡§™‡§∞‡§Æ‡§æ‡§§‡•ç‡§Æ‡§æ ‡§π‡•Ä ‡§∏‡§§‡•ç‡§Ø ‡§π‡•à ‡•§‡•§&#34;
}

POST geetyantra/_doc
{
  &#34;adhyay&#34;:13,
  &#34;updesh&#34;:&#34;‡§Æ‡•á‡§Ç ‡§è‡§ï ‡§∏‡•Ä‡§ß‡§æ ‡§µ‡§ø‡§∑‡§Ø ‡§ï‡•ç‡§∑‡•á‡§§‡•ç‡§∞ ‡§î‡§∞ ‡§ï‡•ç‡§∑‡•á‡§§‡•ç‡§∞‡§ú‡•ç‡§û ‡§ï‡§æ ‡§µ‡§ø‡§ö‡§æ‡§∞ ‡§π‡•à‡•§ ‡§Ø‡§π ‡§∂‡§∞‡•Ä‡§∞ ‡§ï‡•ç‡§∑‡•á‡§§‡•ç‡§∞ ‡§π‡•à, ‡§â‡§∏‡§ï‡§æ ‡§ú‡§æ‡§®‡§®‡•á‡§µ‡§æ‡§≤‡§æ ‡§ú‡•Ä‡§µ‡§æ‡§§‡•ç‡§Æ‡§æ ‡§ï‡•ç‡§∑‡•á‡§§‡•ç‡§∞‡§ú‡•ç‡§û ‡§π‡•à‡•§&#34;
}

POST geetyantra/_doc
{
  &#34;adhyay&#34;:14,
  &#34;updesh&#34;:&#34;‡§ï‡§æ ‡§®‡§æ‡§Æ ‡§ó‡•Å‡§£‡§§‡•ç‡§∞‡§Ø ‡§µ‡§ø‡§≠‡§æ‡§ó ‡§Ø‡•ã‡§ó ‡§π‡•à‡•§ ‡§Ø‡§π ‡§µ‡§ø‡§∑‡§Ø ‡§∏‡§Æ‡§∏‡•ç‡§§ ‡§µ‡•à‡§¶‡§ø‡§ï, ‡§¶‡§æ‡§∞‡•ç‡§∂‡§®‡§ø‡§ï ‡§î‡§∞ ‡§™‡•å‡§∞‡§æ‡§£‡§ø‡§ï ‡§§‡§§‡•ç‡§µ‡§ö‡§ø‡§Ç‡§§‡§® ‡§ï‡§æ ‡§®‡§ø‡§ö‡•ã‡§°‡§º ‡§π‡•à-‡§∏‡§§‡•ç‡§µ, ‡§∞‡§ú, ‡§§‡§Æ ‡§®‡§æ‡§Æ‡§ï ‡§§‡•Ä‡§® ‡§ó‡•Å‡§£-‡§§‡•ç‡§∞‡§ø‡§ï‡•ã ‡§ï‡•Ä ‡§Ö‡§®‡•á‡§ï ‡§µ‡•ç‡§Ø‡§æ‡§ñ‡•ç‡§Ø‡§æ‡§è‡§Å ‡§π‡•à‡§Ç‡•§&#34;
}

POST geetyantra/_doc
{
  &#34;adhyay&#34;:15,
  &#34;updesh&#34;:&#34;‡§ï‡§æ ‡§®‡§æ‡§Æ ‡§™‡•Å‡§∞‡•Å‡§∑‡•ã‡§§‡•ç‡§§‡§Æ‡§Ø‡•ã‡§ó ‡§π‡•à‡•§ ‡§á‡§∏‡§Æ‡•á‡§Ç ‡§µ‡§ø‡§∂‡•ç‡§µ ‡§ï‡§æ ‡§Ö‡§∂‡•ç‡§µ‡§§‡•ç‡§• ‡§ï‡•á ‡§∞‡•Ç‡§™ ‡§Æ‡•á‡§Ç ‡§µ‡§∞‡•ç‡§£‡§® ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à‡•§ ‡§Ø‡§π ‡§Ö‡§∂‡•ç‡§µ‡§§‡•ç‡§• ‡§∞‡•Ç‡§™‡•Ä ‡§∏‡§Ç‡§∏‡§æ‡§∞ ‡§Æ‡§π‡§æ‡§® ‡§µ‡§ø‡§∏‡•ç‡§§‡§æ‡§∞‡§µ‡§æ‡§≤‡§æ ‡§π‡•à‡•§ ‡§¶‡•á‡§∂ ‡§î‡§∞ ‡§ï‡§æ‡§≤ ‡§Æ‡•á‡§Ç ‡§á‡§∏‡§ï‡§æ ‡§ï‡•ã‡§à ‡§Ö‡§Ç‡§§ ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à‡•§&#34;
}

POST geetyantra/_doc
{
  &#34;adhyay&#34;:16,
  &#34;updesh&#34;:&#34;‡§Æ‡•á‡§Ç ‡§¶‡•á‡§µ‡§æ‡§∏‡•Å‡§∞ ‡§∏‡§Ç‡§™‡§§‡•ç‡§§‡§ø ‡§ï‡§æ ‡§µ‡§ø‡§≠‡§æ‡§ó ‡§¨‡§§‡§æ‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à‡•§ ‡§Ü‡§∞‡§Ç‡§≠ ‡§∏‡•á ‡§π‡•Ä ‡§ã‡§ó‡•ç‡§¶‡•á‡§µ ‡§Æ‡•á‡§Ç ‡§∏‡•É‡§∑‡•ç‡§ü‡§ø ‡§ï‡•Ä ‡§ï‡§≤‡•ç‡§™‡§®‡§æ ‡§¶‡•à‡§µ‡•Ä ‡§î‡§∞ ‡§Ü‡§∏‡•Å‡§∞‡•Ä ‡§∂‡§ï‡•ç‡§§‡§ø‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§∞‡•Ç‡§™ ‡§Æ‡•á‡§Ç ‡§ï‡•Ä ‡§ó‡§à ‡§π‡•à‡•§ &#34;
}

POST geetyantra/_doc
{
  &#34;adhyay&#34;:17,
  &#34;updesh&#34;:&#34;‡§ï‡•Ä ‡§∏‡§Ç‡§ú‡•ç‡§û‡§æ ‡§∂‡•ç‡§∞‡§¶‡•ç‡§ß‡§æ‡§§‡•ç‡§∞‡§Ø ‡§µ‡§ø‡§≠‡§æ‡§ó ‡§Ø‡•ã‡§ó ‡§π‡•à‡•§ ‡§á‡§∏‡§ï‡§æ ‡§∏‡§Ç‡§¨‡§Ç‡§ß ‡§∏‡§§, ‡§∞‡§ú ‡§î‡§∞ ‡§§‡§Æ, ‡§á‡§® ‡§§‡•Ä‡§® ‡§ó‡•Å‡§£‡•ã‡§Ç ‡§∏‡•á ‡§π‡•Ä ‡§π‡•à, ‡§Ö‡§∞‡•ç‡§•‡§æ‡§§‡•ç ‡§ú‡§ø‡§∏‡§Æ‡•á‡§Ç ‡§ú‡§ø‡§∏ ‡§ó‡•Å‡§£ ‡§ï‡§æ ‡§™‡•ç‡§∞‡§æ‡§¶‡•Å‡§∞‡•ç‡§≠‡§æ‡§µ ‡§π‡•ã‡§§‡§æ ‡§π‡•à, ‡§â‡§∏‡§ï‡•Ä ‡§∂‡•ç‡§∞‡§¶‡•ç‡§ß‡§æ ‡§Ø‡§æ ‡§ú‡•Ä‡§µ‡§® ‡§ï‡•Ä ‡§®‡§ø‡§∑‡•ç‡§†‡§æ ‡§µ‡•à‡§∏‡•Ä ‡§π‡•Ä ‡§¨‡§® ‡§ú‡§æ‡§§‡•Ä ‡§π‡•à‡•§&#34;
}

POST geetyantra/_doc
{
  &#34;adhyay&#34;:18,
  &#34;updesh&#34;:&#34;‡§ï‡•Ä ‡§∏‡§Ç‡§ú‡•ç‡§û‡§æ ‡§Æ‡•ã‡§ï‡•ç‡§∑‡§∏‡§Ç‡§®‡•ç‡§Ø‡§æ‡§∏ ‡§Ø‡•ã‡§ó ‡§π‡•à‡•§ ‡§á‡§∏‡§Æ‡•á‡§Ç ‡§ó‡•Ä‡§§‡§æ ‡§ï‡•á ‡§∏‡§Æ‡§∏‡•ç‡§§ ‡§â‡§™‡§¶‡•á‡§∂‡•ã‡§Ç ‡§ï‡§æ ‡§∏‡§æ‡§∞ ‡§è‡§µ‡§Ç ‡§â‡§™‡§∏‡§Ç‡§π‡§æ‡§∞ ‡§π‡•à‡•§ ‡§Ø‡§π‡§æ‡§Å ‡§™‡•Å‡§®: ‡§¨‡§≤‡§™‡•Ç‡§∞‡•ç‡§µ‡§ï ‡§Æ‡§æ‡§®‡§µ ‡§ú‡•Ä‡§µ‡§® ‡§ï‡•á ‡§≤‡§ø‡§è ‡§§‡•Ä‡§® ‡§ó‡•Å‡§£‡•ã‡§Ç ‡§ï‡§æ ‡§Æ‡§π‡§§‡•ç‡§µ ‡§ï‡§π‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à‡•§ ‡§™‡•É‡§•‡•ç‡§µ‡•Ä ‡§ï‡•á ‡§Æ‡§æ‡§®‡§µ‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§î‡§∞ ‡§∏‡•ç‡§µ‡§∞‡•ç‡§ó ‡§ï‡•á ‡§¶‡•á‡§µ‡§§‡§æ‡§ì‡§Ç ‡§Æ‡•á‡§Ç ‡§ï‡•ã‡§à ‡§≠‡•Ä ‡§ê‡§∏‡§æ ‡§®‡§π‡•Ä‡§Ç ‡§ú‡•ã ‡§™‡•ç‡§∞‡§ï‡•É‡§§‡§ø ‡§ï‡•á ‡§ö‡§≤‡§æ‡§è ‡§π‡•Å‡§è ‡§á‡§® ‡§§‡•Ä‡§® ‡§ó‡•Å‡§£‡•ã‡§Ç ‡§∏‡•á ‡§¨‡§ö‡§æ ‡§π‡•ã‡•§&#34;
}
</code></pre><h3 id="search">Search</h3>
<pre tabindex="0"><code>
GET geetyantra/_search?size=20

GET geetyantra/_search
{
  &#34;query&#34;: {
    &#34;match&#34;: {
      &#34;updesh&#34;: &#34;‡§Ö‡§∞‡•ç‡§ú‡•Å‡§®&#34;
    }
  }
}

GET geetyantra/_search
{
  &#34;query&#34;: {
    &#34;match&#34;: {
      &#34;shloka&#34;: &#34;‡§ß‡§∞‡•ç‡§Æ‡§∏‡•ç‡§Ø&#34;
    }
  }
}

GET geetyantra/_search
{
  &#34;query&#34;: {
    &#34;multi_match&#34;: {
      &#34;query&#34;: &#34;‡§∂‡•ç‡§∞‡§¶‡•ç‡§ß‡§æ&#34;,
      &#34;fields&#34;: [&#34;shloka&#34;,&#34;updesh&#34;]
    }
  }
}

GET geetyantra/_search
{
  &#34;query&#34;: {
    &#34;match_phrase_prefix&#34;: {
      &#34;updesh&#34;: &#34;‡§ö‡•å‡§•‡•á ‡§Ö‡§ß‡•ç‡§Ø‡§æ‡§Ø ‡§Æ‡•á‡§Ç&#34;
    }
  }
}
</code></pre><h2 id="search-as-you-type">Search as you type</h2>
<p>Refer article <a href="https://ashish.one/blogs/search-as-you-type/" target="_blank" rel="noopener">Search as you type</a>
.</p>
]]></content:encoded>
    </item>
    
    <item>
      <title>Parse custom logs in Elasticsearch using grok_pattern</title>
      <link>https://ashish.one/talks/devops-conf-2022/</link>
      <pubDate>Sun, 06 Mar 2022 14:30:32 +0530</pubDate>
      
      <guid>https://ashish.one/talks/devops-conf-2022/</guid>
      <description>Introduction In the talk, Quickly showed how you can use the metricbeat to check system health. With a few clicks, you can start monitoring your infra.
Another demo shows, How you can parse your custom unstructured logs to Elasticsearch. There is some utility already available for predefined logs format like json, apache, nginx and system logs etc.
But if you have different requirement where you need to parse a different types of log format , You can parse using Grok processor .</description>
      <content:encoded><![CDATA[<h1 id="introduction">Introduction</h1>
<p>In the talk, Quickly showed how you can use the <a href="https://www.elastic.co/beats/metricbeat" target="_blank" rel="noopener">metricbeat</a>
 to check system health. With a few clicks, you can start monitoring your infra.</p>
<p>Another demo shows, How you can parse your custom unstructured logs to Elasticsearch. There is some utility already available for predefined logs format like json, apache, nginx and system logs etc.</p>
<p>But if you have different requirement where you need to parse a different types of log format , You can parse using <a href="https://www.elastic.co/guide/en/elasticsearch/reference/master/grok-processor.html" target="_blank" rel="noopener">Grok processor</a>
.</p>
<p>Also explained how you can read custom logs from log files in real time and ingest to Elasticsearch.</p>
<h1 id="slides">Slides</h1>
<div id="Container"
 style="padding-bottom:56.25%; position:relative; display:block; width: 100%">
 <iframe id="googleSlideIframe"
  width="100%" height="100%"
  src="https://docs.google.com/presentation/d/e/2PACX-1vQtGa1x8-WMwWX8MTMZ-8GdJDMmiro4dNwcIE5HHmj1oGaSs88znwGf-W8bwUSANkIRQkeMZnh8KfWs/embed?start=false&amp;loop=false&amp;delayms=3000"
  frameborder="0" allowfullscreen=""
  style="position:absolute; top:0; left: 0"></iframe>
</div>

<h2 id="talk-video">Talk Video</h2>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/owyv9sQE7q8?start=4856&amp;end=9427" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

<h4 id="feel-free-to-comment-below-if-you-have-any-doubts-or-suggestion-about-this-talk">Feel free to comment below, If you have any doubts or suggestion about this talk.</h4>
]]></content:encoded>
    </item>
    
    <item>
      <title>Deploy Elasicsearch on Azure cloud</title>
      <link>https://ashish.one/talks/deploy_elastic_on_azure/</link>
      <pubDate>Sat, 29 Jan 2022 19:24:45 +0000</pubDate>
      
      <guid>https://ashish.one/talks/deploy_elastic_on_azure/</guid>
      <description>Introduction What this talk is all about ? The purpose of the talk is to give a short overview of Elastic solutions &amp;amp; Elastic stacks. In the demo shown, how you can deploy elasticsearch instance on Microsoft Azure.
Also, it gives an idea to use the elastic cloud to manage the elasticsearch instance which deployed on the Azure cloud. You can also create deployment on elastic cloud (cloud.elastic.co ).
In the demo, Successfully shipped the metric data of the local system (my MacBook) to the newly deployed elasticsearch instance and explored the dashboard on kibana.</description>
      <content:encoded><![CDATA[<h1 id="introduction">Introduction</h1>
<h2 id="what-this-talk-is-all-about-">What this talk is all about ?</h2>
<p>The purpose of the talk is to give a short overview of Elastic solutions &amp; Elastic stacks. In the demo shown, how you can deploy elasticsearch instance on Microsoft Azure.</p>
<p>Also, it gives an idea to use the elastic cloud to manage the elasticsearch instance which deployed on the Azure cloud. You can also create deployment on elastic cloud (<a href="https://cloud.elastic.co" target="_blank" rel="noopener">cloud.elastic.co</a>
).</p>
<p>In the demo, Successfully shipped the metric data of the local system (my MacBook) to the newly deployed elasticsearch instance and explored the dashboard on kibana.</p>
<h2 id="slides">Slides</h2>
<div id="Container"
 style="padding-bottom:56.25%; position:relative; display:block; width: 100%">
 <iframe id="googleSlideIframe"
  width="100%" height="100%"
  src="https://docs.google.com/presentation/d/e/2PACX-1vR9COL0Pod4Hdhc3OlkIPorb-UM0DtbhSgcqQajOYV789jbmRYsffyIRVR0cFCnm8eu80sF8-khLc0K/embed?start=false&amp;loop=false&amp;delayms=3000"
  frameborder="0" allowfullscreen=""
  style="position:absolute; top:0; left: 0"></iframe>
</div>

<h2 id="talk-video">Talk Video</h2>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/O2HdAA5o1i4" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

<h4 id="feel-free-to-comment-below-if-you-have-any-doubts-or-suggestion-about-this-talk">Feel free to comment below, If you have any doubts or suggestion about this talk.</h4>
]]></content:encoded>
    </item>
    
    <item>
      <title>Golang basics &amp; Handling 100k hourly webhooks with golang @MimePost</title>
      <link>https://ashish.one/talks/golang-basics-and-send-100k-hourly-webhooks-with-golang-mimepost/</link>
      <pubDate>Wed, 11 Mar 2020 00:12:30 +0530</pubDate>
      
      <guid>https://ashish.one/talks/golang-basics-and-send-100k-hourly-webhooks-with-golang-mimepost/</guid>
      <description>What this talk about? I am working on Golang for the last 1 year from the published date. I have shared some basics of Golang.
Also, shared What are the pain points developers face when they migrate from any other language (Especially from web language like PHP) to Golang?
I have explained the Webhook architecture of MimePost And how we sending 100k Request hourly( Though Benchmark proves we can scale up to 500k).</description>
      <content:encoded><![CDATA[<h2 id="what-this-talk-about">What this talk about?</h2>
<p>I am working on Golang for the last 1 year from the published date. I have shared some basics of Golang.</p>
<p>Also, shared What are the pain points developers face when they migrate from any other language (Especially from web language like PHP) to Golang?</p>
<p>I have explained the Webhook architecture of MimePost And how we sending 100k Request hourly( Though Benchmark proves we can scale up to 500k).</p>
<p>Shown some immature code which given me a better understanding of 100% CPU utilization and How I waste my major time to debug on silly things.</p>
<p>Shared one of our error and it&rsquo;s solutions related to How you can avoid race conditions on &ldquo;map&rdquo; type variables.</p>
<h2 id="slides">Slides</h2>
<div id="Container"
 style="padding-bottom:56.25%; position:relative; display:block; width: 100%">
 <iframe id="googleSlideIframe"
  width="100%" height="100%"
  src="https://docs.google.com/presentation/d/e/2PACX-1vQExSl-gRPoA9hC6qXuqrjwiQVHAanDieZN_5GpV2Lw9cuxjsVFEN_wkTThqpQwZ36vJz4zwmTvV7cC/embed?start=false&amp;loop=false&amp;delayms=3000"
  frameborder="0" allowfullscreen=""
  style="position:absolute; top:0; left: 0"></iframe>
</div>

<h2 id="talk-video">Talk Video</h2>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/ZjOcwoCkkog" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

<h2 id="demo---1">Demo - 1</h2>
<p>This code will make 100% CPU utilization and <code>forever()</code> function not going to share any single CPU time with <code>anotherGoroutine()</code></p>
<script type="application/javascript" src="https://gist.github.com/ashishtiwari1993/00b2a56ac8f5b39d3229d723e58815bc.js"></script>

<h2 id="demo---2">Demo - 2</h2>
<p>Reproduce Golang &ldquo;fatal error: concurrent map writes&rdquo; &amp; Solution. To reproduce comment Mutex related all operation like line no. 12, 30, 32, 44, 46. Mutex is use to prevent race condition which generates this error.</p>
<script type="application/javascript" src="https://gist.github.com/ashishtiwari1993/d494b71ac264184ba46ced1bf2114c30.js"></script>

<p>Find more details on this <a href="https://ashish.one/blogs/fatal-error-concurrent-map-writes/" target="_blank" rel="noopener">blog</a>
.</p>
<h4 id="feel-free-to-comment-below-if-you-have-any-doubts-or-suggestion-about-this-talk">Feel free to comment below, If you have any doubts or suggestion about this talk.</h4>
]]></content:encoded>
    </item>
    
    <item>
      <title>How to scale with massive update queries in Elasticsearch?</title>
      <link>https://ashish.one/talks/scale-with-massive-updates-queries-in-elasticsearch/</link>
      <pubDate>Sun, 08 Dec 2019 20:26:06 +0530</pubDate>
      
      <guid>https://ashish.one/talks/scale-with-massive-updates-queries-in-elasticsearch/</guid>
      <description>Introduction What this talk is all about? We recently moved from MySQL to Elasticsearch where we got a direct 10x - 15x boost in our performance.
We came up with unique use cases of heavy updates in Elasticsearch. That been challenging but yes currently Our Elaticsearch handling 200 million requests per day very efficiently. Our WRITE consist of the partial update, update with script conditions and of course simple indexing.</description>
      <content:encoded><![CDATA[<h1 id="introduction">Introduction</h1>
<h2 id="what-this-talk-is-all-about">What this talk is all about?</h2>
<p>We recently moved from MySQL to Elasticsearch where we got a direct 10x - 15x boost in our performance.</p>
<p>We came up with unique use cases of heavy updates in Elasticsearch. That been challenging but yes currently Our Elaticsearch handling 200 million requests per day very efficiently. Our WRITE consist of the partial update, update with script conditions and of course simple indexing.</p>
<p>Our READ request is 1 million/day which contains Scroll, simple search &amp; Aggregations Query. We achieved to display our email logs in next to real-time.
We also worked on Disk optimization by believing in the principle of &ldquo;Know your query&rdquo;. Currently having 6TB + of the cluster with 80 GB ingestion per day.</p>
<h2 id="slides">Slides</h2>
<div id="Container"
 style="padding-bottom:56.25%; position:relative; display:block; width: 100%">
 <iframe id="googleSlideIframe"
  width="100%" height="100%"
  src="https://docs.google.com/presentation/d/e/2PACX-1vRiOzGgkrN1dO7fD4MDUKzr8WIhHqIhS5Iw1N27_mxYVdtPYcK17ib6ZTdg3bgExVuccJ35vxUSNP3X/embed?start=false&amp;loop=false&amp;delayms=3000"
  frameborder="0" allowfullscreen=""
  style="position:absolute; top:0; left: 0"></iframe>
</div>

<h2 id="talk-video">Talk Video</h2>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/NSZXMv0va74" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

<!-- raw HTML omitted -->
<h4 id="feel-free-to-comment-below-if-you-have-any-doubts-or-suggestion-about-this-talk">Feel free to comment below, If you have any doubts or suggestion about this talk.</h4>
]]></content:encoded>
    </item>
    
  </channel>
</rss>

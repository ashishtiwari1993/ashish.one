<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Talks on ashish.one</title>
    <link>https://ashish.one/talks/</link>
    <description>Recent content in Talks on ashish.one</description>
    <image>
      <title>ashish.one</title>
      <url>https://www.gravatar.com/avatar/dcb52889deff3e5017a18de40c57add8?s=200</url>
      <link>https://www.gravatar.com/avatar/dcb52889deff3e5017a18de40c57add8?s=200</link>
    </image>
    <generator>Hugo -- 0.115.4</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 03 Jun 2024 14:43:28 +0530</lastBuildDate>
    <atom:link href="https://ashish.one/talks/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Serverless Ahmedabad 2023: Monitoring serverless environment with Elastic observability</title>
      <link>https://ashish.one/talks/serverless-ahmedabad-2023-elastic-observability/</link>
      <pubDate>Mon, 03 Jun 2024 12:13:06 +0530</pubDate>
      <guid>https://ashish.one/talks/serverless-ahmedabad-2023-elastic-observability/</guid>
      <description>Introduction Serverless architectures take on-demand tasks to the next level with event-driven scheduling of workloads. Elastic Observability gives you the same insights into your serverless activities as the rest of your environment. Gather logs and metrics from your serverless invocations and tie them together with traces from your serverless functions.
For example Identify AWS Lambda latency issues, cold starts, and other invocation issues. Logs are collected with the rest of your telemetry data, so you can look at all your data in context, in one place.</description>
      <content:encoded><![CDATA[<h1 id="introduction">Introduction</h1>
<p>Serverless architectures take on-demand tasks to the next level with event-driven scheduling of workloads. Elastic Observability gives you the same insights into your serverless activities as the rest of your environment. Gather logs and metrics from your serverless invocations and tie them together with traces from your serverless functions.</p>
<p>For example Identify AWS Lambda latency issues, cold starts, and other invocation issues. Logs are collected with the rest of your telemetry data, so you can look at all your data in context, in one place.</p>
<h2 id="talk-video">Talk video</h2>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/PCPAlMaqRFw" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

]]></content:encoded>
    </item>
    <item>
      <title>GIDS 2024 - Smart Search with RAG: Elasticsearch Meets Language Models</title>
      <link>https://ashish.one/talks/gids-2024-rag/</link>
      <pubDate>Mon, 03 Jun 2024 12:12:06 +0530</pubDate>
      <guid>https://ashish.one/talks/gids-2024-rag/</guid>
      <description>Introduction In today&amp;rsquo;s data-driven world, just having a search engine is not enough; the key is making it smart. Enter Elasticsearch Relevance Engine (ESRE) augmented with Retrieval Augmented Generation (RAG), a powerful solution that marries Elasticsearch’s superior search capabilities with Large Language Models (LLMs) like ChatGPT for precise, contextual querying over proprietary datasets. This session is a hands-on guide that will show you how to amplify the power of Elasticsearch with advanced LLMs.</description>
      <content:encoded><![CDATA[<h1 id="introduction">Introduction</h1>
<p>In today&rsquo;s data-driven world, just having a search engine is not enough; the key is making it smart. Enter Elasticsearch Relevance Engine (ESRE) augmented with Retrieval Augmented Generation (RAG), a powerful solution
that marries Elasticsearch’s superior search capabilities with Large Language Models (LLMs) like ChatGPT for precise, contextual querying over proprietary datasets. This session is a hands-on guide that will show you how to amplify the power of Elasticsearch with advanced LLMs.</p>
<p>Key Takeaways:</p>
<ul>
<li>Learn how to supercharge Elasticsearch&rsquo;s BM25 algorithm with semantic search for results that are not just relevant but contextually accurate.</li>
<li>Discover how to plug in Large Language Models like OpenAI&rsquo;s ChatGPT to enable context-aware question-answering over your proprietary data.</li>
<li>Gain insights into the latest advancements in vector search within Lucene and Elasticsearch.</li>
<li>A quick live demo: Experience first-hand how ESRE, empowered by RAG, transforms a basic search query into a context-rich, highly relevant result..</li>
</ul>
<p>This talk is for you if you&rsquo;re grappling with search relevance issues and are looking for innovative ways to make your search smarter and more efficient. Whether you&rsquo;re a software developer, data engineer, or ML enthusiast, this session will equip you with the skills you need to build next-generation search capabilities.</p>
<h2 id="talk-video">Talk video</h2>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/r1jO4TglsEg" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

]]></content:encoded>
    </item>
    <item>
      <title>Setup &amp; Observe Kubernetes cluster</title>
      <link>https://ashish.one/talks/setup_and_observe_kubernetes/</link>
      <pubDate>Thu, 28 Mar 2024 21:41:03 +0530</pubDate>
      <guid>https://ashish.one/talks/setup_and_observe_kubernetes/</guid>
      <description>Introduction In this gist we will quickly spin a sample Kubernetes cluster and deploying the nginx pod. Additionally, we will implement monitoring using Elastic.
Setup K8s cluster Cluster architecture 3 Node cluster
Machine - Centos7, 4GB RAM
kube1.local - Control plane node kube2.local - worker node kube3.local - worker node Here I am setting hostname kube1.local, kube2.local, kube3.local. Login into all of the servers and perform below command on all three nodes.</description>
      <content:encoded><![CDATA[<h1 id="introduction">Introduction</h1>
<p>In this gist we will quickly spin a sample Kubernetes cluster and deploying the nginx pod. Additionally, we will implement monitoring using Elastic.</p>
<h1 id="setup-k8s-cluster">Setup K8s cluster</h1>
<h2 id="cluster-architecture">Cluster architecture</h2>
<p>3 Node cluster</p>
<p>Machine - Centos7, 4GB RAM</p>
<ol>
<li>kube1.local  - Control plane node</li>
<li>kube2.local - worker node</li>
<li>kube3.local - worker node</li>
</ol>
<p>Here I am setting hostname <code>kube1.local</code>, <code>kube2.local</code>, <code>kube3.local</code>.  Login into all of the servers and perform below command on all three nodes.</p>
<h2 id="swap-off">Swap off</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>sudo swapoff -a
</span></span></code></pre></div><h2 id="install-docker">Install docker</h2>
<p>You can refer <a href="https://docs.docker.com/engine/install/centos/" target="_blank" rel="noopener">docker documentation</a>
 but here are the quick steps:</p>
<h2 id="contanerd-runtime">Contanerd runtime</h2>
<p>kubeadm automatically tries to detect an installed container runtime by scanning through a list of known endpoints.</p>
<p>Verify if containerd is running or not</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>ps -ef | grep containerd
</span></span></code></pre></div><p>In my system containerd was running. <a href="https://github.com/containerd/containerd/blob/main/docs/getting-started.md" target="_blank" rel="noopener">Install containerd</a>
 if it is not installed.</p>
<p>Change below cofing to remove <code>cri</code> from <code>disable_plugins</code></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>sudo vim /etc/containerd/config.toml
</span></span><span style="display:flex;"><span><span style="color:#75715e">#disabled_plugins = [&#34;cri&#34;]</span>
</span></span><span style="display:flex;"><span>disabled_plugins <span style="color:#f92672">=</span> <span style="color:#f92672">[]</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sudo systemctl restart containerd
</span></span></code></pre></div><h2 id="install-kubeadm-kubelet--kubectl">Install kubeadm, kubelet &amp; kubectl</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF | sudo tee /etc/yum.repos.d/kubernetes.repo
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">[kubernetes]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">name=Kubernetes
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">baseurl=https://pkgs.k8s.io/core:/stable:/v1.28/rpm/
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">enabled=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">gpgcheck=1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">gpgkey=https://pkgs.k8s.io/core:/stable:/v1.28/rpm/repodata/repomd.xml.key
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">exclude=kubelet kubeadm kubectl cri-tools kubernetes-cni
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Set SELinux in permissive mode (effectively disabling it)</span>
</span></span><span style="display:flex;"><span>sudo setenforce <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sudo sed -i <span style="color:#e6db74">&#39;s/^SELINUX=enforcing$/SELINUX=permissive/&#39;</span> /etc/selinux/config
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sudo yum install -y kubelet kubeadm kubectl --disableexcludes<span style="color:#f92672">=</span>kubernetes
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>sudo systemctl enable --now kubelet
</span></span></code></pre></div><p>Make sure you install same version on all of the nodes. In my case i am installing <code>v1.28</code>.</p>
<p>Need to install all three packages on all nodes</p>
<p><strong>Kubeadm</strong> - Use to bootstrap the cluster</p>
<p><strong>Kubelet</strong> - Will run all over the machin and take care of pods and container (General operation like stop / start / modify)</p>
<p><strong>Kubectl</strong> - command line utility to talk with kubernetes APIs</p>
<h2 id="on-control-plane-node-only-kube1local">On control plane node only (kube1.local)</h2>
<p>Initialise kubeadm</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>kubeadm init
</span></span></code></pre></div><p>On success, It will print the below <code>join</code> command, which we will use to join any machine in the cluster.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>kubeadm join control_plane_ip:6443 --token tlif0t.jq7r1nvdmltre7m3 --discovery-token-ca-cert-hash sha256:02eb1a7f249b2f2a2b8db2b8fef9b5564ac3db9d42da39db71c23c06df5cecb8
</span></span></code></pre></div><p>Save this command. We need to execute this command on every worker node to join the cluster.</p>
<h2 id="on-worker-node-only-kube2local-kube3local">On worker node only (kube2.local, kube3.local)</h2>
<p>Perform join command.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>kubeadm join control_plane_ip:6443 --token tlif0t.jq7r1nvdmltre7m3 --discovery-token-ca-cert-hash sha256:02eb1a7f249b2f2a2b8db2b8fef9b5564ac3db9d42da39db71c23c06df5cecb8
</span></span></code></pre></div><p>You should see the message - “This node has joined the cluster” with addition details.</p>
<h2 id="verify-cluster-kube1local">Verify cluster (kube1.local)</h2>
<p>Enable <code>kubectl</code> to run from non root user.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>mkdir -p $HOME/.kube
</span></span><span style="display:flex;"><span>sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
</span></span><span style="display:flex;"><span>sudo chown <span style="color:#66d9ef">$(</span>id -u<span style="color:#66d9ef">)</span>:<span style="color:#66d9ef">$(</span>id -g<span style="color:#66d9ef">)</span> $HOME/.kube/config
</span></span></code></pre></div><p>List nodes</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>kubectl get nodes
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>NAME          STATUS   ROLES           AGE     VERSION
</span></span><span style="display:flex;"><span>kube1.local   Ready    control-plane   199d    v1.28.1
</span></span><span style="display:flex;"><span>kube2.local   Ready    &lt;none&gt;          8m22s   v1.28.8
</span></span><span style="display:flex;"><span>kube3.local   Ready    &lt;none&gt;          199d    v1.28.1
</span></span></code></pre></div><p>Our cluster is up and running.</p>
<h1 id="deploy-nginx-kube1local">Deploy Nginx (kube1.local)</h1>
<p>Create Nginx deployment</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF | kubectl apply -f -
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">apiVersion: apps/v1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kind: Deployment
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  name: nginx-deployment
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">spec:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  selector:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    matchLabels:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      app: nginx
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  replicas: 2
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  template:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      labels:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        app: nginx
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    spec:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      containers:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      - name: nginx
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        image: nginx:latest
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        ports:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        - containerPort: 80
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span></code></pre></div><p>Expose the Nginx deployment on a NodePort 32000</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>cat <span style="color:#e6db74">&lt;&lt;EOF | kubectl apply -f -
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">apiVersion: v1
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">kind: Service
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">metadata:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  name: nginx-service
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">spec:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  selector:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    app: nginx
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  type: NodePort
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">  ports:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    - port: 80
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      targetPort: 80
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">      nodePort: 32000
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">EOF</span>
</span></span></code></pre></div><p>Verify pod is running</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>Kubectl get pods
</span></span></code></pre></div><p>Just visit on browser - http://external_id:32000.</p>
<p>You should able to see the nginx’s default page.</p>
<h1 id="setup-observability-with-elastic">Setup Observability with Elastic</h1>
<h2 id="enable-kube-state-matrics-kube1local">Enable kube-state-matrics (kube1.local)</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>git clone https://github.com/kubernetes/kube-state-metrics
</span></span><span style="display:flex;"><span>kubectl apply -f kube-state-metrics/examples/standard/
</span></span></code></pre></div><h2 id="verify-endpoint">Verify endpoint</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>kubectl port-forward svc/kube-state-metrics -n kube-system 8080:8080
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#login to anoter tab and hit</span>
</span></span><span style="display:flex;"><span>curl localhost:8080/metrics
</span></span></code></pre></div><p>It should return all metrics.</p>
<h2 id="monitoring-using-elastic-cloud">Monitoring using Elastic cloud</h2>
<p>You can follow detailed doc - <a href="https://www.elastic.co/getting-started/observability/monitor-kubernetes-clusters" target="_blank" rel="noopener">https://www.elastic.co/getting-started/observability/monitor-kubernetes-clusters</a>
</p>
<p>Blog - <a href="https://www.elastic.co/blog/kubernetes-cluster-metrics-logs-monitoring" target="_blank" rel="noopener">https://www.elastic.co/blog/kubernetes-cluster-metrics-logs-monitoring</a>
</p>
<h1 id="reference-talk">Reference talk</h1>
<p>Bring logs, metrics, and traces from your Kubernetes cluster and the workloads running on it into a single, unified solution. Elastic observability gives better visibility on your kubernetes ecosystem where you can monitor your pods, services, workload etc. Use a centrally managed Elastic Agent to gain visibility into your Kubernetes deployments on EKS, AKS, GKE or self-managed clusters.</p>
<h2 id="talk-video">Talk Video</h2>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/8qOt_gYjwcw" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

]]></content:encoded>
    </item>
    <item>
      <title>Elasticsearch Query Language (ES|QL)</title>
      <link>https://ashish.one/talks/esql/</link>
      <pubDate>Thu, 01 Feb 2024 10:54:52 +0530</pubDate>
      <guid>https://ashish.one/talks/esql/</guid>
      <description>Introduction ES|QL is a new query language for Elasticsearch. It is the unified language for all kinds of use cases like simple queries, aggregations, performing correlations, finding logs, etc. It provides simple easy syntax to perform complex queries. If you come from SQL background, You going to find this very handy.
It is a piped separated langugage with a combination of source commands and process commands. The Elasticsearch Query Language (ES|QL) makes use of &amp;ldquo;pipes&amp;rdquo; (|) to manipulate and transform data in a step-by-step fashion.</description>
      <content:encoded><![CDATA[<h2 id="introduction">Introduction</h2>
<p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/esql.html" target="_blank" rel="noopener">ES|QL</a>
 is a new query language for Elasticsearch. It is the unified language for all kinds of use cases like simple queries, aggregations, performing correlations, finding logs, etc. It provides simple easy syntax to perform complex queries. If you come from SQL background, You going to find this very handy.</p>
<p>It is a piped separated langugage with a combination of <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/esql-commands.html#esql-source-commands" target="_blank" rel="noopener">source commands</a>
 and <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/esql-commands.html#esql-processing-commands" target="_blank" rel="noopener">process</a>
 commands. The Elasticsearch Query Language (ES|QL) makes use of &ldquo;pipes&rdquo; (|) to manipulate and transform data in a step-by-step fashion. This means output of the first step will go as an input for second step.</p>
<p>ES|QL is more than langugage. The execution engine is developed by considering performance in mind. Here ES|QL is not going to convert into Query DSL instead it will be directly executed within Elasticsearch. It operates on blocks at a time instead of per row, targets vectorization and cache locality, and embraces specialization and multi-threading.</p>
<blockquote>
<p>ES|QL - Filter, Transform and Analyze</p>
</blockquote>
<h2 id="example">Example</h2>
<p>Below is a few examples of ES|QL. I am considering you have an Elasticsearch and kibana is <a href="https://www.elastic.co/search-labs/tutorials/install-elasticsearch" target="_blank" rel="noopener">installed</a>
 and running. Please <a href="https://www.elastic.co/guide/en/kibana/current/get-started.html#gs-get-data-into-kibana" target="_blank" rel="noopener">import the sample dataset (Sample web logs)</a>
 from kibana. Navigate in side menu  -&gt; <code>Management</code> -&gt; <code>Dev Tools</code>  to perform the below query.</p>
<h3 id="source-commands">Source commands</h3>
<h4 id="from">FROM</h4>
<pre tabindex="0"><code># Format

POST /_query?format=csv
{
  &#34;query&#34;: &#34;&#34;&#34;
    from kibana_sample_data_logs
  &#34;&#34;&#34;
}
</code></pre><h4 id="row">ROW</h4>
<pre tabindex="0"><code>POST _query?format=txt
{
  &#34;query&#34;:&#34;&#34;&#34;
    row a = &#34;Mozilla/5.0 (X11; Linux x86_64; rv:6.0a1) Gecko/20110421 Firefox/6.0a1&#34;
    | dissect a &#34;%{browser}/%{version}&#34;
    | keep browser
  &#34;&#34;&#34;
}
</code></pre><h4 id="show">SHOW</h4>
<pre tabindex="0"><code>POST /_query?format=txt
{
  &#34;query&#34;: &#34;&#34;&#34;
    show info
  &#34;&#34;&#34;
}
</code></pre><h3 id="processing-commands">Processing commands</h3>
<h4 id="keep">keep</h4>
<pre tabindex="0"><code>POST _query?format=txt
{
  &#34;query&#34;: &#34;&#34;&#34;
    from kibana_sample_data_logs
    | keep @timestamp, clientip, host, tags, bytes
  &#34;&#34;&#34;
}
</code></pre><h4 id="where-limit-sort">where, limit, sort</h4>
<pre tabindex="0"><code>POST _query?format=txt
{
  &#34;query&#34;: &#34;&#34;&#34;
    from kibana_sample_data_logs
    | keep @timestamp, clientip, host, tags, bytes
    | where bytes &gt; 1000
    | sort bytes desc
    | limit 5
  &#34;&#34;&#34;
}
</code></pre><h4 id="like">like</h4>
<pre tabindex="0"><code>POST _query?format=txt
{
  &#34;query&#34;:&#34;&#34;&#34;
    FROM sample_data
    | where message like &#34;*error*&#34;
  &#34;&#34;&#34;
}
</code></pre><h4 id="grok-statsby">GROK, STATS&hellip;BY</h4>
<pre tabindex="0"><code>POST _query?format=txt
{
  &#34;query&#34;:&#34;&#34;&#34;
    from kibana_sample_data_logs
    | grok agent &#34;%{WORD:browser}/%{NUMBER:version}&#34;
    | keep browser, version, @timestamp
  &#34;&#34;&#34;
}

POST _query?format=txt
{
  &#34;query&#34;:&#34;&#34;&#34;
    from kibana_sample_data_logs
    | grok agent &#34;%{WORD:browser}/%{NUMBER:version}&#34;
    | keep browser, version, @timestamp
    | stats count(*) by version
  &#34;&#34;&#34;
}
</code></pre><h4 id="dissect">DISSECT</h4>
<pre tabindex="0"><code>POST _query?format=txt
{
  &#34;query&#34;: &#34;&#34;&#34;
    from kibana_sample_data_logs 
    | dissect message &#34;%{ip} - - %{time} %{web_call} &#34;
    | keep ip, time, web_call
  &#34;&#34;&#34;
}
</code></pre><h4 id="eval">EVAL</h4>
<pre tabindex="0"><code>POST /_query?format=txt
{
  &#34;query&#34;: &#34;&#34;&#34;
    from kibana_sample_data_logs
    | eval t = replace(agent, &#34;Mozilla&#34;, &#34;Chrome&#34;)
    | eval l = length(agent)
    | dissect agent &#34;%{browser}/%{version} &#34;
    | eval lt = left(t, 6)
    | keep lt, browser, version, t, l
  &#34;&#34;&#34;
}
</code></pre><p>You can check more <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/esql-functions-operators.html#esql-string-functions" target="_blank" rel="noopener">string functions</a>
.</p>
<h4 id="data-enrichment-enrich">Data enrichment (ENRICH)</h4>
<pre tabindex="0"><code>
# Create mappings

PUT lang
{
  &#34;mappings&#34;: {
    &#34;properties&#34;: {
      &#34;lang_id&#34;: {
        &#34;type&#34;: &#34;keyword&#34;
      },
      &#34;name&#34;: {
        &#34;type&#34;: &#34;keyword&#34;
      }
    }
  }
}

PUT devs
{
  &#34;mappings&#34;: {
    &#34;properties&#34;: {
      &#34;lang_id&#34;: {
        &#34;type&#34;: &#34;keyword&#34;
      },
      &#34;name&#34;: {
        &#34;type&#34;: &#34;keyword&#34;
      }
    }
  }
}

# Create index &#34;lang&#34;

PUT lang/_bulk
{ &#34;index&#34; : {}}
{ &#34;lang_id&#34;: &#34;1x&#34;, &#34;name&#34;: &#34;java&#34; }
{ &#34;index&#34; : {}}
{ &#34;lang_id&#34;: &#34;2x&#34;, &#34;name&#34;: &#34;php&#34; }
{ &#34;index&#34; : {}}
{ &#34;lang_id&#34;: &#34;3x&#34;, &#34;name&#34;: &#34;node&#34; }
{ &#34;index&#34; : {}}
{ &#34;lang_id&#34;: &#34;4x&#34;, &#34;name&#34;: &#34;python&#34; }
{ &#34;index&#34; : {}}
{ &#34;lang_id&#34;: &#34;5x&#34;, &#34;name&#34;: &#34;ruby&#34; }

# create index &#34;devs&#34;

PUT devs/_bulk
{ &#34;index&#34; : {}}
{ &#34;lang_id&#34;: &#34;5x&#34;, &#34;developer&#34;: &#34;bob&#34; }
{ &#34;index&#34; : {}}
{ &#34;lang_id&#34;: &#34;3x&#34;, &#34;developer&#34;: &#34;mark&#34; }
{ &#34;index&#34; : {}}
{ &#34;lang_id&#34;: &#34;1x&#34;, &#34;developer&#34;: &#34;max&#34; }
{ &#34;index&#34; : {}}
{ &#34;lang_id&#34;: &#34;2x&#34;, &#34;developer&#34;: &#34;david&#34; }
{ &#34;index&#34; : {}}
{ &#34;lang_id&#34;: &#34;4x&#34;, &#34;developer&#34;: &#34;ashish&#34; }


# Create enrich policy

PUT /_enrich/policy/dev_lang
{
  &#34;match&#34;: {
    &#34;indices&#34;: &#34;lang&#34;,
    &#34;match_field&#34;: &#34;lang_id&#34;,
    &#34;enrich_fields&#34;: [&#34;name&#34;]
  }
}

PUT /_enrich/policy/dev_lang/_execute?wait_for_completion=true

POST _query?format=txt
{
  &#34;query&#34;:&#34;&#34;&#34;
    from devs
    | keep lang_id, name, developer
    | enrich dev_lang on lang_id with name
  &#34;&#34;&#34;
}
</code></pre>]]></content:encoded>
    </item>
    <item>
      <title>Elasticsearch: Vector and Hybrid Search</title>
      <link>https://ashish.one/talks/vector-hybrid-search/</link>
      <pubDate>Tue, 29 Aug 2023 21:41:03 +0530</pubDate>
      <guid>https://ashish.one/talks/vector-hybrid-search/</guid>
      <description>Introduction Search is not just traditional TF/IDF any more but the current trend of machine learning and models has opened another dimension for search.
This talk gives an overview of:
Classic search and its limitations. What is a model and how can you use it. How to use vector search or hybrid search in Elasticsearch. Where OpenAI&amp;rsquo;s ChatGPT or similar LLMs come into play to with Elastic. Check how to leverage Leverage ChatGPT with Elasticsearch .</description>
      <content:encoded><![CDATA[<h1 id="introduction">Introduction</h1>
<p>Search is not just traditional TF/IDF any more but the current trend of machine learning and models has opened another dimension for search.</p>
<p>This talk gives an overview of:</p>
<ul>
<li><strong>Classic</strong> search and its limitations.</li>
<li>What is a model and how can you use it.</li>
<li>How to use vector search or hybrid search in Elasticsearch.</li>
<li>Where OpenAI&rsquo;s ChatGPT or similar LLMs come into play to with Elastic.</li>
</ul>
<p>Check how to leverage <a href="https://ashish.one/talks/chatgpt-elasticsearch/" target="_blank" rel="noopener">Leverage ChatGPT with Elasticsearch</a>
.</p>
<h2 id="talk-video">Talk Video</h2>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/AljarsLZRW0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

]]></content:encoded>
    </item>
    <item>
      <title>Monitor Kubernetes cluster with Elastic</title>
      <link>https://ashish.one/talks/monitor_k8_elastic_observability/</link>
      <pubDate>Fri, 28 Jul 2023 21:41:03 +0530</pubDate>
      <guid>https://ashish.one/talks/monitor_k8_elastic_observability/</guid>
      <description>Introduction Bring logs, metrics, and traces from your Kubernetes cluster and the workloads running on it into a single, unified solution. Elastic observability gives better visibility on your kubernetes ecosystem where you can monitor your pods, services, workload etc. Use a centrally managed Elastic Agent to gain visibility into your Kubernetes deployments on EKS, AKS, GKE or self-managed clusters.
Talk Video </description>
      <content:encoded><![CDATA[<h1 id="introduction">Introduction</h1>
<p>Bring logs, metrics, and traces from your Kubernetes cluster and the workloads running on it into a single, unified solution. Elastic observability gives better visibility on your kubernetes ecosystem where you can monitor your pods, services, workload etc. Use a centrally managed Elastic Agent to gain visibility into your Kubernetes deployments on EKS, AKS, GKE or self-managed clusters.</p>
<h2 id="talk-video">Talk Video</h2>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/8qOt_gYjwcw" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

]]></content:encoded>
    </item>
    <item>
      <title>Workshop - Leverage ChatGPT with Elasticsearch</title>
      <link>https://ashish.one/talks/chatgpt-elasticsearch/</link>
      <pubDate>Fri, 21 Jul 2023 15:52:06 +0530</pubDate>
      <guid>https://ashish.one/talks/chatgpt-elasticsearch/</guid>
      <description>Connect ChatGPT to proprietary data stores using Elasticsearch</description>
      <content:encoded><![CDATA[<h1 id="objective">Objective</h1>
<p>In this hands-on workshop, We will learn how to connect ChatGPT to proprietary data stores using Elasticsearch and build question/answer capabilities for your data. In a demo, We will quickly convert your website, FAQ, or any documentation into prompt chat where your user can directly ask a question on your data.</p>
<h1 id="flow">Flow</h1>
<p><img loading="lazy" src="/img/talks/elasticsearch-chatgpt/flow.png" alt="ChatGPT with Elasticsearch"  />
</p>
<h1 id="prerequisites">Prerequisites</h1>
<ol>
<li>
<p>You have used ChatGPT :)</p>
</li>
<li>
<p>Good to have understanding around Elasticsearch (Not mandatory, Introduction will be cover)</p>
</li>
<li>
<p>System + Internet connection</p>
</li>
<li>
<p>OpenAI account with API key - Create new one from <a href="https://platform.openai.com/account/api-keys" target="_blank" rel="noopener">https://platform.openai.com/account/api-keys</a>
. Make sure it having <a href="https://platform.openai.com/account/usage" target="_blank" rel="noopener">free credits</a>
.</p>
</li>
</ol>
<h2 id="without-local-setup">Without local setup</h2>
<ol>
<li>
<p>Google account to use <a href="https://colab.research.google.com/" target="_blank" rel="noopener">google Colab</a>
.</p>
</li>
<li>
<p><a href="https://render.com/" target="_blank" rel="noopener">Render</a>
 account.</p>
</li>
</ol>
<h2 id="local-setup">Local setup</h2>
<ol>
<li>
<p>Git - Install it from <a href="https://git-scm.com/downloads" target="_blank" rel="noopener">https://git-scm.com/downloads</a>
</p>
</li>
<li>
<p>Docker - Good to have. Install it from <a href="https://docs.docker.com/engine/install/" target="_blank" rel="noopener">https://docs.docker.com/engine/install/</a>
.</p>
</li>
<li>
<p>Having basic python knowledge will be good.</p>
</li>
</ol>
<p>For a workshop we going to follow without local setup.</p>
<h1 id="1-setup-cluster">1. Setup cluster</h1>
<ol>
<li>
<p>Visit <a href="https://cloud.elastic.co" target="_blank" rel="noopener">cloud.elastic.co</a>
 and signup.</p>
</li>
<li>
<p>Click on <em><strong>Create deployment</strong></em>. In the pop-up, you can change the settings or leave it default.</p>
</li>
<li>
<p>We need to add machine learning instance. For that, simply click on &ldquo;<em><strong>advance settings</strong></em>&rdquo; .</p>
</li>
<li>
<p>Go to <em><strong>&ldquo;Machine Learning instances&rdquo; -&gt; click on &ldquo;Add Capacity&rdquo;</strong></em> and select at least <strong>4GB</strong> ram capacity.</p>
</li>
<li>
<p>Finally click on &ldquo;<em><strong>Create deployment</strong></em>&rdquo;.</p>
</li>
<li>
<p>Download / Copy the deployment credentials.</p>
</li>
<li>
<p>Once deployment ready, click on &ldquo;Continue&rdquo; (or click on <em><strong>Open Kibana</strong></em>). It will redirect you on kibana dashboard.</p>
</li>
</ol>
<h1 id="2-deploy-model">2. Deploy Model</h1>
<h2 id="elser-model-by-elastic-recommended">ELSER Model by Elastic (Recommended)</h2>
<p>Go to the kibana panel. Navigate to <em><strong>Menu -&gt; Machine Learning</strong></em> (In <em>Analytics</em> section). In left menu, Click on <em><strong>Trained Models</strong></em> (In <em>Model Management</em> Section).</p>
<ol>
<li>ELSER can be found in the list of trained models.</li>
<li>Click the <em><strong>Download model</strong></em> button under <em><strong>Actions</strong></em>.</li>
<li>After the download is finished, start the deployment by clicking the <em><strong>Start deployment</strong></em> button.</li>
<li>Provide a deployment ID, select the priority, and set the number of allocations and threads per allocation values.</li>
<li>Click <em><strong>Start</strong></em>.</li>
</ol>
<h2 id="third-party-model">Third party model</h2>
<p>We are going to use <a href="https://huggingface.co/sentence-transformers/all-distilroberta-v1" target="_blank" rel="noopener">all-distilroberta-v1</a>
 model hosted on a hugging face. Lets import on an elastic cluster using eland.</p>
<p><strong>Get your credentials ready</strong></p>
<ul>
<li><code>cloud_id</code> : Visit “<em><strong><a href="https://cloud.elastic.co" target="_blank" rel="noopener">cloud.elastic.co</a>
</strong></em>” -&gt; Navigate to your deployment and click on “<em><strong>manage</strong></em>”. Simply copy Cloud ID and save it.</li>
<li><code>cloud_user</code>: <code>elastic</code></li>
<li><code>cloud_password</code>: You will get it from step 1.6. If you forget to save, Simply click on <em><strong>“Action” -&gt; “Reset password”</strong></em>. (Username will be <code>elastic</code> only)</li>
<li><code>hf_model_id</code>: <code>sentence-transformers/all-distilroberta-v1</code> (Go to model <a href="https://huggingface.co/sentence-transformers/all-distilroberta-v1" target="_blank" rel="noopener">page</a>
 on huggingface &amp; copy the ID <code>sentence-transformers/all-distilroberta-v1</code>)</li>
</ul>
<p>Now there is two way, You can upload the model using <code>docker</code> as well as <code>Google colab</code>.</p>
<h3 id="using-google-colab-recommended">Using Google Colab (Recommended)</h3>
<p>Simply click on below link. It will open ready made notebook. You just need to click on <code>play</code> button to run notebood.</p>
<p><a href="https://colab.research.google.com/github/ashishtiwari1993/elasticsearch-chatgpt/blob/main/load_model_eland.ipynb" target="_blank" rel="noopener"><img loading="lazy" src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"  />
</a>
</p>
<h3 id="using-docker">Using Docker</h3>
<ol start="2">
<li>
<p>We’re going to use docker for import model to the elastic cluster</p>
<ol>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span> git clone https://github.com/elastic/eland.git 
</span></span><span style="display:flex;"><span> cd eland
</span></span></code></pre></div></li>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span> docker build -t elastic/eland .
</span></span></code></pre></div></li>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span> docker run -it --rm elastic/eland eland_import_hub_model <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>     --cloud-id &lt;cloud_id&gt; <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>     -u elastic -p &lt;elastic_cloud_password&gt; <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>     --hub-model-id sentence-transformers/all-distilroberta-v1 <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>     --task-type text_embedding <span style="color:#ae81ff">\
</span></span></span><span style="display:flex;"><span><span style="color:#ae81ff"></span>     --start
</span></span></code></pre></div></li>
<li>
<p>Let&rsquo;s wait till the model gets uploaded without any error.</p>
</li>
<li>
<p>Exit from <code>eland</code> folder.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>cd ..
</span></span></code></pre></div></li>
</ol>
</li>
</ol>
<h3 id="verify-uploaded-model">Verify uploaded model</h3>
<p>Go to the kibana panel. Navigate to <em><strong>Menu -&gt; Machine Learning (In <code>Analytics</code> section)</strong></em>. In left menu, Click on <em><strong>Trained Models</strong></em>(<code>Model Management</code> Section). You must see your model here in the “<em><strong>Started</strong></em>” state.</p>
<p>In case if a warning message is displayed at the top of the page that says <em><strong>ML job and trained model synchronization required</strong></em>. Follow the link to <em><strong>Synchronize your jobs and trained models.</strong></em> Then click <em><strong>Synchronize</strong></em>.</p>
<h1 id="3-crawling-private-data">3. Crawling private data</h1>
<ol>
<li>Click on <em><strong>Menu -&gt; Enterprise Search -&gt; “Create an Elasticsearch index”</strong></em> button</li>
<li>Click on <em><strong>Web crawler</strong></em>.</li>
<li>Add index name (It will add prefix <em><strong>search</strong></em>) and  hit “<em><strong>Create index</strong></em>”. In my case index name is (search-ashish.one)</li>
<li>Go to “<em><strong>Pipelines</strong></em>” to create a pipeline.</li>
<li>Click “<em><strong>Copy and customize</strong></em>” in the Ingest Pipeline Box.</li>
<li>Click “<em><strong>Add Inference Pipeline</strong></em>” in the Machine Learning Inference Pipelines box.</li>
<li>Give the unique pipeline name e.g. “<em><strong>ml-inference-ashish-one</strong></em>”</li>
<li>Select a trained ML Model from the dropdown “<em><strong>sentence-transformers__all-distilroberta-v1</strong></em>” (For ELSER choose &ldquo;<em><strong>.elser_model_1</strong></em>&rdquo;)</li>
<li>Select “<em><strong>title</strong></em>” as the Source field and set “<em><strong>title-vector</strong></em>” as a destination. You can specify your own destination field name. (In case of ELSER, just select the &ldquo;<em><strong>Source</strong></em>&rdquo; field e.g <em>title, body_content</em>)</li>
<li>Let&rsquo;s click on “<em><strong>Continue</strong></em>” and move to the Test(Optional) tab.  Click on “<em><strong>Continue</strong></em>” again.</li>
<li>At the Review stage let&rsquo;s click on “<em><strong>Create pipeline</strong></em>”.</li>
<li>(Skip this for <em><strong>ELSER</strong></em>) Go to <em><strong>Menu -&gt; Management -&gt; Dev Tools</strong></em>. Let&rsquo;s create a mapping</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>POST &lt;index_name&gt;/_mapping
</span></span><span style="display:flex;"><span><span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;properties&#34;</span>: <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&lt;vector_field_name&gt;&#34;</span>: <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;dense_vector&#34;</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;dims&#34;</span>: 768,
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;index&#34;</span>: true,
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;similarity&#34;</span>: <span style="color:#e6db74">&#34;dot_product&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">}</span>
</span></span></code></pre></div><p>In my case mapping will be:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>POST search-ashish.one/_mapping
</span></span><span style="display:flex;"><span><span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>  <span style="color:#e6db74">&#34;properties&#34;</span>: <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;title-vector&#34;</span>: <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;dense_vector&#34;</span>,
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;dims&#34;</span>: 768,
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;index&#34;</span>: true,
</span></span><span style="display:flex;"><span>      <span style="color:#e6db74">&#34;similarity&#34;</span>: <span style="color:#e6db74">&#34;dot_product&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">}</span>
</span></span></code></pre></div><p>Paste above query in <code>cosole</code> and hit on play button.</p>
<ol start="13">
<li>Go to <em><strong>Enterprise search -&gt; indices -&gt; your_index_name -&gt; Manage Domains</strong></em>. Enter the domain (e.g. <a href="https://ashish.one" target="_blank" rel="noopener">https://ashish.one</a>
. You can add your own domain) to crawl and hit “<em><strong>Validate Domain</strong></em>”.</li>
<li>If everything is fine, simply click on “<em><strong>Add domain</strong></em>” and start crawling by click on <em><strong>Crawl -&gt; Crawl all domains on this index</strong></em>.</li>
<li>Go to <em><strong>Enterprise Search -&gt; Indices</strong></em>. You should see your index name.</li>
</ol>
<h1 id="4-setup-interface">4. Setup Interface</h1>
<p>** Get your credentials ready **</p>
<ol>
<li><code>cloud_id</code> : Visit “<em><strong><a href="https://cloud.elastic.co" target="_blank" rel="noopener">cloud.elastic.co</a>
</strong></em>” -&gt; Navigate to your deployment and click on “<em><strong>manage</strong></em>”. Simply copy Cloud ID and save it.</li>
<li><code>cloud_user</code>: elastic</li>
<li><code>cloud_password</code>: You will get it from step 1.6. If you forget to save, Simply click on <em><strong>“Action” -&gt; “Reset password”</strong></em>. (Username will be elastic)</li>
<li><code>openai_api</code>: Create open ai api key from <a href="https://platform.openai.com/account/api-keys" target="_blank" rel="noopener">https://platform.openai.com/account/api-keys</a>
.</li>
<li><code>es_index</code>: Index name which we created in step 3.3. (search-ashish.one)</li>
<li><code>vector_field</code>: The field which we&rsquo;ve set for destination at step 3.9. i.e. <strong>title-vector</strong></li>
</ol>
<h2 id="setup-on-local-with-docker">Setup on local with Docker</h2>
<ol>
<li>Clone</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>git clone https://github.com/ashishtiwari1993/elasticsearch-chatgpt.git
</span></span><span style="display:flex;"><span>cd elasticsearch-chatgpt
</span></span></code></pre></div><ol start="2">
<li>Replace credentials in <code>Dockerfile</code></li>
</ol>
<p>Open <code>Dockerfile</code> and change below creds</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>ENV openai_api<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&lt;open_api_key&gt;&#34;</span>
</span></span><span style="display:flex;"><span>ENV cloud_id<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&lt;elastic cloud id&gt;&#34;</span>
</span></span><span style="display:flex;"><span>ENV cloud_user<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;elastic&#34;</span>
</span></span><span style="display:flex;"><span>ENV cloud_pass<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&lt;elastic_cloud_password&gt;&#34;</span>
</span></span><span style="display:flex;"><span>ENV es_index<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&lt;elasticsearch_index_name&gt;&#34;</span>
</span></span><span style="display:flex;"><span>ENV chat_title<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&lt;Any title for your page e.g. ashish.one GPT&gt;&#34;</span>
</span></span><span style="display:flex;"><span>ENV vector_field<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&lt; specify vector field where embedding will be save. e.g. title-vector&gt;&#34;</span>
</span></span></code></pre></div><ol start="3">
<li>Build</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>docker build -t es-gpt .
</span></span></code></pre></div><ol start="4">
<li>Run</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>docker run -p 8501:8501 es-gpt
</span></span></code></pre></div><p>Simply visit on <a href="!http://localhost:8501">localhost:8501</a>
</p>
<h2 id="setup-on-renderhttpsrendercom-with-docker">Setup on <a href="https://render.com/" target="_blank" rel="noopener">Render</a>
 with Docker</h2>
<ol>
<li>
<p>Signup on <a href="https://render.com" target="_blank" rel="noopener">https://render.com</a>
.</p>
</li>
<li>
<p>Create <strong>Web Service</strong>.</p>
</li>
<li>
<p>Go to <strong>Public Git repository</strong> section and add below repo url</p>
</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>https://github.com/ashishtiwari1993/elasticsearch-chatgpt
</span></span></code></pre></div><p>Hit on <strong>Continue</strong>.</p>
<ol start="4">
<li>
<p>Add <strong>Name</strong> and select <strong>Free</strong> Instance Type.</p>
</li>
<li>
<p>Click on <strong>Advanced</strong> and <strong>Add Environment Variable</strong></p>
</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>openai_api<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&lt;open_api_key&gt;&#34;</span>
</span></span><span style="display:flex;"><span>cloud_id<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&lt;elastic cloud id&gt;&#34;</span>
</span></span><span style="display:flex;"><span>cloud_user<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;elastic&#34;</span>
</span></span><span style="display:flex;"><span>cloud_pass<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&lt;elastic_cloud_password&gt;&#34;</span>
</span></span><span style="display:flex;"><span>es_index<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&lt;elasticsearch_index_name&gt;&#34;</span>                                                 
</span></span><span style="display:flex;"><span>chat_title<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&lt;Any title for your page e.g. ashish.one GPT&gt;&#34;</span>
</span></span><span style="display:flex;"><span>vector_field<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;&lt; specify vector field where embedding will be save. e.g. title-vector&gt;&#34;</span>
</span></span></code></pre></div><ol start="6">
<li>Finally click on <strong>Create Web Service</strong></li>
</ol>
<h2 id="output">Output</h2>
<p><img loading="lazy" src="/img/talks/elasticsearch-chatgpt/ashish_one_gpt.gif" alt="ashish.one ChatGPT"  />
</p>
<h1 id="reference">Reference</h1>
<p><a href="https://www.elastic.co/blog/chatgpt-elasticsearch-openai-meets-private-data" target="_blank" rel="noopener">Blog - ChatGPT and Elasticsearch: OpenAI meets private data</a>
</p>
]]></content:encoded>
    </item>
    <item>
      <title>Getting started with Elastic stack</title>
      <link>https://ashish.one/talks/getting_started_elastic_stack/</link>
      <pubDate>Sat, 17 Sep 2022 19:24:45 +0000</pubDate>
      <guid>https://ashish.one/talks/getting_started_elastic_stack/</guid>
      <description>What this talk is all about ? Elastic Stack (Elasticsearch, Logstash, Kibana and Beats) is such a platform which is built for scalability, performance and “You know&amp;hellip; for Search”. When you have a system which scales to the horizons of your data, helps you in your data quest, shows you insights - imagine what you can do with it.
Talk Video Feel free to comment below, If you have any doubts or suggestion about this talk.</description>
      <content:encoded><![CDATA[<h2 id="what-this-talk-is-all-about-">What this talk is all about ?</h2>
<p>Elastic Stack (Elasticsearch, Logstash, Kibana and Beats) is such a platform which is built for scalability, performance and “You know&hellip; for Search”. When you have a system which scales to the horizons of your data, helps you in your data quest, shows you insights - imagine what you can do with it.</p>
<h2 id="talk-video">Talk Video</h2>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/hJoorF6zxBA" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

<h4 id="feel-free-to-comment-below-if-you-have-any-doubts-or-suggestion-about-this-talk">Feel free to comment below, If you have any doubts or suggestion about this talk.</h4>
]]></content:encoded>
    </item>
    <item>
      <title>Getting started with Elasticsearch</title>
      <link>https://ashish.one/talks/ws-es/</link>
      <pubDate>Wed, 14 Sep 2022 17:44:43 +0530</pubDate>
      <guid>https://ashish.one/talks/ws-es/</guid>
      <description>Sample Queries for Elasticsearch Workshop CRUD # Insert POST meetup/_doc/ { &amp;#34;name&amp;#34;:&amp;#34;Ashish Tiwari&amp;#34; } # Insert with id POST meetup/_doc/1 { &amp;#34;name&amp;#34;:&amp;#34;Ashish Tiwari&amp;#34; } # Search GET meetup/_search # Update POST meetup/_doc/1 { &amp;#34;name&amp;#34;:&amp;#34;Ashish&amp;#34;, &amp;#34;company&amp;#34;:&amp;#34;elastic&amp;#34;, &amp;#34;address&amp;#34;:&amp;#34;Navi Mumbai kharghar&amp;#34;, &amp;#34;skills&amp;#34;:{ &amp;#34;language&amp;#34;:[&amp;#34;php&amp;#34;,&amp;#34;java&amp;#34;,&amp;#34;node&amp;#34;], &amp;#34;database&amp;#34;:[&amp;#34;mysql&amp;#34;,&amp;#34;mongodb&amp;#34;], &amp;#34;search&amp;#34;:&amp;#34;elasticsearch&amp;#34; } } # search with query GET meetup/_search { &amp;#34;query&amp;#34;: { &amp;#34;match&amp;#34;: { &amp;#34;address&amp;#34;: &amp;#34;navi&amp;#34; } } } # delete DELETE meetup BULK POST _bulk {&amp;#34;index&amp;#34;:{&amp;#34;_index&amp;#34;:&amp;#34;meetup&amp;#34;}} {&amp;#34;user_id&amp;#34;:1,&amp;#34;first_name&amp;#34;:&amp;#34;Yvonne&amp;#34;,&amp;#34;last_name&amp;#34;:&amp;#34;Willmott&amp;#34;,&amp;#34;email&amp;#34;:&amp;#34;ywillmott0@live.com&amp;#34;,&amp;#34;gender&amp;#34;:&amp;#34;Female&amp;#34;,&amp;#34;street_address&amp;#34;:&amp;#34;38 Helena Avenue&amp;#34;,&amp;#34;ip_address&amp;#34;:&amp;#34;104.</description>
      <content:encoded><![CDATA[<h1 id="sample-queries-for-elasticsearch-workshop">Sample Queries for Elasticsearch Workshop</h1>
<h2 id="crud">CRUD</h2>
<pre tabindex="0"><code>
# Insert

POST meetup/_doc/
{
  &#34;name&#34;:&#34;Ashish Tiwari&#34;
}

# Insert with id

POST meetup/_doc/1
{
  &#34;name&#34;:&#34;Ashish Tiwari&#34;
}

# Search

GET meetup/_search

# Update

POST meetup/_doc/1
{
  &#34;name&#34;:&#34;Ashish&#34;,
  &#34;company&#34;:&#34;elastic&#34;,
  &#34;address&#34;:&#34;Navi Mumbai kharghar&#34;,
  &#34;skills&#34;:{
    &#34;language&#34;:[&#34;php&#34;,&#34;java&#34;,&#34;node&#34;],
    &#34;database&#34;:[&#34;mysql&#34;,&#34;mongodb&#34;],
    &#34;search&#34;:&#34;elasticsearch&#34;
  }
}

# search with query

GET meetup/_search
{
  &#34;query&#34;: {
    &#34;match&#34;: {
      &#34;address&#34;: &#34;navi&#34;
    }
  }
}

# delete

DELETE meetup
</code></pre><h2 id="bulk">BULK</h2>
<pre tabindex="0"><code>POST _bulk
{&#34;index&#34;:{&#34;_index&#34;:&#34;meetup&#34;}}
{&#34;user_id&#34;:1,&#34;first_name&#34;:&#34;Yvonne&#34;,&#34;last_name&#34;:&#34;Willmott&#34;,&#34;email&#34;:&#34;ywillmott0@live.com&#34;,&#34;gender&#34;:&#34;Female&#34;,&#34;street_address&#34;:&#34;38 Helena Avenue&#34;,&#34;ip_address&#34;:&#34;104.221.25.110&#34;,&#34;company&#34;:&#34;Flashset&#34;}
{&#34;index&#34;:{&#34;_index&#34;:&#34;meetup&#34;}}
{&#34;user_id&#34;:2,&#34;first_name&#34;:&#34;Immanuel&#34;,&#34;last_name&#34;:&#34;Philbrick&#34;,&#34;email&#34;:&#34;iphilbrick1@wunderground.com&#34;,&#34;gender&#34;:&#34;Male&#34;,&#34;street_address&#34;:&#34;01 Bunting Pass&#34;,&#34;ip_address&#34;:&#34;9.20.164.27&#34;,&#34;company&#34;:&#34;Babblestorm&#34;}
{&#34;index&#34;:{&#34;_index&#34;:&#34;meetup&#34;}}
{&#34;user_id&#34;:3,&#34;first_name&#34;:&#34;Clotilda&#34;,&#34;last_name&#34;:&#34;Danelut&#34;,&#34;email&#34;:&#34;cdanelut2@deliciousdays.com&#34;,&#34;gender&#34;:&#34;Agender&#34;,&#34;street_address&#34;:&#34;0 Crowley Trail&#34;,&#34;ip_address&#34;:&#34;158.94.144.140&#34;,&#34;company&#34;:&#34;Riffpedia&#34;}
{&#34;index&#34;:{&#34;_index&#34;:&#34;meetup&#34;}}
{&#34;user_id&#34;:4,&#34;first_name&#34;:&#34;Nahum&#34;,&#34;last_name&#34;:&#34;Attfield&#34;,&#34;email&#34;:&#34;nattfield3@blog.com&#34;,&#34;gender&#34;:&#34;Male&#34;,&#34;street_address&#34;:&#34;7 Garrison Court&#34;,&#34;ip_address&#34;:&#34;225.144.148.44&#34;,&#34;company&#34;:&#34;Chatterpoint&#34;}
{&#34;index&#34;:{&#34;_index&#34;:&#34;meetup&#34;}}
{&#34;user_id&#34;:5,&#34;first_name&#34;:&#34;Vaughan&#34;,&#34;last_name&#34;:&#34;Middis&#34;,&#34;email&#34;:&#34;vmiddis4@ted.com&#34;,&#34;gender&#34;:&#34;Male&#34;,&#34;street_address&#34;:&#34;7 Cody Way&#34;,&#34;ip_address&#34;:&#34;66.198.31.108&#34;,&#34;company&#34;:&#34;Mynte&#34;}
{&#34;index&#34;:{&#34;_index&#34;:&#34;meetup&#34;}}
{&#34;user_id&#34;:6,&#34;first_name&#34;:&#34;Nolie&#34;,&#34;last_name&#34;:&#34;Alessandrucci&#34;,&#34;email&#34;:&#34;nalessandrucci5@networksolutions.com&#34;,&#34;gender&#34;:&#34;Male&#34;,&#34;street_address&#34;:&#34;826 Brown Hill&#34;,&#34;ip_address&#34;:&#34;96.77.221.95&#34;,&#34;company&#34;:&#34;Feedfish&#34;}
{&#34;index&#34;:{&#34;_index&#34;:&#34;meetup&#34;}}
{&#34;user_id&#34;:7,&#34;first_name&#34;:&#34;Beverlie&#34;,&#34;last_name&#34;:&#34;Ovitts&#34;,&#34;email&#34;:&#34;bovitts6@tripod.com&#34;,&#34;gender&#34;:&#34;Male&#34;,&#34;street_address&#34;:&#34;6 Sycamore Pass&#34;,&#34;ip_address&#34;:&#34;102.24.117.107&#34;,&#34;company&#34;:&#34;Zazio&#34;}
{&#34;index&#34;:{&#34;_index&#34;:&#34;meetup&#34;}}
{&#34;user_id&#34;:8,&#34;first_name&#34;:&#34;Graeme&#34;,&#34;last_name&#34;:&#34;Dopson&#34;,&#34;email&#34;:&#34;gdopson7@free.fr&#34;,&#34;gender&#34;:&#34;Female&#34;,&#34;street_address&#34;:&#34;26 Dunning Avenue&#34;,&#34;ip_address&#34;:&#34;198.33.215.93&#34;,&#34;company&#34;:&#34;Flashset&#34;}
{&#34;index&#34;:{&#34;_index&#34;:&#34;meetup&#34;}}
{&#34;user_id&#34;:9,&#34;first_name&#34;:&#34;Mellisa&#34;,&#34;last_name&#34;:&#34;Hurich&#34;,&#34;email&#34;:&#34;mhurich8@nbcnews.com&#34;,&#34;gender&#34;:&#34;Male&#34;,&#34;street_address&#34;:&#34;6371 Browning Way&#34;,&#34;ip_address&#34;:&#34;66.0.3.199&#34;,&#34;company&#34;:&#34;Divanoodle&#34;}
{&#34;index&#34;:{&#34;_index&#34;:&#34;meetup&#34;}}
{&#34;user_id&#34;:10,&#34;first_name&#34;:&#34;Dyan&#34;,&#34;last_name&#34;:&#34;Loude&#34;,&#34;email&#34;:&#34;dloude9@berkeley.edu&#34;,&#34;gender&#34;:&#34;Female&#34;,&#34;street_address&#34;:&#34;9818 Reindahl Road&#34;,&#34;ip_address&#34;:&#34;16.56.137.54&#34;,&#34;company&#34;:&#34;Agivu&#34;}
{&#34;index&#34;:{&#34;_index&#34;:&#34;meetup&#34;}}
{&#34;user_id&#34;:11,&#34;first_name&#34;:&#34;Becky&#34;,&#34;last_name&#34;:&#34;Shank&#34;,&#34;email&#34;:&#34;bshanka@tinypic.com&#34;,&#34;gender&#34;:&#34;Male&#34;,&#34;street_address&#34;:&#34;1206 Warrior Terrace&#34;,&#34;ip_address&#34;:&#34;90.63.35.111&#34;,&#34;company&#34;:&#34;Izio&#34;}
{&#34;index&#34;:{&#34;_index&#34;:&#34;meetup&#34;}}
{&#34;user_id&#34;:12,&#34;first_name&#34;:&#34;Bar&#34;,&#34;last_name&#34;:&#34;Bedburrow&#34;,&#34;email&#34;:&#34;bbedburrowb@vistaprint.com&#34;,&#34;gender&#34;:&#34;Male&#34;,&#34;street_address&#34;:&#34;75 Onsgard Crossing&#34;,&#34;ip_address&#34;:&#34;85.122.33.250&#34;,&#34;company&#34;:&#34;Zoombox&#34;}
{&#34;index&#34;:{&#34;_index&#34;:&#34;meetup&#34;}}
{&#34;user_id&#34;:13,&#34;first_name&#34;:&#34;Dorey&#34;,&#34;last_name&#34;:&#34;Isenor&#34;,&#34;email&#34;:&#34;disenorc@privacy.gov.au&#34;,&#34;gender&#34;:&#34;Female&#34;,&#34;street_address&#34;:&#34;53682 Parkside Crossing&#34;,&#34;ip_address&#34;:&#34;150.158.150.213&#34;,&#34;company&#34;:&#34;Rhyzio&#34;}
{&#34;index&#34;:{&#34;_index&#34;:&#34;meetup&#34;}}
{&#34;user_id&#34;:14,&#34;first_name&#34;:&#34;Torrin&#34;,&#34;last_name&#34;:&#34;Rangall&#34;,&#34;email&#34;:&#34;trangalld@buzzfeed.com&#34;,&#34;gender&#34;:&#34;Male&#34;,&#34;street_address&#34;:&#34;24247 Old Shore Plaza&#34;,&#34;ip_address&#34;:&#34;40.151.17.2&#34;,&#34;company&#34;:&#34;Devpoint&#34;}
{&#34;index&#34;:{&#34;_index&#34;:&#34;meetup&#34;}}
{&#34;user_id&#34;:15,&#34;first_name&#34;:&#34;Genvieve&#34;,&#34;last_name&#34;:&#34;Beslier&#34;,&#34;email&#34;:&#34;gbesliere@yolasite.com&#34;,&#34;gender&#34;:&#34;Male&#34;,&#34;street_address&#34;:&#34;96214 Miller Trail&#34;,&#34;ip_address&#34;:&#34;115.143.68.208&#34;,&#34;company&#34;:&#34;Oyonder&#34;}
{&#34;index&#34;:{&#34;_index&#34;:&#34;meetup&#34;}}
{&#34;user_id&#34;:16,&#34;first_name&#34;:&#34;Arden&#34;,&#34;last_name&#34;:&#34;Ramas&#34;,&#34;email&#34;:&#34;aramasf@whitehouse.gov&#34;,&#34;gender&#34;:&#34;Polygender&#34;,&#34;street_address&#34;:&#34;390 Gulseth Alley&#34;,&#34;ip_address&#34;:&#34;36.83.126.154&#34;,&#34;company&#34;:&#34;Youbridge&#34;}
{&#34;index&#34;:{&#34;_index&#34;:&#34;meetup&#34;}}
{&#34;user_id&#34;:17,&#34;first_name&#34;:&#34;Alyosha&#34;,&#34;last_name&#34;:&#34;Domm&#34;,&#34;email&#34;:&#34;adommg@washingtonpost.com&#34;,&#34;gender&#34;:&#34;Female&#34;,&#34;street_address&#34;:&#34;32 Oxford Way&#34;,&#34;ip_address&#34;:&#34;174.71.176.45&#34;,&#34;company&#34;:&#34;Wikizz&#34;}
</code></pre><h2 id="upload-sample-json-data-from-kibana">Upload sample json data from kibana</h2>
<p>Download <a href="/data/movies.json">movies.json</a>
 and insert into elasticsearch by using below command:</p>
<p><em>Open Kibana -&gt; Menu -&gt; Home -&gt; Upload a file</em></p>
<h2 id="create-data-view-in-kibana">Create Data view in Kibana</h2>
<p><em>Open Kibana -&gt; Menu -&gt; Stack Management -&gt; Data Views (Kibana)</em></p>
<h2 id="create-dashboard">Create Dashboard</h2>
<p><em>Open Kibana -&gt; Menu -&gt; Analytics -&gt; Dashboard</em></p>
<h2 id="create-mapping">Create mapping</h2>
<pre tabindex="0"><code>PUT /devfest-raipur
{
  &#34;mappings&#34;: {
    &#34;properties&#34;: {
      &#34;age&#34;:    { &#34;type&#34;: &#34;integer&#34; },  
      &#34;email&#34;:  { &#34;type&#34;: &#34;keyword&#34;  }, 
      &#34;name&#34;:   { &#34;type&#34;: &#34;text&#34;  }     
    }
  }
}
</code></pre><h2 id="analyze">Analyze</h2>
<pre tabindex="0"><code># analyze

GET /_analyze?pretty
{
  &#34;text&#34; : &#34;Quick Brown Foxes!&#34;
}

# Whitespace

GET _analyze
{
  &#34;analyzer&#34;: &#34;whitespace&#34;,
  &#34;text&#34;: &#34;The 2 QUICK Brown-Foxes jumped over the lazy dog\u0027s bone.&#34;
}
</code></pre><h3 id="what-is-an-analyzer">What is an analyzer?</h3>
<p>An analyzer is made of character filters, tokenizer and token filters.</p>
<p>Let&rsquo;s build one</p>
<pre tabindex="0"><code>POST _analyze
{
  &#34;char_filter&#34;: [], 
  &#34;tokenizer&#34;:   &#34;standard&#34;,
  &#34;filter&#34;:      [], 
  &#34;text&#34;: [ 
    &#34;I like when the &lt;strong&gt;quick&lt;/strong&gt; foxes jumps over lazy DOGS!&#34;,
    &#34;and &lt;strong&gt;fast&lt;/strong&gt;&#34;
  ]
}
</code></pre><p>Let&rsquo;s remove the html code.</p>
<pre tabindex="0"><code>POST _analyze
{
  &#34;char_filter&#34;: [&#34;html_strip&#34;], 
  &#34;tokenizer&#34;:   &#34;standard&#34;,
  &#34;filter&#34;:      [], 
  &#34;text&#34;: [ 
    &#34;I like when the &lt;strong&gt;quick&lt;/strong&gt; foxes jumps over lazy DOGS!&#34;,
    &#34;and &lt;strong&gt;fast&lt;/strong&gt;&#34;
  ]
}
</code></pre><p>Some words don&rsquo;t bring us any value. Let&rsquo;s skip them.</p>
<pre tabindex="0"><code>POST _analyze
{
  &#34;char_filter&#34;: [&#34;html_strip&#34;], 
  &#34;tokenizer&#34;:   &#34;standard&#34;,
  &#34;filter&#34;:      [
    {
      &#34;type&#34;:       &#34;stop&#34;,
      &#34;stopwords&#34;:  [ &#34;_english_&#34;]
    }
  ], 
  &#34;text&#34;:
  [ 
    &#34;I like when the &lt;strong&gt;quick&lt;/strong&gt; foxes jumps over lazy DOGS!&#34;,
    &#34;and &lt;strong&gt;fast&lt;/strong&gt;&#34;
  ]
}
</code></pre><p>We can also remove &ldquo;I&rdquo;, &ldquo;when&rdquo; and &ldquo;over&rdquo;.</p>
<pre tabindex="0"><code>POST _analyze
{
  &#34;char_filter&#34;: [&#34;html_strip&#34;], 
  &#34;tokenizer&#34;:   &#34;standard&#34;,
  &#34;filter&#34;:      [
    {
      &#34;type&#34;:       &#34;stop&#34;,
      &#34;ignore_case&#34;:true, 
      &#34;stopwords&#34;:  [ &#34;_english_&#34;, &#34;I&#34;, &#34;when&#34;, &#34;over&#34;]
    }
  ], 
  &#34;text&#34;:
  [ 
    &#34;I like when the &lt;strong&gt;quick&lt;/strong&gt; foxes jumps over lazy DOGS!&#34;,
    &#34;and &lt;strong&gt;fast&lt;/strong&gt;&#34;
  ]
}
</code></pre><p><code>DOGS</code> and <code>dogs</code> should match.</p>
<pre tabindex="0"><code>POST _analyze
{
  &#34;char_filter&#34;: [&#34;html_strip&#34;], 
  &#34;tokenizer&#34;:   &#34;standard&#34;,
  &#34;filter&#34;:      [
    {
      &#34;type&#34;:       &#34;stop&#34;,
      &#34;ignore_case&#34;:true, 
      &#34;stopwords&#34;:  [ &#34;_english_&#34;, &#34;I&#34;, &#34;when&#34;, &#34;over&#34;]
    },
    &#34;lowercase&#34;
  ], 
  &#34;text&#34;:
  [ 
    &#34;I like when the &lt;strong&gt;quick&lt;/strong&gt; foxes jumps over lazy DOGS!&#34;,
    &#34;and &lt;strong&gt;fast&lt;/strong&gt;&#34;
  ]
}
</code></pre><p><code>dog</code>, <code>dogs</code> and <code>fox</code>, <code>foxes</code> and <code>jump</code>, <code>jumps</code>, <code>jumping</code>, <code>jumped</code> should match. Let&rsquo;s use a <code>stemmer</code>.</p>
<pre tabindex="0"><code>POST _analyze
{
  &#34;char_filter&#34;: [&#34;html_strip&#34;], 
  &#34;tokenizer&#34;:   &#34;standard&#34;,
  &#34;filter&#34;:      [
    {
      &#34;type&#34;:       &#34;stop&#34;,
      &#34;ignore_case&#34;:true, 
      &#34;stopwords&#34;:  [ &#34;_english_&#34;, &#34;I&#34;, &#34;when&#34;, &#34;over&#34;]
    },
    &#34;lowercase&#34;,
    {
      &#34;type&#34;:       &#34;stemmer&#34;,
      &#34;language&#34;:   &#34;english&#34; 
    }
  ], 
  &#34;text&#34;:
  [ 
    &#34;jumping jumps jump jumped&#34;,
    &#34;I like when the &lt;strong&gt;quick&lt;/strong&gt; foxes jumps over lazy DOGS!&#34;,
    &#34;and &lt;strong&gt;fast&lt;/strong&gt;&#34;
  ]
}
</code></pre><h1 id="language-analyzer">Language analyzer</h1>
<pre tabindex="0"><code>GET /_analyze?pretty
{
  &#34;analyzer&#34;: &#34;hindi&#34;, 
  &#34;text&#34; : &#34;चाणक्य ने चंद्रगुप्त और बिंदूसार दोनों के लिए प्रधानमंत्री और राजनयिक सलाहकार के रूप में काम किया।&#34;
}
</code></pre><h2 id="lets-create-hindi-search-engine-गतयतर">Let&rsquo;s create Hindi search engine (गीतयंत्र)</h2>
<h3 id="create-mapping-1">Create mapping</h3>
<pre tabindex="0"><code>PUT geetyantra
{
  &#34;settings&#34;: {
    &#34;analysis&#34;: {
      &#34;analyzer&#34;: {
        &#34;geetyantra-analyzer&#34;:{
          &#34;type&#34;:&#34;hindi&#34;
        }
      }
    }
  },
  &#34;mappings&#34;: {
    &#34;properties&#34;: {
      &#34;adhyay&#34;: {&#34;type&#34;: &#34;integer&#34;},
      &#34;updesh&#34;: {&#34;type&#34;: &#34;text&#34;,&#34;analyzer&#34;: &#34;geetyantra-analyzer&#34;}
    }
  }
}
</code></pre><h3 id="insert-data">Insert data</h3>
<p>Taking data from 🙏<a href="https://hi.wikipedia.org/wiki/%E0%A4%B6%E0%A5%8D%E0%A4%B0%E0%A5%80%E0%A4%AE%E0%A4%A6%E0%A5%8D%E0%A4%AD%E0%A4%97%E0%A4%B5%E0%A4%A6%E0%A5%8D%E0%A4%97%E0%A5%80%E0%A4%A4%E0%A4%BE" target="_blank" rel="noopener">विकिपीडिया-श्रीमद्भगवद्गीता</a>
</p>
<p>Lets insert some data like below:</p>
<pre tabindex="0"><code>POST geetyantra/_doc
{
  &#34;adhyay&#34;:1,
  &#34;updesh&#34;:&#34;कृष्ण ने अर्जुन की वह स्थिति देखकर जान लिया कि अर्जुन का शरीर ठीक है किंतु युद्ध आरंभ होने से पहले ही उस अद्भुत क्षत्रिय का मनोबल टूट चुका है। बिना मन के यह शरीर खड़ा नहीं रह स।&#34;
}

POST geetyantra/_doc
{
  &#34;adhyay&#34;:2,
  &#34;updesh&#34;:&#34;दूसरे अध्याय का नाम सांख्ययोग है। इसमें जीवन की दो प्राचीन संमानित परंपराओं का तर्कों द्वारा वर्णन आया है। अर्जुन को उस कृपण स्थिति में रोते देखकर कृष्ण ने उनका ध्यान दिलाया है कि इस प्रकार का क्लैव्य और हृदय की क्षुद्र दुर्बलता अर्जुन जैसे वीर के लिए उचित नहीं।&#34;
}

POST geetyantra/_doc
{
  &#34;adhyay&#34;:3,
  &#34;updesh&#34;:&#34;नित्य कर्म करने वाले की श्रेष्ठता&#34;
}

POST geetyantra/_doc
{
  &#34;adhyay&#34;:4,
  &#34;updesh&#34;:&#34;चौथे अध्याय में, जिसका नाम ज्ञान-कर्म-संन्यास-योग है, यह बाताया गया है कि ज्ञान प्राप्त करके कर्म करते हुए भी कर्मसंन्यास का फल किस उपाय से प्राप्त किया जा सकता है।&#34;,
  &#34;shloka&#34;:&#34;यदा यदा हि धर्मस्य ग्लानिर्भवति भारत,अभ्युत्थानमधर्मस्य तदात्मानं सृजाम्यहम्&#34;
}

POST geetyantra/_doc
{
  &#34;adhyay&#34;:5,
  &#34;updesh&#34;:&#34;ज्ञानी महापुरुष विद्या-विनययुक्त ब्राह्मण में और चाण्डाल में तथा गाय, हाथी एवं कुत्ते में भी समरूप परमात्मा को देखने वाले होते हैं।&#34;,
  &#34;shloka&#34;:&#34;विद्याविनयसंपन्ने ब्राह्मणे गवि हस्तिनि,शुनि चैव श्वपाके च पंडिता: समदर्शिन&#34;
}


POST geetyantra/_doc
{
  &#34;adhyay&#34;:6,
  &#34;updesh&#34;:&#34;छठा अध्याय आत्मसंयम योग है जिसका विषय नाम से ही प्रकट है। जितने विषय हैं उन सबसे इंद्रियों का संयम-यही कर्म और ज्ञान का निचोड़ है। सुख में और दुख में मन की समान स्थिति, इसे ही योग कहते हैं।&#34;
}

POST geetyantra/_doc
{
  &#34;adhyay&#34;:7,
  &#34;updesh&#34;:&#34;पंचतत्व, मन, बुद्धि भी मैं हूँ| मैं ही संसार की उत्पत्ति करता हूँ और विनाश भी मैं ही करता हूँ। मेरे भक्त चाहे जिस प्रकार भजें परन्तु अंततः मुझे ही प्राप्त होते हैं। मैं योगमाया से अप्रकट रहता हूँ और मुर्ख मुझे केवल साधारण मनुष्य ही समझते हैं।&#34;,
  &#34;shloka&#34;:&#34;यो यो यां यां तनुं भक्तः श्रद्धयार्चितुमिच्छति,तस्य तस्याचलां श्रद्धां तामेव विदधाम्यहम्&#34;
}

POST geetyantra/_doc
{
  &#34;adhyay&#34;:8,
  &#34;updesh&#34;:&#34;की संज्ञा अक्षर ब्रह्मयोग है। उपनिषदों में अक्षर विद्या का विस्तार हुआ। गीता में उस अक्षरविद्या का सार कह दिया गया है-अक्षर ब्रह्म परमं, अर्थात् परब्रह्म की संज्ञा अक्षर है। मनुष्य, अर्थात् जीव और शरीर की संयुक्त रचना का ही नाम अध्यात्म है।&#34;
}

POST geetyantra/_doc
{
  &#34;adhyay&#34;:9,
  &#34;updesh&#34;:&#34;को राजगुह्ययोग कहा गया है, अर्थात् यह अध्यात्म विद्या विद्याराज्ञी है और यह गुह्य ज्ञान सबमें श्रेष्ठ है। राजा शब्दका एक अर्थ मन भी था। अतएव मन की दिव्य शक्तिमयों को किस प्रकार ब्रह्ममय बनाया जाय, इसकी युक्ति ही राजविद्या है।&#34;
}

POST geetyantra/_doc
{
  &#34;adhyay&#34;:10,
  &#34;updesh&#34;:&#34;दसवें अध्याय का नाम विभूतियोग है। इसका सार यह है कि लोक में जितने देवता हैं, सब एक ही भगवान, की विभूतियाँ हैं, मनुष्य के समस्त गुण और अवगुण भगवान की शक्ति के ही रूप हैं।&#34;
}

POST geetyantra/_doc
{
  &#34;adhyay&#34;:11,
  &#34;updesh&#34;:&#34;का नाम विश्वरूपदर्शन योग है। इसमें अर्जुन ने भगवान का विश्वरूप देखा। विराट रूप का अर्थ है मानवीय धरातल और परिधि के ऊपर जो अनंत विश्व का प्राणवंत रचनाविधान है, उसका साक्षात दर्शन। विष्णु का जो चतुर्भुज रूप है, वह मानवीय धरातल पर सौम्यरूप है।&#34;
}

POST geetyantra/_doc
{
  &#34;adhyay&#34;:12,
  &#34;updesh&#34;:&#34;का नाम भक्ति योग है। जो जानने योग्य है। जिसको जानकर मनुष्य परमानन्द को प्राप्त हो जाता है अर्थात वो परमात्मा ही सत्य है ।।&#34;
}

POST geetyantra/_doc
{
  &#34;adhyay&#34;:13,
  &#34;updesh&#34;:&#34;में एक सीधा विषय क्षेत्र और क्षेत्रज्ञ का विचार है। यह शरीर क्षेत्र है, उसका जाननेवाला जीवात्मा क्षेत्रज्ञ है।&#34;
}

POST geetyantra/_doc
{
  &#34;adhyay&#34;:14,
  &#34;updesh&#34;:&#34;का नाम गुणत्रय विभाग योग है। यह विषय समस्त वैदिक, दार्शनिक और पौराणिक तत्वचिंतन का निचोड़ है-सत्व, रज, तम नामक तीन गुण-त्रिको की अनेक व्याख्याएँ हैं।&#34;
}

POST geetyantra/_doc
{
  &#34;adhyay&#34;:15,
  &#34;updesh&#34;:&#34;का नाम पुरुषोत्तमयोग है। इसमें विश्व का अश्वत्थ के रूप में वर्णन किया गया है। यह अश्वत्थ रूपी संसार महान विस्तारवाला है। देश और काल में इसका कोई अंत नहीं है।&#34;
}

POST geetyantra/_doc
{
  &#34;adhyay&#34;:16,
  &#34;updesh&#34;:&#34;में देवासुर संपत्ति का विभाग बताया गया है। आरंभ से ही ऋग्देव में सृष्टि की कल्पना दैवी और आसुरी शक्तियों के रूप में की गई है। &#34;
}

POST geetyantra/_doc
{
  &#34;adhyay&#34;:17,
  &#34;updesh&#34;:&#34;की संज्ञा श्रद्धात्रय विभाग योग है। इसका संबंध सत, रज और तम, इन तीन गुणों से ही है, अर्थात् जिसमें जिस गुण का प्रादुर्भाव होता है, उसकी श्रद्धा या जीवन की निष्ठा वैसी ही बन जाती है।&#34;
}

POST geetyantra/_doc
{
  &#34;adhyay&#34;:18,
  &#34;updesh&#34;:&#34;की संज्ञा मोक्षसंन्यास योग है। इसमें गीता के समस्त उपदेशों का सार एवं उपसंहार है। यहाँ पुन: बलपूर्वक मानव जीवन के लिए तीन गुणों का महत्व कहा गया है। पृथ्वी के मानवों में और स्वर्ग के देवताओं में कोई भी ऐसा नहीं जो प्रकृति के चलाए हुए इन तीन गुणों से बचा हो।&#34;
}
</code></pre><h3 id="search">Search</h3>
<pre tabindex="0"><code>
GET geetyantra/_search?size=20

GET geetyantra/_search
{
  &#34;query&#34;: {
    &#34;match&#34;: {
      &#34;updesh&#34;: &#34;अर्जुन&#34;
    }
  }
}

GET geetyantra/_search
{
  &#34;query&#34;: {
    &#34;match&#34;: {
      &#34;shloka&#34;: &#34;धर्मस्य&#34;
    }
  }
}

GET geetyantra/_search
{
  &#34;query&#34;: {
    &#34;multi_match&#34;: {
      &#34;query&#34;: &#34;श्रद्धा&#34;,
      &#34;fields&#34;: [&#34;shloka&#34;,&#34;updesh&#34;]
    }
  }
}

GET geetyantra/_search
{
  &#34;query&#34;: {
    &#34;match_phrase_prefix&#34;: {
      &#34;updesh&#34;: &#34;चौथे अध्याय में&#34;
    }
  }
}
</code></pre><h2 id="search-as-you-type">Search as you type</h2>
<p>Refer article <a href="https://ashish.one/blogs/search-as-you-type/" target="_blank" rel="noopener">Search as you type</a>
.</p>
]]></content:encoded>
    </item>
    <item>
      <title>Parse custom logs in Elasticsearch using grok_pattern</title>
      <link>https://ashish.one/talks/devops-conf-2022/</link>
      <pubDate>Sun, 06 Mar 2022 14:30:32 +0530</pubDate>
      <guid>https://ashish.one/talks/devops-conf-2022/</guid>
      <description>Introduction In the talk, Quickly showed how you can use the metricbeat to check system health. With a few clicks, you can start monitoring your infra.
Another demo shows, How you can parse your custom unstructured logs to Elasticsearch. There is some utility already available for predefined logs format like json, apache, nginx and system logs etc.
But if you have different requirement where you need to parse a different types of log format , You can parse using Grok processor .</description>
      <content:encoded><![CDATA[<h1 id="introduction">Introduction</h1>
<p>In the talk, Quickly showed how you can use the <a href="https://www.elastic.co/beats/metricbeat" target="_blank" rel="noopener">metricbeat</a>
 to check system health. With a few clicks, you can start monitoring your infra.</p>
<p>Another demo shows, How you can parse your custom unstructured logs to Elasticsearch. There is some utility already available for predefined logs format like json, apache, nginx and system logs etc.</p>
<p>But if you have different requirement where you need to parse a different types of log format , You can parse using <a href="https://www.elastic.co/guide/en/elasticsearch/reference/master/grok-processor.html" target="_blank" rel="noopener">Grok processor</a>
.</p>
<p>Also explained how you can read custom logs from log files in real time and ingest to Elasticsearch.</p>
<h1 id="slides">Slides</h1>
<div id="Container"
 style="padding-bottom:56.25%; position:relative; display:block; width: 100%">
 <iframe id="googleSlideIframe"
  width="100%" height="100%"
  src="https://docs.google.com/presentation/d/e/2PACX-1vQtGa1x8-WMwWX8MTMZ-8GdJDMmiro4dNwcIE5HHmj1oGaSs88znwGf-W8bwUSANkIRQkeMZnh8KfWs/embed?start=false&amp;loop=false&amp;delayms=3000"
  frameborder="0" allowfullscreen=""
  style="position:absolute; top:0; left: 0"></iframe>
</div>

<h2 id="talk-video">Talk Video</h2>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/owyv9sQE7q8?start=4856&amp;end=9427" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

<h4 id="feel-free-to-comment-below-if-you-have-any-doubts-or-suggestion-about-this-talk">Feel free to comment below, If you have any doubts or suggestion about this talk.</h4>
]]></content:encoded>
    </item>
    <item>
      <title>Deploy Elasicsearch on Azure cloud</title>
      <link>https://ashish.one/talks/deploy_elastic_on_azure/</link>
      <pubDate>Sat, 29 Jan 2022 19:24:45 +0000</pubDate>
      <guid>https://ashish.one/talks/deploy_elastic_on_azure/</guid>
      <description>Introduction What this talk is all about ? The purpose of the talk is to give a short overview of Elastic solutions &amp;amp; Elastic stacks. In the demo shown, how you can deploy elasticsearch instance on Microsoft Azure.
Also, it gives an idea to use the elastic cloud to manage the elasticsearch instance which deployed on the Azure cloud. You can also create deployment on elastic cloud (cloud.elastic.co ).
In the demo, Successfully shipped the metric data of the local system (my MacBook) to the newly deployed elasticsearch instance and explored the dashboard on kibana.</description>
      <content:encoded><![CDATA[<h1 id="introduction">Introduction</h1>
<h2 id="what-this-talk-is-all-about-">What this talk is all about ?</h2>
<p>The purpose of the talk is to give a short overview of Elastic solutions &amp; Elastic stacks. In the demo shown, how you can deploy elasticsearch instance on Microsoft Azure.</p>
<p>Also, it gives an idea to use the elastic cloud to manage the elasticsearch instance which deployed on the Azure cloud. You can also create deployment on elastic cloud (<a href="https://cloud.elastic.co" target="_blank" rel="noopener">cloud.elastic.co</a>
).</p>
<p>In the demo, Successfully shipped the metric data of the local system (my MacBook) to the newly deployed elasticsearch instance and explored the dashboard on kibana.</p>
<h2 id="slides">Slides</h2>
<div id="Container"
 style="padding-bottom:56.25%; position:relative; display:block; width: 100%">
 <iframe id="googleSlideIframe"
  width="100%" height="100%"
  src="https://docs.google.com/presentation/d/e/2PACX-1vR9COL0Pod4Hdhc3OlkIPorb-UM0DtbhSgcqQajOYV789jbmRYsffyIRVR0cFCnm8eu80sF8-khLc0K/embed?start=false&amp;loop=false&amp;delayms=3000"
  frameborder="0" allowfullscreen=""
  style="position:absolute; top:0; left: 0"></iframe>
</div>

<h2 id="talk-video">Talk Video</h2>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/O2HdAA5o1i4" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

<h4 id="feel-free-to-comment-below-if-you-have-any-doubts-or-suggestion-about-this-talk">Feel free to comment below, If you have any doubts or suggestion about this talk.</h4>
]]></content:encoded>
    </item>
    <item>
      <title>Golang basics &amp; Handling 100k hourly webhooks with golang @MimePost</title>
      <link>https://ashish.one/talks/golang-basics-and-send-100k-hourly-webhooks-with-golang-mimepost/</link>
      <pubDate>Wed, 11 Mar 2020 00:12:30 +0530</pubDate>
      <guid>https://ashish.one/talks/golang-basics-and-send-100k-hourly-webhooks-with-golang-mimepost/</guid>
      <description>What this talk about? I am working on Golang for the last 1 year from the published date. I have shared some basics of Golang.
Also, shared What are the pain points developers face when they migrate from any other language (Especially from web language like PHP) to Golang?
I have explained the Webhook architecture of MimePost And how we sending 100k Request hourly( Though Benchmark proves we can scale up to 500k).</description>
      <content:encoded><![CDATA[<h2 id="what-this-talk-about">What this talk about?</h2>
<p>I am working on Golang for the last 1 year from the published date. I have shared some basics of Golang.</p>
<p>Also, shared What are the pain points developers face when they migrate from any other language (Especially from web language like PHP) to Golang?</p>
<p>I have explained the Webhook architecture of MimePost And how we sending 100k Request hourly( Though Benchmark proves we can scale up to 500k).</p>
<p>Shown some immature code which given me a better understanding of 100% CPU utilization and How I waste my major time to debug on silly things.</p>
<p>Shared one of our error and it&rsquo;s solutions related to How you can avoid race conditions on &ldquo;map&rdquo; type variables.</p>
<h2 id="slides">Slides</h2>
<div id="Container"
 style="padding-bottom:56.25%; position:relative; display:block; width: 100%">
 <iframe id="googleSlideIframe"
  width="100%" height="100%"
  src="https://docs.google.com/presentation/d/e/2PACX-1vQExSl-gRPoA9hC6qXuqrjwiQVHAanDieZN_5GpV2Lw9cuxjsVFEN_wkTThqpQwZ36vJz4zwmTvV7cC/embed?start=false&amp;loop=false&amp;delayms=3000"
  frameborder="0" allowfullscreen=""
  style="position:absolute; top:0; left: 0"></iframe>
</div>

<h2 id="talk-video">Talk Video</h2>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/ZjOcwoCkkog" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

<h2 id="demo---1">Demo - 1</h2>
<p>This code will make 100% CPU utilization and <code>forever()</code> function not going to share any single CPU time with <code>anotherGoroutine()</code></p>
<script type="application/javascript" src="https://gist.github.com/ashishtiwari1993/00b2a56ac8f5b39d3229d723e58815bc.js"></script>

<h2 id="demo---2">Demo - 2</h2>
<p>Reproduce Golang &ldquo;fatal error: concurrent map writes&rdquo; &amp; Solution. To reproduce comment Mutex related all operation like line no. 12, 30, 32, 44, 46. Mutex is use to prevent race condition which generates this error.</p>
<script type="application/javascript" src="https://gist.github.com/ashishtiwari1993/d494b71ac264184ba46ced1bf2114c30.js"></script>

<p>Find more details on this <a href="https://ashish.one/blogs/fatal-error-concurrent-map-writes/" target="_blank" rel="noopener">blog</a>
.</p>
<h4 id="feel-free-to-comment-below-if-you-have-any-doubts-or-suggestion-about-this-talk">Feel free to comment below, If you have any doubts or suggestion about this talk.</h4>
]]></content:encoded>
    </item>
    <item>
      <title>How to scale with massive update queries in Elasticsearch?</title>
      <link>https://ashish.one/talks/scale-with-massive-updates-queries-in-elasticsearch/</link>
      <pubDate>Sun, 08 Dec 2019 20:26:06 +0530</pubDate>
      <guid>https://ashish.one/talks/scale-with-massive-updates-queries-in-elasticsearch/</guid>
      <description>Introduction What this talk is all about? We recently moved from MySQL to Elasticsearch where we got a direct 10x - 15x boost in our performance.
We came up with unique use cases of heavy updates in Elasticsearch. That been challenging but yes currently Our Elaticsearch handling 200 million requests per day very efficiently. Our WRITE consist of the partial update, update with script conditions and of course simple indexing.</description>
      <content:encoded><![CDATA[<h1 id="introduction">Introduction</h1>
<h2 id="what-this-talk-is-all-about">What this talk is all about?</h2>
<p>We recently moved from MySQL to Elasticsearch where we got a direct 10x - 15x boost in our performance.</p>
<p>We came up with unique use cases of heavy updates in Elasticsearch. That been challenging but yes currently Our Elaticsearch handling 200 million requests per day very efficiently. Our WRITE consist of the partial update, update with script conditions and of course simple indexing.</p>
<p>Our READ request is 1 million/day which contains Scroll, simple search &amp; Aggregations Query. We achieved to display our email logs in next to real-time.
We also worked on Disk optimization by believing in the principle of &ldquo;Know your query&rdquo;. Currently having 6TB + of the cluster with 80 GB ingestion per day.</p>
<h2 id="slides">Slides</h2>
<div id="Container"
 style="padding-bottom:56.25%; position:relative; display:block; width: 100%">
 <iframe id="googleSlideIframe"
  width="100%" height="100%"
  src="https://docs.google.com/presentation/d/e/2PACX-1vRiOzGgkrN1dO7fD4MDUKzr8WIhHqIhS5Iw1N27_mxYVdtPYcK17ib6ZTdg3bgExVuccJ35vxUSNP3X/embed?start=false&amp;loop=false&amp;delayms=3000"
  frameborder="0" allowfullscreen=""
  style="position:absolute; top:0; left: 0"></iframe>
</div>

<h2 id="talk-video">Talk Video</h2>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/NSZXMv0va74" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

<!-- raw HTML omitted -->
<h4 id="feel-free-to-comment-below-if-you-have-any-doubts-or-suggestion-about-this-talk">Feel free to comment below, If you have any doubts or suggestion about this talk.</h4>
]]></content:encoded>
    </item>
  </channel>
</rss>
